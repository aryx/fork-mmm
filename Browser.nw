\documentclass[twocolumn]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, changed for the better a few things:
% - deadcode?

%thx to codemap/codegraph/scheck:
% - use cg to reduce backward deps (ocaml linker enforces that)
%   (harder to understand non layered code)
% - TODO use scheck to remove deadcode, dead prototypes, useless export
%   or mv as forward decl
%   (harder to understand big interface files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand web browsers?:
% - TODO encodings, accents, base64, iso8559, etc

%history LP-ization:
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * TODO ctor/dtor, dumper
%    * TODO [[xxx]] other fields, [[xxx]] extra fields
% - TODO read Extra section, identify concepts, first TOC
% - TODO distribute parts of the Extra section in the main file
% - TODO understand main(), LP split main, improve TOC
% - TODO understand main functions, LP split, cluster, improve TOC
% - TODO LP split the structures, use datalog for flow to field info
% - TODO nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - TODO aspecify advanced features! remove useless features
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\iffinal
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\fi
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
%\usepackage{cleveref} %\cref
%\usepackage{multirow}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}
 %\usepackage[margin=0.5in]{geometry}
 %  but eat the bottom when very low
 %\usepackage{fullpage} is deprecated 
 % => do the more manual below:
 \addtolength{\oddsidemargin}{-.850in}
 \addtolength{\evensidemargin}{-.850in}
 \addtolength{\textwidth}{1.70in}
 \addtolength{\topmargin}{-.850in}
 \addtolength{\textheight}{1.70in}
%\usepackage{minitoc}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% used for forward decl, pragmas, func decl, extern decl, stats, #ifdef,
% debugging macros

%\setcounter{tocdepth}{1}

%******************************************************************************
% Title
%******************************************************************************

\begin{document}

\title{
{\Huge 
Principia Softwarica: The Web Browser [[mmm]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}
}

\maketitle 
\onecolumn
\hrule
\begin{quote}
    Copyright \copyright{} 2015 Yoann Padioleau \\
    Permission is granted to copy, distribute and/or modify this document,
    except all the source code it contains, under the terms of the GNU Free
    Documentation License, Version 1.3.
\end{quote}
\hrule

%CONFIG: \dominitoc

\iffinal
\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\twocolumn
\tableofcontents
\endgroup
\else
\tableofcontents
\fi

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

\section{Motivations}

The goal of this book is to present in full details the source code of
a web browser.
Why? Because I think it makes you a better programmer if
you fully understand how things work under the hood.

% chose mmm, written in ocaml, small, elegant.

Here are other candidates that were considered but ultimately discarded:
\begin{itemize}
\item mosaic
% maybe good. LOC?
\item gecko (firefox)
% huge
\item khtml/webkit/blink (kconqueror, chrome, safari)
% huge
\item netsurf
% with subprojects like hubhub, libcss, libdom, etc
%... was used originally by servo
\item servo
% already lots of LOC actually
% https://github.com/servo/servo/wiki/Design
\end{itemize}

% see wikipedia page on history of web browser, pretty good,
% I have it printed.
%todo: my todo-browser/ somewhere

%todo:
%https://github.com/servo/servo/wiki/Relevant-spec-links

%good:
%http://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html

%todo: 
%http://www.html5rocks.com/en/tutorials/internals/howbrowserswork/

%todo: look at ocamlnet? more up to date web components?

\section{Getting started}

\section{Requirements}

\section{About this document}
#include "docs/latex/About.nw"

\section{Copyright}

Most of this document is actually source code from MMM, so
those parts are copyright by INRIA.
The prose is mine and is licensed under the GNU Free Documentation
License.

<<copyright header v6>>=
(***********************************************************************)
(*                                                                     *)
(*                           The V6 Engine                             *)
(*                                                                     *)
(*          Francois Rouaix, projet Cristal, INRIA Rocquencourt        *)
(*                                                                     *)
(*  Copyright 1996 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@

\section{Acknowledgments}

I would like to thank of course Francois Rouaix,
the main author of MMM.


\chapter{Overview}

\section{Web browser principles}

% before seing the browser, first expose web principles: world wide web.
% a "web" of interconnected machines with:
%  - html documents (and associated pictures sometimes)
%  - URL to reference a document, a document containing itself possible links
%    to other documents
%  - http protocol to fetch the document
%  - client/server around this protocol

% a web browser is then a special kind of interface on top of that:
% a navigator interface! (history, forward, click etc)

% see mmm-gdr-fr.ps


%"The main function of a browser is to present the web resource you
%choose, by requesting it from the server and displaying it in the
%browser window. The resource is usually an HTML document, but may also
%be a PDF, image, or some other type of content. The location of the
%resource is specified by the user using a URI (Uniform Resource
%Identifier)." HBW

\section{[[mmm]] services}




<<signature Version.about>>=
val about : string -> string   (* dialog *)
@
<<function Version.about>>=
(* dialog uses an gigantic font ! *)
let about = function
  | "iso8859" ->
"MMM Version 0." ^ version_number ^
"\nWritten by Fran\231ois Rouaix
Contributions by Jun P. Furuse and Jacques Garrigue
Ported to O'Caml 3 by Jun P. Furuse and Pierre Weis
\169 Copyright INRIA

Projet Cristal
INRIA Rocquencourt
Domaine de Voluceau
78153 Le Chesnay Cedex
France

Francois.Rouaix@inria.fr
http://pauillac.inria.fr/~rouaix/
"
  | "ja" -> "\027$B$b!A\027(B Version 0." ^ version_number ^
"\n\027$B:n<T\027(B: Fran\231ois Rouaix
\027$BF|K\\8l2=<T\027(B: \027$B8E@%\027(B \027$B=_\027(B
\027$B4sM?\027(B: \027$B2mMx2l\027(B \027$B<f6j\027(B
O'Caml 3 \027$B$X$N0\\?\"\027(B: \027$B8E@%\027(B \027$B=_!\"\027(B Pierre Weis
\169 Copyright INRIA

Projet Cristal
INRIA Rocquencourt
Domaine de Voluceau
78153 Le Chesnay Cedex
France

Francois.Rouaix@inria.fr
http://pauillac.inria.fr/~rouaix/

Jun.Furuse@inria.fr
http://pauillac.inria.fr/~furuse/
"
  | _ -> assert false
@


<<signature Version.http>>=
val http : string              (* the version in User-Agent field *)
@
<<constant Version.http>>=
(* User-Agent field *)
let http = "MMM/0." ^ string_of_int number
@



<<signature Version.number>>=
(* Version and other builtin strings *)
val number : int
@
<<constant Version.number>>=
(* Version *)
let number = 418
@

<<constant Version.version_number>>=
let version_number = 
  string_of_int number;;
@


\section{HTML document language}

\section{[[hello.html]]}

<<signature Version.html>>=
val html : string -> string    (* fake initial document *)
@
<<function Version.html>>=
let html = function
  | "iso8859" ->
"<HTML><HEAD><TITLE>MMM 0." ^ version_number ^ "</TITLE></HEAD>
<BODY>
<H1> The MMM navigator Version 0." ^ version_number ^ "</H1>
<H2 ALIGN=CENTER> Written by Fran\231ois Rouaix </H2>
<H2 ALIGN=CENTER> Contributions by Jun P. Furuse and Jacques Garrigue</H2>
<H3 ALIGN=CENTER> Port to O'Caml V3.0 by Jun P. Furuse and Pierre Weis</H3>
<H2 ALIGN=CENTER> \169 Copyright INRIA </H2>

<H4 ALIGN=CENTER> Using Objective Caml \169 Copyright INRIA </H4>
<H4 ALIGN=CENTER> And Tcl8.0/Tk8.0 (John Ousterhout and al.)<BR>
 \169 Copyright The Regents of the University of California<BR>
 and Sun Microsystems, Inc </H4>
<BLOCKQUOTE>
Please note that the software is a product currently being developed.
INRIA shall not be responsible in any way concerning conformity, and in
particular shall not be liable should the software not comply with the
requirements of the user, INRIA not being obliged to repair any
possible direct or indirect damage.
</BLOCKQUOTE>
<P>
The MMM home page is 
<A HREF=\"http://pauillac.inria.fr/mmm/\">here</A>,
and there is also some
<A HREF=\"http://pauillac.inria.fr/mmm/doc.html\">documentation</A>
and
<A HREF=\"http://pauillac.inria.fr/mmm/releases.html\">release notes</A>.
<BR>
Join the author by clicking
<A HREF=\"mailto:Francois.Rouaix@inria.fr\">here.</A>
<P>
<BLOCKQUOTE>
This document is included in your browser. Click on <TT>Reload</TT> to
get an updated copy.
</BLOCKQUOTE>
</BODY>
</HTML>
"
| "ja" -> "<HTML><HEAD><TITLE>MMM 0." ^ version_number ^ "</TITLE></HEAD>
<BODY>
<H1> \027$B%J%S%2!<%?\027(B \027$B$b!A\027(B Version 0." ^ version_number ^ "</H1>
<H2> \027$B:n<T\027(B \027$B!'\027(B Fran&ccedil;ois Rouaix </H2>
<H2> \027$BF|K\\8l2=<T\027(B \027$B!'\027(B \027$B8E@%\027(B \027$B=_\027(B </H2>
<H2> \027$B4sM?\027(B \027$B!'\027(B \027$B2mMx2l\027(B \027$B<f6j\027(B </H2>
<H2> O'Caml 3 \027$B$X$N0\\?\"\027(B: \027$B8E@%\027(B \027$B=_!\"\027(B Pierre Weis </H2>
<H2> &copy; Copyright INRIA (\027$BJ)9q9qN)>pJs<+F02=8&5f=j\027(B) </H2>

<H3> \027$B;HMQ%=%U%H%&%'%\"\027(B </H3>
<H3> Objective Caml &copy; Copyright INRIA </H3>
<H3> Tcl8.0/Tk8.0 (John Ousterhout and al.) &copy; Copyright The Regents of the University of California and Sun Microsystems, Inc </H3>
<BLOCKQUOTE>
\027$B$3$N%=%U%H%&%'%\"$K4X$7$F\027(BINRIA \027$B$O$$$+$J$k7A<0$N@UG$$bIi$$$^$;$s!#\027(B
\027$BFC$K!\"$3$N%=%U%H%&%'%\"$r%f!<%6!<$NI,MW$KJ;$;$k5AL3!\"\027(B
\027$B$^$?;HMQ$7$F@8$8$?$$$+$J$kD>@\\E*$^$?$O4V@\\E*Ho32$N@UG$$bIi$$$+$M$^$9!#\027(B
</BLOCKQUOTE>
<P>
\027$B$b!A$N%[!<%`%Z!<%8$O\027(B
<A HREF=\"http://pauillac.inria.fr/mmm/jmmm/\">\027$B$3$3\027(B</A>\027$B!\"\027(B
\027$B$b!A$N1Q8l$G=q$+$l$?%*%j%8%J%k$N%[!<%`%Z!<%8$O\027(B
<A HREF=\"http://pauillac.inria.fr/mmm/\">\027$B$3$3\027(B</A>\027$B$G$9!#\027(B
<BR>
\027$B6=L#$,$\"$kJ}$O\027(B
<A HREF=\"mailto:Jun.Furuse@inria.fr\">\027$B$3$3\027(B</A>
\027$B$r2!$7$F3+H/$K;22C$7$F2<$5$$!#\027(B
<P>
<BLOCKQUOTE>
\027$B$3$NJ8=q$O%V%i%&%6$KFbB\"$5$l$F$$$^$9!#\027(B<TT>\027$B:FFI\027(B</TT> \027$B$r2!$7$F0lHV?7$7$$J*$r<hF@$7$F2<$5$$!#\027(B
</BLOCKQUOTE>
</BODY>
</HTML>
"
  |  _ -> assert false
@
%$


\section{CSS style language}

\section{[[hello.css]]}

\section{Javascript dynamic language}

\section{[[hello.js]]}

\section{Code organization}

% commons/: utilities
% globals/: config
% www/: url
% html/: html format
% http/: protocol
% protocols/: more protocols
% retrieve/: fetching stuff
% viewers/: viewing embedded stuff
% display/: html display engine
% gui/: interface

% skipped for now: 
% i18n/japan/ 
% applets/ sandbox/ crcs/ 
% extensions/
% demos/ 

\section{Software architecture}


\section{Trace of a mouse click}

% see mmm-gdr-fr.ps
% mouse click -> fetch doc (async), wait server, header parsing, 
%  adequat viewer, 

%###############################################################################

\chapter{Core Data Structures}

\section{Request}

\subsection{URIs}
% =~ /path/elements/

<<type Uri.abs_uri>>=
(* URI utilities. RFC 1630 *)

type abs_uri = {
   uri_url : string;
   uri_frag : string option
 }
@
% frag?
% arg, uri_url, hmmm should be uri_path no?

<<signature Uri.is_absolute>>=
val is_absolute : string -> bool
   (* [is_absolute uri] determines if [uri] is absolute according to
      rules of RFC 1630 *)
@

<<function Uri.is_absolute>>=
(* RFC 1630, partial forms *)
let is_absolute uri =
  try
    let colonpos = String.index uri ':' in
    try 
      let slashpos = String.index uri '/' in
      colonpos < slashpos (* colon must occur before slash *)
    with
      Not_found -> true (* colon occurs before slash *)
  with
    Not_found -> false (* absolute must have a : *)
@

\subsection{URLs and protocols}
% =~ protocol://host@user:port/paths?search

<<type Url.t>>=
(* URLs as defined by RFC 1738 *)

(* Relative adressing in anchors, fragments are NOT URLs, but URI *)
(* Not all components are used for all protocols. See RFC. *)
type t = 
  { mutable protocol : protocol;

    mutable user : string option;
    mutable password: string option;

    mutable host : string option;
    mutable port : int option;

    mutable path : string option;

    mutable search: string option
  }
@
% search?

<<type Url.protocol>>=
type protocol =
 | HTTP 
 | FILE | MAILTO | FTP | NNTP
 | TELNET 
 | GOPHER | NEWS | WAIS | PROSPERO
 | OtherProtocol of string
@


<<signature Url.distant_path>>=
(* For http. The thing we have to send in the request *)
val distant_path : t -> string
@

<<function Url.distant_path>>=
(* For http only *)
let distant_path urlp =
  match urlp.path, urlp.search with
     None, None -> "/"
   | Some p, None -> "/"^p
   | Some p, Some s -> "/"^p^"?"^s
   | None, Some s -> "/?" ^ s (* ??? *)
@

\subsection{Hypertext Links}
%=~ <a href="...">

<<type Hyper.link>>=
(* An hypertext(media) link on the Web *)
type link = {
  h_uri : string;
  h_context: string option;

  h_method : link_method;		(* default is GET *)
  h_params : (string * string) list
  }
@
% context?
% why not parse h_uri? and make it a Url.t?

<<type Hyper.link_method>>=
(* This is currently for HTTP and derived, but ... *)
(* Contains only the one we support *)
type link_method =
   GET 
 | HEAD
 | POST of string
@

\subsection{Request}
% =~ ?

<<type Www.request>>=
(*
 * Requests
 *)

type request =  { 
    www_link : Hyper.link;        (* the link that produced this request *)
    www_url : Url.t;	          (* parsed version *)
    www_fragment : string option; (* because viewer is passed down *)

    mutable www_auth : (string * string) list;  (* basic auth *)
    mutable www_headers : string list;		  (* additional headers *)

    mutable www_logging : string -> unit;	  (* logging *)
    mutable www_error : Error.t
  }
@
%less: merge www_url in link?
%less: fragment??

<<signature Www.make>>=
val make : Hyper.link -> request
  (* raises: 
      Url_Lexing
      Invalid_link
   *)
@


<<constant Www.sp>>=
let sp = Str.regexp "[ \t\n]"
@

<<function Www.make>>=
let make hlink =
  let absuri = Hyper.resolve hlink in 
  let url = Lexurl.make absuri.uri_url in
  try (* search for space in network URI *)
    if List.mem url.protocol [FILE; MAILTO] then raise Not_found
    else
      let n = Str.search_forward sp absuri.uri_url 0 in
      raise (Hyper.Invalid_link (Hyper.UrlLexing ("suspicious white space", n)))
  with
    Not_found -> {
      www_link = hlink;
      www_url = url; (* should not fail ? *)
      www_fragment = absuri.uri_frag;
      www_auth = [];
      www_headers = [];
      www_logging = (fun _ -> ());
      www_error = !Error.default
    }
@


\section{Document}

<<type Document.document_id>>=
(* Document Id is a reference to a document in the browser.
   For some documents, e.g. results of POST queries, the URL is not a
   sufficient description. Stamp is 0 for unique documents.
*)
type document_id = {
  document_url : Url.t;
  document_stamp : int
  }
@

<<signature Document.no_stamp>>=
val no_stamp : int
@

<<signature Document.new_stamp>>=
val new_stamp : unit -> int
@


<<constant Document.stamp_counter>>=
let stamp_counter = ref 0
@

<<constant Document.no_stamp>>=
let no_stamp = 0
@

<<function Document.new_stamp>>=
let new_stamp () =
  incr stamp_counter; !stamp_counter
@


<<signature Document.document_id>>=
val document_id : Www.request -> document_id
@

<<function Document.document_id>>=
let document_id wwwr =
  match wwwr.www_link.h_method with
    POST _  ->
        { document_url = wwwr.www_url; document_stamp = new_stamp()}
  | _ -> { document_url = wwwr.www_url; document_stamp = no_stamp}
@




<<module Document.DocumentIDSet>>=
module DocumentIDSet =
  Set.Make(struct type t = document_id let compare = compare end)
@

<<type Document.handle>>=
(* This is passed around by request continuations. It represents a handle
   on a connexion for retrieving a document *)
type handle = {
  document_id : document_id;
  document_referer : string option;
    (* URL of refering document, if any *)
  mutable document_status : int;
    (* Status code of response *)
  mutable document_headers : string list;
    (* HTTP headers of document, or faked ones *)
  document_feed : Feed.t;
    (* where to get the data *)
  document_fragment : string option;
    (* fragment (#foo) if any *)
  mutable document_logger : logger
    (* how to log information relative to this document processing *)
}
@

% important one
<<type Document.document_continuation>>=
type document_continuation = {
  document_process : handle -> unit;
    (* What to do one we have a dh on the real document *)
  document_finish :  bool -> unit
    (* What to do if a request does not yield a document *)
}
@


\section{DOM}

%https://dom.spec.whatwg.org/

\section{Abstract syntax trees}

% html
% css
% js

\subsection{HTML}

%https://html.spec.whatwg.org/multipage/introduction.html#a-quick-introduction-to-html

<<type Html.tag>>=
type tag = {
  tag_name : string;
  attributes: attributes
}
@

<<type Html.attributes>>=
type attributes = (attribute_name * attribute_value) list
@

<<type Html.attribute_name>>=
(* HTML tokens *)
type attribute_name = string 
@
<<type Html.attribute_value>>=
type attribute_value = string
@


%todo: where is the tree? the full AST?




<<constant Html.default_attributes>>=
(* Attribute values *)
let default_attributes = [ 
  ("isindex", "prompt"), "Document is indexed/searchable: ";
  ("a", "methods"), "GET";              (* <A METHODS=GET> *)
  ("ol", "type"), "1";			(* <OL TYPE=1 *)
  ("embed", "methods"), "GET";		(* <EMBED METHODS=GET> *)
  ("embed", "alt"), "[EMBEDDED OBJECT]";(* <EMBED ALT="EMBEDDED OBJECT"> *)
  ("form", "method"), "GET";		(* <FORM METHOD=GET> *)
  ("form", "enctype"), "application/x-www-form-urlencoded";
  ("input", "type"), "TEXT";		(* <INPUT TYPE=TEXT> *)
  ("select", "size"), "5";
  ("textarea", "align"), "bottom";
  ("input", "align"), "bottom";
  ("select", "align"), "bottom";
  ("img", "align"), "bottom";
  (* ("img", "alt"), "[IMAGE]"; *) (* Just "IMAGE" ? Boring... *)
  ("area", "shape"), "rect";
  ("div", "align"), "left";
  ("basefont", "size"), "3";
  (* frames *)
  ("frame", "frameborder"), "0";
  ("frame", "scrolling"), "auto";
  ("frameset", "rows"), "100%";
  ("frameset", "cols"), "100%";
  ]
@


<<signature Html.get_entity>>=
val get_entity : string -> string
  (* [get_entity "amp"] returns "&" *)
@

<<constant Html.get_entity>>=
let get_entity = Hashtbl.find ampersand_table
@



<<signature Html.get_attribute>>=
val get_attribute : tag -> string -> string
  (* [get_attribute tag attrib_name] *)
@

<<signature Html.has_attribute>>=
val has_attribute : tag -> string -> bool
  (* [has_attribute tag attrib_name] *)
@


<<function Html.get_attribute>>=
let get_attribute tag attr =
  try
    List.assoc attr tag.attributes 
  with
    Not_found ->
     List.assoc (tag.tag_name, attr) default_attributes
@

<<function Html.has_attribute>>=
let has_attribute tag attr =
     List.mem_assoc attr tag.attributes
  || List.mem_assoc (tag.tag_name, attr) default_attributes
@


\subsection{CSS}

\subsection{Javascript}

\section{Protocols}

<<constant Protos.protos>>=
let protos = Hashtbl.create 11
@

<<constant Protos.get>>=
let get = Hashtbl.find protos
@

%will see code like:
%<<toplevel Protos._2>>=
%let _ = Hashtbl.add protos HTTP (Http.req, Cache.tobuffer)
%@



\section{HTTP}
% 1.0.
% 2.0 just got published recently


<<type Messages.request>>=
(* Request-Line of a Request *)
type request = {
  request_version: string;	(* HTTP/1.0 *)
  request_method : string;	(* GET, POST, etc... *)
  request_uri : string		(* the uri *)
  }
@

<<type Messages.status>>=
(* Status-Line of a Response *)
type status =  { 
    status_version : string;	(* HTTP/1.0 *)
    status_code : int;		(* http return codes *)
    status_message : string	(* http return message *)
 }
@

<<type Messages.header>>=
(* Other headers *)
type header = string
@

%(* HTTP messages: requests and responses
% *  What a client sends to a server is called a request 
% *  What a server answers is called a response
% *)

<<type Messages.request_message>>=
(* HTTP-Message *)
type request_message = {
  request : request;
  request_headers : header list;
  request_body : string;
  request_auth : (string * string) option 
           (* have we authentified the emitter (authtype, authuser) *)
  }
@

<<type Messages.response_message>>=
type response_message = {
  status : status;
  response_headers : header list;
  response_body : string        (* responde body is *not* the document body *)
  }
@


\chapter{[[main()]]}


<<function Main.main>>=
let main () =

  Error.default := new Tk_error.t Widget.default_toplevel;
  Condition.backend := Tk_condition.backend ();
  Low.timer_add_backend := (fun a b -> Timer.add a b |> ignore);
  Low.update_idletasks_backend := Tk.update_idletasks;
  File_event.add_fileinput_ref := Fileevent.add_fileinput;
  File_event.remove_fileinput_ref := Fileevent.remove_fileinput;
  File_event.add_fileoutput_ref := Fileevent.add_fileoutput;
  File_event.remove_fileoutput_ref := Fileevent.remove_fileoutput;

 (* As always, we must parse argument first, using references... *)
  let sufxfile = ref (Mmm.user_file "mime.types")
  and display = ref (try Sys.getenv("DISPLAY") with Not_found -> "")
  and preffile = ref (Mmm.user_file "MMM.ad")
  and init_urls = ref [] 
  and accept_external = ref false
  and palette = ref None
  and modules = ref true
  and clicktofocus = ref false
  in
  Arg.parse [
  "-proxy", Arg.String (fun s -> Http.proxy := s), 
  "<hostname>\tProxy host";
  "-port", Arg.Int (fun i -> Http.proxy_port := i),
  "<port>\t\tProxy port";
  "-d", Arg.String (fun s -> display := s),
  "<foo:0>\t\tDisplay";
  "-display", Arg.String (fun s -> display := s),
  "<foo:0>\tDisplay";
  "-suffixes", Arg.String (fun s -> sufxfile := s),
  "<file>\tSuffix file";
  "-external", Arg.Unit (fun () -> accept_external := true),
  "\t\tAccept remote command (mmm_remote <url>)";
  "-lang", Arg.String (fun s -> I18n.language := s),
  "<lang>\t\tI18n language";
  "-msgfile", Arg.String (fun s -> I18n.message_file := s),
  "<file>\tI18n message file";
  "-prefs", Arg.String (fun s -> preffile := s),
  "<file>\t\tPreference File";
  "-helpurl", Arg.String (fun s -> Mmm.helpurl := Lexurl.make s),
  "<url>\tHelp URL";
  "-palette", Arg.String (fun s -> palette := Some s),
  "<color>\tTk Palette";
  "-nomodule", Arg.Unit (fun () -> modules := false),
  "\t\tDon't load initial modules";
  "-clicktofocus", Arg.Unit (fun () -> clicktofocus := true),
  "\tClick to Focus mode (default is Focus Follows Mouse)";
  "-geometry", Arg.String (fun s -> Mmm.initial_geom := Some s),
  "<wxh+x+y>\tInitial geometry for the first navigator"
  ]
    (fun s -> init_urls := s :: !init_urls)
    "Usage: meuh <opts> <initial url>";

  Sys.catch_break true;
  (* Avoid SIGPIPE completely, in favor of write() errors *)
  Sys.set_signal Sys.sigpipe Sys.Signal_ignore;

  let top = Tk.openTkDisplayClass !display "mmm" in

  (* Just after the init. of Tk, we have to detect the Tk is under
   * Latin or Japanese mode at first. 
   *)
  Lang.japan := Jtk.is_japanese_mode () && Lang.is_japanese ();
  (* Run Tcl in JIS (ISO2022-jp) Mode *)
  if !Lang.japan 
  then Jtk.Kanji.internal_code_set Jtk.JIS;

  Wm.withdraw top;
  
  if not !clicktofocus 
  then Focus.follows_mouse();

  (* Default values for navigator window *)
  Resource.add "*MMM.Width" "640" Tk.WidgetDefault;
  Resource.add "*MMM.Height" "480" Tk.WidgetDefault;

  (* Resources *)
  let site_resfile =
    localize (Filename.concat (Filename.dirname Sys.argv.(0)) "MMM.ad") in
  (* Site specific resource file usually in $INSTALLDIR=/usr/local/lib/mmm *)
  if Sys.file_exists site_resfile 
  then Tkresource.readfile site_resfile Tk.StartupFile;

  begin match !palette with
  | None -> ()
  | Some bg -> try Palette.set_background (Tk.NamedColor bg) with _ -> ()
  end;

  (* Initialisations in frx library : kbd navigation, search 
   * No prerequisite except Tk *)
  Frx_text.init ();
  (* Initialisations in jpf's balloon library *)
  Balloon.init ();
  (* Initialisations in jpf's GIF ANIMATION library *)
  Tkaniminit.f ();

  (* Local initialisations *)
  Low.init();                         (* start regular tasks *)
  Cache.init();                       (* builtin document *)
  Auth.init();                        (* start expiration timer *)
  Debug.init();                       (* debugging RPC *)
  
  (* Suffix mapping to Content-Type and Content-Encoding *)
  if Sys.file_exists !sufxfile 
  then Http_headers.read_suffix_file !sufxfile;
  
  (* Various stuff for the HTML viewer, needing Tk *)
  Ctext.init();
  Attrs.init !Textw_fo.html_bg; (* built the bullet images *)

  (* Initialization of HTML entities *)
  Html.init !Lang.japan;

  (* The applet system.
   * This loads the local modules also, so any setup that might be
   * overriden by a local module should happen before here.
   * However, preference initialisation must happen *after* initialisation
   * of the applet system
   *)
  !Version.applet_init !modules;

  (* This must occur after most initialisations *)
  if !accept_external 
  then Cci.init();

  (* Start the initial navigator *)
  ignore
    (Mmm.initial_navigator 
        (localize !preffile)
        (match !init_urls with | [] -> None | x :: l -> Some x));
  safe_loop();
  if !Log.debug_mode then begin
    Cache.postmortem();
    Gcache.postmortem()
  end
@
%$

<<function Main.safe_loop>>=
let rec safe_loop() =
  try
    Printexc.print Tk.mainLoop () (* prints and reraises *)
  with
  | Out_of_memory -> raise Out_of_memory
  | Sys.Break -> raise Sys.Break
  | Stack_overflow -> raise Stack_overflow
  | e -> 
      flush Pervasives.stderr; 
      safe_loop()
@




<<toplevel Main._1>>=
let _ = 
  Printexc.catch postmortem ()
@

<<function Main.postmortem>>=
let postmortem () =
  try 
    main ()
  with
  | Dynlink.Error err ->
      failwith (spf "dynlink error = %s" (Dynlink.error_message err))
  | e -> 
      if !Log.debug_mode then begin
        Cache.postmortem();
        Gcache.postmortem();
      end;
      raise e
@


\section{XXX}
<<signature Version.initurl>>=
val initurl : string -> string (* fake initial url *)
@

<<signature Version.helpurl>>=
val helpurl : string -> string (* help url *)
@



<<function Version.initurl>>=
(* MUST BE NORMALIZED *)
let initurl = function
  | "iso8859" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/v%d/about.html" number
  | "ja" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/jmmm/v%d/about.html"
    number
  | _ -> assert false
@

<<function Version.helpurl>>=
let helpurl = function
  | "iso8859" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/v%d/docindex.html" number
  | "ja" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/v%d/docindex-ja.html"
    number
  | _ -> assert false
@

\section{[[Html.init()]]}

<<signature Html.init>>=
val init : bool -> unit 
@

<<function Html.init>>=
let init japan =
  List.iter (fun (str, c) -> Hashtbl.add ampersand_table str c) 
    (if japan then latin1_japan else latin1_normal) 
@

\section{Preferences}

\section{The event loop}

\subsection{[[Glevents]]}

<<signature Glevents.get>>=
val get : string -> (modifier list * xEvent) list 
@

<<signature Glevents.reset>>=
val reset : unit -> unit
@

<<constant Glevents.events>>=
(* A global table for describing events
 * TODO: use virtual events because here we don't change bindings in 
 * place after a preference reload
 *)

let events = Hashtbl.create 37
@

<<constant Glevents.builtin_defaults>>=
let builtin_defaults = [

  (* tachymeter bindings *)
  "tachy_about", [[], ButtonPressDetail 3];
  "tachy_gc",[[], KeyPressDetail "g"; [], KeyPressDetail "c"];
  "tachy_new", [[], ButtonPressDetail 1];
  "tachy_sel", [[], ButtonPressDetail 2];

  (* bindings on inlined images *)
  "loadimage", [[Control], ButtonPressDetail 1];
  "alt_imap", [[],ButtonPressDetail 1];	(* alt mode client side img map *)
  "stopanim",  [[], ButtonPressDetail 2];
  "restartanim", [[Shift], ButtonPressDetail 2];
  "copyimgurl", [[], ButtonPressDetail 2];
  "updateimage", [[Shift], ButtonPressDetail 2];

  (* anchor bindings *)
  "goto", [[], ButtonPressDetail 1];
  "save", [[Shift], ButtonPressDetail 1];
  "gotonew", [[], ButtonPressDetail 3];
  "hypermenu", [[Control], ButtonPressDetail 1];
]
@
% ???

<<constant Glevents.get>>=
let get = Hashtbl.find events
@

<<function Glevents.reset>>=
(* This is for preferences *)
let reset () =
  Hashtbl.clear events;
  (* Now: for all names defined in defaults, check a possible overriding value
     in resources *)
  List.iter (fun (name,default) ->
    Hashtbl.add events 
      name (Tkresource.event_sequence (sprintf "bind<%s>" name) default))
    builtin_defaults
@


\chapter{Navigator Interface}
% The chrome
% gui/

\section{Address bar}

\section{Back and forward}

\section{Refresh and stop}

\section{Home}

<<signature Version.home>>=
val home : string -> string    (* MMM home page *)
@

<<function Version.home>>=
let home = function 
  | "iso8859" -> "http://pauillac.inria.fr/mmm/"
  | "ja" -> "http://pauillac.inria.fr/mmm/jmmm/"
  | _ -> assert false
@

\section{Bookmarks}

\section{History}

\chapter{Parsing}
% www/ html/ 

\section{URLs}

<<signature Lexurl.f>>=
val f : Lexing.lexbuf -> Url.t
@

<<signature Lexurl.make>>=
val make : string -> Url.t
   (* raise Url_Lexing(msg,pos) *)
@

<<signature Lexurl.maken>>=
val maken : string -> Url.t
   (* raise Url_Lexing(msg,pos) *)
@
% diff?




%todo: lexurl.mll?

\subsection{Paths}

<<signature Lexpath.path_components>>=
(* Path lexer
   Deals with "./" and "../"
 *)

val path_components : Lexing.lexbuf -> string list
  (* in normal order: /a/b/c/ -> [a;b;c] *)
@

<<signature Lexpath.rev_path_components>>=
val rev_path_components : Lexing.lexbuf -> string list
  (* in reverse order: /a/b/c/ -> [c;b;a] *)
@

<<signature Lexpath.build>>=
val build : string -> string list -> string
  (* [build root [a;b;d]] returns path/a/b/c *)
@

<<signature Lexpath.remove_dots>>=
val remove_dots : string -> string
  (* takes path and removes . and .. *)
@

\subsection{Encoding}
% unparsing? escaping?

<<signature Urlenc.decode>>=
(* URL encoding *)

val decode : string -> string
@

<<signature Urlenc.encode>>=
val encode : string -> string
    (* encoding and decoding for an arbitrary string *)
@

<<signature Urlenc.strict_form_standard>>=
val strict_form_standard : bool ref
    (* if true, we take RFC1866 8.2.1 case 1 strictly, and encode any 
       non-alphanumeric character in the field name
       else, we encode only values, but not field names *)
@

<<signature Urlenc.form_encode>>=
val form_encode : (string * string) list -> string
@

<<signature Urlenc.form_decode>>=
val form_decode : string -> (string * string) list
    (* application/x-www-form-urlencoded encoding *)
@

<<signature Urlenc.unquote>>=
(*-*)
val unquote : string -> string
@


<<function Urlenc.hexchar>>=
let hexchar c = 
  let s = String.make 3 '%'
  and i = Char.code c in
  s.[1] <- dec_to_hex (i/16);
  s.[2] <- dec_to_hex (i mod 16);
  s
@

<<function Urlenc.decode>>=
(* Decode escaped characters *)
(* Note: beware of order of splitting wrt '&' and decoding *)
let decode s =
  let l = String.length s in
  let target = Ebuffer.create l in
  let pos = ref 0 in
  while !pos < l do
    if s.[!pos] = '%' & !pos + 2 < l  then begin
      let c = 16 * hex_to_dec s.[!pos+1] + hex_to_dec s.[!pos+2] in
       Ebuffer.output_char target (Char.chr c);
    pos := !pos + 3
    end
    else if s.[!pos] = '+' then begin
      Ebuffer.output_char target ' ';
      incr pos
      end
    else begin
      Ebuffer.output_char target s.[!pos];
      incr pos
      end
  done;
  Ebuffer.get target
@

<<constant Urlenc.keep_quoted>>=
(* Unquote an url path:
   We decode all % except those corresponding to significative
   characters for parsing: /, ?, #, sp, :
 *)
let keep_quoted = 
  ['/'; '?'; '#'; ' '; '\t'; '\r'; '\n'; ':'; '%'; '&'; '='; '+']
@

<<function Urlenc.unquote>>=
let unquote s =
  try
    (* optim *)
    let _ = String.index s '%' in
    let l = String.length s in
    let target = Ebuffer.create l in
    let pos = ref 0 in
    try
      while !pos < l do
    let perpos = String.index_from s !pos '%' in
    if perpos > !pos then Ebuffer.output target s !pos (perpos - !pos);
    pos := perpos;
       if s.[!pos] = '%' & !pos + 2 < l  then begin
         let c = 16 * hex_to_dec s.[!pos+1] + hex_to_dec s.[!pos+2] in
      let substc = Char.chr c in
      if List.mem substc keep_quoted then
        for i = 0 to 2 do
             Ebuffer.output_char target s.[!pos];
             incr pos
          done
          else begin
             Ebuffer.output_char target (Char.chr c);
          pos := !pos + 3
       end
     end
     else begin
        Ebuffer.output_char target s.[!pos];
        incr pos
     end
      done;
      Ebuffer.get target
    with
      Not_found -> (* no more substitutions *)
    Ebuffer.output target s !pos (l - !pos);
    Ebuffer.get target
  with
    Not_found -> s
@

<<function Urlenc.encode>>=
let encode s =
  let target = Ebuffer.create (String.length s) in
  for pos = 0 to String.length s - 1 do
    match s.[pos] with
      ' ' -> Ebuffer.output_char target '+'
    | '0'..'9' | 'a'..'z' | 'A'..'Z' as c -> Ebuffer.output_char target c
    | '\n' -> Ebuffer.output_string target "%0D%0A"
    | c -> Ebuffer.output_string target (hexchar c)
    done;
  Ebuffer.get target
@

<<constant Urlenc.strict_form_standard>>=
let strict_form_standard = ref true
@

<<function Urlenc.form_encode>>=
let form_encode = function 
  [] -> ""
 | (e,v)::l ->
  let b = Ebuffer.create 512 in
    Ebuffer.reset b;
    Ebuffer.output_string b (encode e);
    Ebuffer.output_char b '=';
    Ebuffer.output_string b (encode v);
    List.iter (fun (e,v) ->
         Ebuffer.output_char b '&';
         Ebuffer.output_string b (
                   if !strict_form_standard then encode e
           else e);
         Ebuffer.output_char b '=';
         Ebuffer.output_string b (encode v))
             l;
    Ebuffer.get b
@

<<constant Urlenc.form_decode>>=
let form_decode =
  let ampersand c = c = '&' and equals c = c = '=' in
  (function  s ->
     List.map (fun encp ->
       match split_str equals encp with
       [x;y] -> (decode x, decode y)
     | [x] -> (decode x, "")
     | _ -> invalid_arg "form_decode")
       (split_str ampersand s))
@

\subsection{Links}

<<signature Hyper.parse_method>>=
val parse_method : string -> link_method
@

<<function Hyper.parse_method>>=
let parse_method = function
   "GET" -> GET
 | "HEAD" -> HEAD
 | "POST" -> POST ""
 | _ -> raise Not_found (* other cases should be caught by caller ! *)
@






<<signature Hyper.urlconcat>>=
val urlconcat: Url.t -> string -> string
   (* [urlconcat url relurl] resolves the relative URL [relurl] in the
       context of the URL [url]
      Doesn't handle fragments
    *)
@

<<signature Hyper.resolve>>=
val resolve : link -> Uri.abs_uri
  (* raises Invalid_link(msg) *)
@


<<function Hyper.urlconcat>>=
(* parsed Absolute URL + URL -> Absolute URL *)
(* NO FRAGMENT HANDLING *)

let urlconcat contextp newuri =
  let l = String.length newuri in 
    if l = 0 then string_of contextp 
    else if l > 2 & newuri.[0] = '/' & newuri.[1] = '/' then
      (* this is probably a gopher relative uri *)
      sprintf "%s:%s" (string_of_protocol contextp.protocol) newuri
    else if newuri.[0] = '/' then (* start from root *)
      string_of {
        protocol = contextp.protocol;
     user = contextp.user;
     password = contextp.password;
        host = contextp.host;
        port = contextp.port;
     path = Some (Urlenc.unquote 
                (String.sub newuri 1 (String.length newuri - 1)));
     search = None }
    else if newuri.[0] = '?' then (* change only search part *)
      string_of {
        protocol = contextp.protocol;
     user = contextp.user;
     password = contextp.password;
        host = contextp.host;
        port = contextp.port;
     path = contextp.path;
     search = Some (String.sub newuri 1 (String.length newuri - 1))}
    else 
      let pathpart,searchpart =
    try
      let n = String.index newuri '?' in
      String.sub newuri 0 n,
      Some (String.sub newuri (n+1) (l - n - 1))
    with
      Not_found -> newuri, None
      in
      match contextp.path with
      None | Some "" -> 
        string_of {
        protocol = contextp.protocol;
        user = contextp.user;
        password = contextp.password;
        host = contextp.host;
        port = contextp.port;
        path = Some (Urlenc.unquote (Lexurl.remove_dots pathpart));
        search = searchpart}
    | Some old ->
        (* only the "dirname" part of the context path is important *)
        (* e.g  .../d/e/f becomes /d/e/ *)
       let path = sprintf "%s/%s" (Filename.dirname old) pathpart in
        (* we then have to remove dots *)
    let reduced = Lexurl.remove_dots path in
        string_of {
        protocol = contextp.protocol;
        user = contextp.user;
        password = contextp.password;
        host = contextp.host;
        port = contextp.port;
        path = Some (Urlenc.unquote reduced);
        search = searchpart}
@

<<function Hyper.resolve>>=
(* Produces an URL *)
let resolve link =
  (* First remove the possible fragment of the uri *)
  let newuri, frag =
    try
      let pos = String.index link.h_uri '#' in
       String.sub link.h_uri 0 pos, 
        Some (String.sub link.h_uri (succ pos) 
                    (String.length link.h_uri - pos - 1))
    with
        Not_found -> link.h_uri, None 
  in
  if Uri.is_absolute newuri then
    try
     {uri_url = Lexurl.normalize newuri;
      uri_frag = frag}
    with
      Url_Lexing _ ->
    raise (Invalid_link
              (LinkResolve (I18n.sprintf "not a legal absolute uri")))

  else begin (* It is a relative uri *)
    let context =
      match link.h_context with 
     None -> 
      raise (Invalid_link (LinkResolve (I18n.sprintf 
                  "no context and not an absolute url")))
       | Some c -> c in

    let contextp = 
       try Lexurl.maken context
       with
    Url_Lexing (err,pos) ->
     raise (Invalid_link (UrlLexing (err,pos)))
       in
    {uri_url = urlconcat contextp newuri;
     uri_frag = frag}
     end
@


\subsection{Normalization}

<<signature Lexurl.remove_dots>>=
val remove_dots : string -> string
@
<<signature Lexurl.normalize>>=
val normalize : string -> string
@


\section{HTML}

%https://html.spec.whatwg.org/multipage/syntax.html#parsing


\subsection{Lexing}

<<type Html.token>>=
type token =
   PCData of string
 | CData of string

 | OpenTag of tag
 | CloseTag of string

 | Comment of string
 | Doctype of string
 | EOF
@
% need doctype?

<<type Html.location>>=
type location = Loc of int * int
@

% lexhtml.mll


<<signature Lexhtml.html>>=
val html : Lexing.lexbuf -> t -> warnings * Html.token * Html.location
@

<<type Lexhtml.warnings>>=
type warnings = (string * int) list
@




<<signature Lexhtml.strict>>=
val strict : bool ref
    (* if true, use strict parsing; else, activate leniency on some
       lexing decisisons such as: comments, attribute names and values
     *)
@


<<signature Lexhtml.new_data>>=
val new_data : unit -> t
    (* instance data for a lexer; must be allocated for each instance, in
       order to get reentrant lexers
     *)
@



<<signature Lexhtml.cdata>>=
val cdata : Lexing.lexbuf -> t -> warnings * Html.token * Html.location
@

\subsubsection{Comments}

\subsubsection{Escaped characters}

\subsubsection{Doctype}


\subsection{Parsing, the DTD}

% for 3.2
% html 4.0 and 5.0 has been published
% TODO: add 4.0 with span element

<<signature module Dtd.Elements>>=
module Elements : Set.S with type elt = string
@

<<module Dtd.elements>>=
module Elements = Set.Make(struct type t = string let compare = compare end)
@

<<type Dtd.t>>=
type t = {
  dtd_name : string;
  contents : (string, Elements.t) Hashtbl.t;
    (* for each element, give the set of included elements *)

  mutable open_omitted : Elements.t;
    (* set of elements for which opening tag may be omitted *)
  mutable close_omitted : Elements.t
    (* set of elements for which closing tag may be omitted *)
 } 
@

<<signature Dtd.dtd32>>=
val dtd32 : t
@

<<signature Dtd.name>>=
val name : t -> string
@
<<function Dtd.name>>=
let name t = 
  t.dtd_name
@


<<function Dtd.sol>>=
(* Utils *)
let sol l =
  List.fold_right Elements.add l Elements.empty
@

<<function Dtd.sos>>=
let sos l =
  List.fold_right Elements.union l Elements.empty
@



%(* #PCDATA and #CDATA are considered as elements, but they will never
%   be pushed on the stack during evaluation. Moreover, since they are
%   not in open_omitted/close_omitted, minimization algorithm will not
%   attempt to choose them
% *)

%todo: copy the comments made on dtd20 to dtd32
% and adapt to latest dtd of html5?
<<constant Dtd.dtd32>>=
let dtd32 =
  let dtd = {
    dtd_name = "HTML 3.2";
    contents = Hashtbl.create 53;
    open_omitted = Elements.empty;
    close_omitted = Elements.empty
     } in
  let omit_open el =
    dtd.open_omitted <- Elements.add el dtd.open_omitted
  and omit_close el =
    dtd.close_omitted <- Elements.add el dtd.close_omitted
  and add_elem = Hashtbl.add dtd.contents
  in

  let head_misc_E = sol ["script"; "style"; "meta"; "link"]
  and heading_E = sol ["h1"; "h2"; "h3"; "h4"; "h5"; "h6"]
  and list_E = sol ["ul"; "ol"; "dir"; "menu"]
  and preformatted_E = sol ["pre"; "xmp"; "listing"]
  and font_E =
     sol ["tt"; "i"; "b"; "u"; "strike"; "big"; "small"; "sub"; "sup"]
  and phrase_E =
     sol ["em"; "strong"; "dfn"; "code"; "samp"; "kbd"; "var"; "cite"]
  and special_E =
     sol ["a"; "img"; "applet"; "font"; "basefont"; "br"; "script"; "map"]
  and form_E =
     sol ["input"; "select"; "textarea"]
  in
  (* EMBED is not in the original DTD ! *)
  let text_E =
     sos [sol ["#pcdata"; "embed"]; font_E; phrase_E; special_E; form_E]
  in
  Elements.iter (fun e -> add_elem e text_E) font_E;
  Elements.iter (fun e -> add_elem e text_E) phrase_E;
  add_elem "font" text_E;
  add_elem "basefont" Elements.empty;
  omit_close "basefont";
  add_elem "br" Elements.empty;
  omit_close "br";

  let block_E =
    sos [sol ["p"; "dl"; "div"; "center"; "blockquote"; "form"; "isindex";
              "hr"; "table"];
         list_E; preformatted_E]
  in
  let flow_E = sos [text_E; block_E]
  in
  let body_content_E = sos [sol ["address"]; heading_E; text_E; block_E]
  in
  add_elem "body" body_content_E;
  omit_open "body";
  omit_close "body";

  let address_content_E = sos [sol ["p"]; text_E] in
  add_elem "address" address_content_E;
  
  add_elem "div" body_content_E;
  add_elem "center" body_content_E;

  add_elem "a" (Elements.remove "a" text_E);
  
  add_elem "map" (sol ["area"]);
  add_elem "area" Elements.empty;
  omit_close "area";

  add_elem "link" Elements.empty;
  omit_close "link";
   
  add_elem "img" Elements.empty;
  omit_close "img";

  add_elem "applet" (Elements.add "param" text_E);
  add_elem "param" Elements.empty;
  omit_close "param";

  add_elem "hr" Elements.empty;
  omit_close "hr";

  add_elem "p" text_E;
  omit_close "p";

  Elements.iter (fun e -> add_elem e text_E) heading_E;

  let pre_exclusion_E = sol ["img"; "big"; "small"; "sub"; "sup"; "font"]
  in
  add_elem "pre" (Elements.diff text_E pre_exclusion_E);

  List.iter (fun e -> add_elem e (sol ["#cdata"])) ["xmp"; "listing"];

  add_elem "blockquote" body_content_E;

  add_elem "dl" (sol ["dt"; "dd"]);
  add_elem "dt" text_E; omit_close "dt";
  add_elem "dd" flow_E; omit_close "dd";

  List.iter (fun e -> add_elem e (sol ["li"])) ["ol"; "ul"];
  List.iter (fun e -> add_elem e (sol ["li"])) ["dir"; "menu"];

  add_elem "li" flow_E;
  omit_close "li";


  add_elem "form" (Elements.remove "form" body_content_E);
  add_elem "input" Elements.empty;
  omit_close "input";
  add_elem "select" (sol ["option"]);
  add_elem "option" (sol ["#pcdata"]);
  omit_close "option";
  add_elem "textarea" (sol ["#pcdata"]);


  add_elem "table" (sol ["caption"; "tr"]);
  add_elem "tr" (sol ["th"; "td"]);
  omit_close "tr";
  List.iter (fun e -> add_elem e body_content_E; omit_close e) ["th"; "td"];
  add_elem "caption" text_E;


  let head_content_E = sol ["title"; "isindex"; "base"]
  in

  add_elem "head" (Elements.union head_content_E head_misc_E);
  omit_close "head";
  omit_open "head";

  add_elem "title" (sol ["#pcdata"]);
  add_elem "isindex" Elements.empty;
  omit_close "isindex";
  add_elem "base" Elements.empty;
  omit_close "base";
  add_elem "meta" Elements.empty;
  omit_close "meta";

  add_elem "script" (sol ["#cdata"]);
  add_elem "style" (sol ["#cdata"]);

  let html_content_E = sol ["head"; "body"] in

  add_elem "html" html_content_E;
  omit_open "html";
  omit_close "html";

  (* fake element PCDATA for minimisation rules *)
  add_elem "#pcdata" Elements.empty;

  (* embed is an extension *)
  add_elem "embed" Elements.empty;
  omit_close "embed";

  dtd
@



<<constant Dtd.table>>=
let table = Hashtbl.create 11
@

<<signature Dtd.add>>=
val add : t -> unit
@

<<signature Dtd.get>>=
(* A table of DTDs for preferences *)
val get : string -> t
@

<<signature Dtd.names>>=
val names : unit -> string list
@

<<signature Dtd.current>>=
val current : t ref 
@
<<constant Dtd.current>>=
let current = ref dtd32
@



<<function Dtd.add>>=
let add t = 
  Hashtbl.add table t.dtd_name t
@

<<constant Dtd.get>>=
let get = 
  Hashtbl.find table
@

<<function Dtd.names>>=
let names () =
  let names = ref [] in
   Hashtbl.iter (fun name _ -> names := name :: !names) table;
   !names
@



<<constant Dtd.dtd32f>>=
(* Add frames somwhere to dtd32.
 * Luckily we chose sets, and they are functional
 *)
let dtd32f =
  let dtd = {
    dtd_name = "HTML 3.2 + frames";
    contents = Hashtbl.create 101;
    open_omitted = dtd32.open_omitted;
    close_omitted = dtd32.close_omitted;
  } in
  let omit_open el =
    dtd.open_omitted <- Elements.add el dtd.open_omitted
  and omit_close el =
    dtd.close_omitted <- Elements.add el dtd.close_omitted
  and add_elem = 
   Hashtbl.add dtd.contents
  in
  (* first : copy in the 3.2 contents *)
  Hashtbl.iter add_elem dtd32.contents;

  (* frameset and frames is pretty simple *)
  add_elem "frameset" (sol ["frameset"; "frame"; "noframes"]);
  add_elem "frame" Elements.empty;
  omit_close "frame";
  (* we say that noframes contains the same thing as body in 3.2 *)
  add_elem "noframes" (Hashtbl.find dtd.contents "body");
  (* and we say that frameset can occur in html *)
  let html_contents = Hashtbl.find dtd.contents "html" in
  Hashtbl.remove dtd.contents "html";
  add_elem "html" (Elements.add "frameset" 
             (Elements.add "noframes" html_contents));
  dtd
@

<<toplevel Dtd._1>>=
let _ = add dtd20; add dtd32
@

<<toplevel Dtd._2>>=
let _ = add dtd32f
@


\subsection{SGML evaluator}

<<type Html_eval.minimization>>=
(* Wrapped up lexer to insert open/close tags in the stream of "normal"
   tokens, according to some DTD, in order to always get fully parenthesized
   streams *)

type minimization =
  Legal | Illegal of string
@

<<signature Html_eval.add_html_filter>>=
(* test suit *)
val add_html_filter : ((Html.token -> unit) -> Html.token -> unit) -> unit
(* [add_html_filter filter] adds an HTML filter between the lexing and
  displaying of HTML. So, the filters do not affect the source (and
  the source display), change the content of HTML silently, and affect
  the display. The filter function [filter pfilter] receives a HTML token
  for each time, and do some job, and send a token to the parent filter 
  pfilter if possible. The filters will receive a correct HTML token
  stream (all the tags are placed and closed correctly due to the DTD),
  and they must send the correct stream to the parent filter also. 
*)
@

<<signature Html_eval.sgml_lexer>>=
val sgml_lexer :
  Dtd.t -> Lexing.lexbuf -> 
    ((string * int) list * minimization * Html.token list * Html.location)
@

<<signature Html_eval.automat>>=
val automat : Dtd.t -> (Html.location -> Html.token -> unit)
                    -> Lexing.lexbuf
                    -> (Html.location -> string -> unit)
            -> unit
@





<<exception Html_eval.CantMinimize>>=
exception CantMinimize			            (* bogus HTML *)
@

<<constant Html_eval.initial>>=
(* initial element of the DTD *)
let initial = Elements.add "html" Elements.empty
@

<<function Html_eval.dump_stack>>=
let dump_stack () = function
    (x,_)::(y,_)::(z,_)::_ -> sprintf "..<%s><%s><%s>" z y x
  | [x,_;y,_] -> sprintf "<%s><%s>" y x
  | [x,_] -> sprintf "<%s>" x
  | [] -> "empty stack"
@

<<function Html_eval.ominimize>>=
(* open minimize 
   [ominimize dtd open_tag current_stack]
   returns a list of inferred open/close tags and the new stack
 *)
let ominimize dtd t stack =
  let elem = t.tag_name in

  (* Is elem allowed for the given stack ? *)
  let goodpos = function
      [] -> Elements.mem elem initial
    | (_, cts)::l -> Elements.mem elem cts

  (* Return with inferred and stack.
     The stack has been reduced during the inference, so it is enough
     to push the opened element *)
  (* Special hack when t is fake #pcdata... *)
  and return inferred stack =
    if elem = "#pcdata" then
      List.rev inferred, stack
    else
      List.rev ((OpenTag t) :: inferred),
      (elem, Hashtbl.find dtd.contents elem) :: stack
      
  in
  (* [attempt_close mods_so_far current_stack] *)
  let rec attempt_close accu = function
     [] -> (* reached all the possible closing, attempt to open again *)
        attempt_open accu []
   | ((last, _)::l) as stack ->
       if Elements.mem last dtd.close_omitted then
          (* we can attempt to close the previous element *)
      if goodpos l then 
        (* good position, we're done *)
        return ((CloseTag last) :: accu) l
          else (* attempt to open in this new position *)
        try 
              attempt_open ((CloseTag last) :: accu) l
            with
          CantMinimize -> (* try once more to close *)
             attempt_close ((CloseTag last)::accu) l
       else begin (* since we can't close, try to open *)
      attempt_open accu stack
       end

   (* [attempt_open mods_so_far currentstack] *)
   and attempt_open accu = function
     [] -> 
       (* open HTML, and retry from there *)
       (* should actually iterate on all elements in initial *)
       let newstack = ["html", Hashtbl.find dtd.contents "html"]
       and newaccu = (OpenTag {tag_name = "html"; attributes = []}) :: accu
       in
      if goodpos newstack then return newaccu newstack
          else attempt_open newaccu newstack

   | ((_, cts)::l ) as stack ->
       (* check if, in contents, there is an element with implicit omission
          that would help *)
       let possible = Elements.inter cts dtd.open_omitted in
        match Elements.cardinal possible with
      0 -> (* argh *) raise CantMinimize
        | 1 -> 
      (* open this element and try from there *)
      let newelem = Elements.choose possible in
      let newaccu = (OpenTag {tag_name = newelem; attributes = []})::accu
          and newstack = (newelem, Hashtbl.find dtd.contents newelem)::stack
          in
        if goodpos newstack 
        then return newaccu newstack
        else attempt_open newaccu newstack (* maybe more ? *)
        | n -> (* since we have the choice, examine all possibilities *)
       let elems = Elements.elements possible in
       let rec backtrack = function 
             [] -> raise CantMinimize
        | x::l -> 
        try
          let newaccu = (OpenTag {tag_name = x; attributes = []})::accu
          and newstack = (x, Hashtbl.find dtd.contents x)::stack
                  in
            if goodpos newstack then return newaccu newstack 
            else attempt_open newaccu newstack
        with
         CantMinimize -> backtrack l
           in 
       backtrack elems
  in
   (* now do some error recovery *)   
   try Legal, attempt_close [] stack
   with
     CantMinimize ->
       (* what the hell, dammit, open it anyway, who cares, duh *)
       let current = match stack with (x,_)::l -> x | [] -> "" in
       Illegal (sprintf "illegal <%s> in %a, keep it though"
                t.tag_name dump_stack stack),
       return [] stack
@

<<function Html_eval.cminimize>>=
(* close minimize
   [cminimize dtd elem current_stack]
   returns a list of inferred open/close tags and the new stack
 *)
let cminimize dtd tagname stack =
  (* Is elem allowed for the given stack ? *)
  let goodpos = function
      [] -> false
    | (elem, cts)::l -> tagname = elem

  and return inferred stack =
     List.rev ((CloseTag tagname) :: inferred), stack

  in
  (* [attempt_close mods_so_far current_stack] *)
  let rec attempt_close accu = function
     [] -> raise CantMinimize
   | ((last, _)::l) as stack ->
       if Elements.mem last dtd.close_omitted then
          (* we can attempt to close the previous element *)
      if goodpos l then 
        (* good position, we're done *)
        return (CloseTag last :: accu) (List.tl l)
          else (* close a bit more ? *)
        attempt_close ((CloseTag last)::accu) l
       else 
     (* there's no reason we should have to open a new element in order
        to close the current one, is it ? *)
          raise CantMinimize
  in
  (* error recovery strategy *)
  let rec attempt_matching accu = function
     [] -> raise Not_found (* didn't find a matching open at all ! *)
   | (curelem,_):: l when curelem = tagname ->
     (* so, consider we match this open, and close them all *)
     return accu l
   | (curelem,_):: l  -> (* otherwise, find something up there *)
     attempt_matching (CloseTag curelem :: accu) l
   in
   (* now do some error recovery *)   
   try Legal, attempt_close [] stack
   with
     CantMinimize ->
       try
     Illegal (sprintf "unmatched </%s> in %a, close closest match"
                  tagname dump_stack stack),
         attempt_matching [] stack 
       with
     Not_found -> 
       Illegal (sprintf "unmatched </%s> in %a, skipped"
                    tagname dump_stack stack),
           ([], stack) (* just skip the damn thing *)
@

<<function Html_eval.is_cdata>>=
let is_cdata cts =
     Elements.cardinal cts = 1 
  && Elements.mem "#cdata" cts
@

<<function Html_eval.sgml_lexer>>=
let sgml_lexer dtd =
  let current_lex = ref Lexhtml.html
  and stack = ref [] 
  and lexdata = Lexhtml.new_data ()
  in

  (* currently allowed elements *)
  let allowed () = match !stack with
      [] -> initial
    | (elem, cts)::_ -> cts 
  in
  (* whatever the situation (but close), if the previous element is empty
     with an omittable close, close it *)
  let close_empty () = match !stack with
      [] -> []
    | (elem, ctx)::l ->
    if Elements.is_empty ctx && Elements.mem elem dtd.close_omitted
    then (stack := l; [CloseTag elem])
    else []
  in  
  (fun lexbuf ->
    let warnings, token, loc = !current_lex lexbuf lexdata in
    if !debug then 
      begin prerr_string "got "; Html.print token; prerr_newline() end;
    let status, tokens = 
      match token with
      | OpenTag t ->
          begin try (* first check that we know this element *)
        let contents = Hashtbl.find dtd.contents t.tag_name in
            let extraclose = close_empty() in    
        (* check changing of lexers; this works only if error recovery
           rules imply that the tag will *always* be open
             *)
        if is_cdata contents then current_lex := Lexhtml.cdata
        else current_lex := Lexhtml.html;
        (* is it allowed in here ? *)
        if Elements.mem t.tag_name (allowed()) then begin
              (* push on the stack *)
              stack := (t.tag_name, contents) :: !stack;
          Legal, extraclose @ [token]
              end
            else begin (* minimisation or error *)
              let flag, (res, l) = ominimize dtd t !stack in
        stack := l;
        flag, extraclose @ res
              end
          with
        Not_found -> 
          (* Not in the DTD ! We return it, but don't change our state
         or stack. An applet extension to the HTML display machine
                 can attempt to do something with it *)
          Illegal (sprintf "Element %s not in DTD" t.tag_name),
          [token]
          end
        
      | CloseTag t ->
      begin try (* do we know this element *)
            let _ = Hashtbl.find dtd.contents t in
        match !stack with
          [] -> 
        Illegal(sprintf "Unmatched closing </%s>" t),
        []
            | (elem, cts)::l when elem = t -> (* matching close *)
            stack := l; (* pop the stack *)
                (* the lexer has to be "normal" again, because CDATA
                   can't be nested anyway *)
               current_lex := Lexhtml.html;
        Legal, [token]
            | (elem, cts)::l -> (* unmatched close ! *)
        (* if we were in cdata, change the token to cdata *)
        if is_cdata cts then Legal, [CData (sprintf "</%s>" t)]
        else begin
                 current_lex := Lexhtml.html;
          let flag, (res, l) = cminimize dtd t !stack in
          stack := l;
          flag, res
        end
          with
        Not_found ->
          Illegal (sprintf "Element %s not in DTD" t),
          [token]
          end

      | PCData s ->
          let extraclose = close_empty() in    
      (* is it allowed in here ? *)
      if Elements.mem "#pcdata" (allowed()) then
              Legal, extraclose @ [token]
          (* ignore PCData made of spaces if not relevant to the context *)
      else if issp s then Legal, extraclose
      else
           begin	    
          (* bad hack. make believe that we try to open the #pcdata element *)
        let flag, (res, l) = 
          ominimize dtd {tag_name = "#pcdata"; attributes = []} !stack in
          stack := l;
          flag,  extraclose @ res @ [token]
       end

      (* CData never happens with an empty stack *)
      | CData s ->
          let extraclose = close_empty() in    
      if Elements.mem "#cdata" (allowed()) then
        Legal, extraclose @ [token]
          else
        Illegal(sprintf "Unexpected CDATA in %a" dump_stack !stack),
        extraclose @ [token]
        
      (* See if the stack is empty *)
      | EOF ->
      begin match !stack with
        [] -> Legal, [EOF]
          | l ->
             (* we must be able to close all remaining tags *)
         let rec closethem tokens = function
        [] -> None, EOF :: tokens
          | (last,_) :: l ->
          if Elements.mem last dtd.close_omitted then
            closethem (CloseTag last::tokens) l
          else
            let status, tokens = 
              closethem (CloseTag last::tokens) l in
            let err = sprintf "</%s>" last in
            let newstatus = match status with
              Some s -> Some (err^s)
            | None -> Some err in
            newstatus, tokens
         in
         match closethem [] l with
           None, tokens -> Legal, List.rev tokens
         | Some s, tokens -> Illegal ("Missing "^s), List.rev tokens
          end

      | _ ->  Legal, [token] (* ignore all other cases *)
      
      in
      warnings, status, tokens, loc)
@

<<constant Html_eval.filters>>=
let filters = ref []
@

<<function Html_eval.add_html_filter>>=
let add_html_filter f =
  filters := f :: !filters
@

<<function Html_eval.sgml_lexer (./html/html_eval.ml)>>=
(* Redefine sgml_lexer with filters *)
let sgml_lexer dtd = 
  let org_lexer = sgml_lexer dtd in
  let buf = ref [] in
  let allfilter = 
    List.fold_right (fun f st -> f st) !filters 
      (fun tkn -> buf := !buf @ [tkn]) 
  in
  function lexbuf ->
    let warnings, correct, tokens, loc = org_lexer lexbuf in
    List.iter allfilter tokens; (* inefficient *)
    let tokens = !buf in 
    buf := [];
    warnings, correct, tokens, loc
@

<<function Html_eval.automat>>=
let automat dtd action lexbuf error =
  try
    let lexer = sgml_lexer dtd in
    while true do
      try 
       let warnings, correct, tokens, loc = lexer lexbuf in
    List.iter (fun (reason, pos) -> error (Loc(pos,succ pos)) reason)
              warnings;
    begin match correct with
      Legal -> ()
        | Illegal reason -> error loc reason
        end;
    List.iter 
      (function token -> 
            begin 
          try action loc token
              with Invalid_Html s -> error loc s
            end;
        if token = EOF then failwith "quit_html_eval")
       tokens
      with
        Html_Lexing (s,n) -> error (Loc(n,n+1)) s
    done
  with
    Failure "quit_html_eval" -> ()
@


\subsection{[[htparse]]}

%(* Testing the HTML Lexer/evaluator *)

<<type Htparse.mode>>=
type mode =
  Check | Indent of int | Nesting
@
<<constant Htparse.mode>>=
let mode = ref Check
@


<<function Htparse.main>>=
let main () =
  Lang.japan := Lang.is_japanese ();
  Html.init !Lang.japan;

  Arg.parse [
     "-debug", Arg.Unit (function () -> Html_eval.debug := true), "Debug mode";
     "-strict", Arg.Set Lexhtml.strict, "Strict mode";
     "-v", Arg.Unit (function () -> verbose := true), "Verbose mode";
     "-struct", Arg.Int (function n -> mode := Indent n), "Parse Tree";
     "-nesting", Arg.Unit (function () -> mode := Nesting), "Check nesting";
     "-dtd", Arg.Unit (function () -> Dtd.dump Dtd.dtd32f), "Dump DTD";
     "-depth", Arg.Int (function n -> Format.set_max_boxes n), "Max print depth"
     ]
     (fun s -> 
       match !mode with
       | Check -> html_lex s
       | Indent n -> html_indent s n
       | Nesting -> html_nest s
       )
     "Usage: htparse <opts> file1.html ... filen.html"
@

<<toplevel Htparse._2>>=
let _ = Printexc.catch main ()
@


<<function Htparse.html_lex>>=
let html_lex name =
  let ic = open_in name in
  let lexbuf, find_line = line_reporting ic in
  Html_eval.automat Dtd.dtd32f
     (fun loc token ->
        match token with
        | EOF -> close_in ic
        | t -> if !verbose then (Html.print t; flush stdout)
     )
     lexbuf
     (error name find_line)
@


<<toplevel Htparse._1>>=
let _ = 
  Html.verbose := false (* we do our own error report *)
@

<<constant Htparse.verbose>>=
let verbose = ref false
@



<<function Htparse.error>>=
let error name find_line (Loc(n,n')) msg =
  let linenum, linestart = find_line n in
  printf "File \"%s\", line %d, characters %d-%d:\n%s\n"
         name linenum (n - linestart) (n' - linestart) msg
@

<<function Htparse.line_reporting>>=
(* lines: start at 1 *)
(* pos: start at 0 as in caml *)
let line_reporting ic =
  let lines = ref [] 
  and current_line = ref 1
  and current_pos = ref 0 in
  let read = 
    if !Lang.japan then 
      (Japan.create_read_japanese (input ic) (Japan.default_config ()))#read
    else input ic 
  in
  Lexing.from_function (fun buf len ->
     let n = read buf 0 len in
       for i = 0 to n - 1 do
     match buf.[i] with
       '\n' -> incr current_pos; incr current_line;
               lines := (!current_pos, !current_line) :: !lines
         | _ -> incr current_pos
         done; 
         n),
  (fun pos ->
    let rec find_line = function
      [] -> 1, 0
    | (linestart, linenum)::l when pos < linestart -> find_line l
    | (linestart, linenum)::l -> linenum, linestart
    in
     find_line !lines)
@




<<function Htparse.html_nest>>=
let html_nest name =
  let ic = open_in name in
  let lexbuf = Lexing.from_channel ic in
  let stack = ref [] in
   Html_eval.automat Dtd.dtd32f
      (function Loc(n,n') ->
      function 
        EOF -> close_in ic
          | OpenTag t ->
          stack := t.tag_name :: !stack
          | CloseTag t ->
          begin match !stack with
            hd::tl when hd = t -> stack := tl
              | hd::tl -> eprintf "Unmatched closing tag %s (expected %s) at 
                            pos %d - %d" t hd n n'
          | [] -> eprintf "Unmatched closing tag %s (Empty stack) at
                            pos %d - %d" t n n'
              end
          | _ -> ())
      lexbuf
      (fun _ _ -> ())
@

<<function Htparse.html_indent>>=
let html_indent name level =
  let box = match level with
     0 -> Format.open_box
   | 1 -> Format.open_hvbox
   | n -> Format.open_vbox in
  let ic = open_in name in
  let lexbuf  = Lexing.from_channel ic in
   box 0;
   Html_eval.automat Dtd.dtd32f
      (fun loc token ->
      match token with
        EOF -> 
        Format.print_newline();
        close_in ic
          | OpenTag t ->
                Format.print_cut();
        box 0;
        box 2;
        Format.print_string (sprintf "<%s>" t.tag_name)
      | CloseTag t ->
        Format.close_box();
                Format.print_cut();
        Format.print_string (sprintf "</%s>" t);
                Format.close_box()
      | PCData _ -> Format.print_string "*"
      | _ -> ()
      )
      lexbuf
      (fun _ msg -> Format.print_string (sprintf "ERROR(%s)" msg))
@



\section{HTTP}

\subsection{Request}

<<signature Http_headers.parse_request>>=
val parse_request : string -> request
  (* Parses a Request-Line
     Request-Line = Method SP Request-URI SP HTTP-Version CRLF
     Raises [Invalid_HTTP_header "Request-Line"] *)
@





<<function Http_headers.parse_request>>=
(* CHECK: Normally the URI should be encoded (no spaces ?) *)
let parse_request s =
 try
  match Str.bounded_split (regexp "[ ]") s 3 with
    [m;r;v] ->
         { request_version = v;
       request_method = m;
       request_uri = r }
  | ["GET"; uri] ->
         { request_version = "HTTP/0.9";
           request_method = "GET";
       request_uri = uri }
  | [m;s] -> (* uri omitted ? *)
         { request_version = s;
           request_method = m;
       request_uri = "/" }
  | _ -> raise (Invalid_HTTP_header "Request-Line")
 with
   Failure "int_of_string" -> raise (Invalid_HTTP_header "Request-Line")
@


\subsection{Status}

<<signature Http_headers.parse_status>>=
val parse_status : string -> status
  (* Parses a Status-Line
     Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase CRLF
     Raises [Invalid_HTTP_header "Status-Line"] 
     or [Not_found] if the string is not a Status-Line at all *)
@

<<function Http_headers.parse_status>>=
(* Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase CRLF *)
let parse_status s =
 if String.length s > 5 & String.sub s 0 5 = "HTTP/" then
 try
  match Str.bounded_split (regexp "[ ]") s 3 with
    [v;c;m] ->
         { status_version = v;
           status_code = int_of_string c;
           status_message = m }
  (* it happened once with Server: Netscape-Commerce/1.1 *)
  (* where the Status Line was: HTTP/1.0 302 *)
  | [v;c] ->
         { status_version = v;
           status_code = int_of_string c;
           status_message = "empty" }
  | _ -> raise (Invalid_HTTP_header "Status-Line")
 with
   Failure "int_of_string" -> raise (Invalid_HTTP_header "Status-Line")
 else (* 0.9, dammit *)
   raise Not_found
@


\subsection{Headers}

<<signature Http_headers.get_header>>=
val get_header : string -> header list -> string
  (* [get_header field_name hs] returns the field_value, if any, of
     the headers, or raises [Not_found].
     [field_name] is the token is lowercase (e.g. "content-type") *)
@

<<signature Http_headers.get_multi_header>>=
val get_multi_header : string -> header list -> string list
  (* [get_multi_header field_name hs] returns the list of field_value
     of the headers.
     [field_name] is the token is lowercase (e.g. "content-type") *)
@


<<function Http_headers.get_header>>=
(* [get_header field-name headers]
 *   returns, if it exists the field value of the header field-name
 * This is a bit costly though, but we keep headers as plain strings.
 * CHECK: speed up with some regexp matching.
 * HYP: field-name in lower-case
 *)
let get_header field_name = 
  let size = String.length field_name in
  let rec search = function
     [] -> raise Not_found
   | s::l ->
    if   String.length s >= size + 2 (* : SP *)
       & String.lowercase (String.sub s 0 size) = field_name
    then String.sub s (size + 2) (String.length s - size - 2)
    else search l in
  search
@

<<function Http_headers.get_multi_header>>=
(* [get_multi_header field_name headers]
 *   get all values of the header
 *)
let get_multi_header field_name =
  let size = String.length field_name in (* :SP *)
  let rec search = function
     [] -> []
   | s::l ->
    if   String.length s >= size + 2 (* : SP *)
       & String.lowercase (String.sub s 0 size) = field_name
    then (String.sub s (size + 2) (String.length s - size - 2)) :: search l
    else search l in
  search
@

\subsection{Media}

<<signature Lexheaders.media_type>>=
val media_type : 
  string -> media_type * Http_headers.media_parameter list
@



\chapter{HTML}
% html/

\section{Tables}

\section{Forms}

\section{Maps}

% important for imgs?

%(* Client-side image maps:
%     the "only" difficulty in implementing client-side image maps is that
%     the map may well come *after* the image in the document. In general,
%     anyway, the map may be an arbitrary URL.
%
%   We thus have to implement a general delay mechanism for maps : the idea
%   here is to use a table of maps, each map being accessed by an URI (that is,
%   an URL plus a fragment).
%
%   PROBLEM: we have no idea in general when to flush this table.
%
% *)


<<type Maps.area_kind>>=
(* The active areas *)
type area_kind = Rect | Circle | Poly | Default
@

<<type Maps.area>>=
(* The area *)
type area = {
  area_kind : area_kind;
  area_coords : int list;
  area_link : Hyper.link;
  area_alt  : string
 }
@

<<type Maps.map>>=
type map = area list
@

<<type Maps.t>>=
(* We merge any kind of map, for we actually are going to support
   maps for arbitrary embedded objects
 *)
type t = 
    ClientSide of Hyper.link		(* usemap link *)
  | ServerSide of Hyper.link		(* ismap *)
  | Direct of Hyper.link			(* inside an anchor *)
  | NoMap				(* no additionnal navigation *)
  | FormMap of (int * int -> Hyper.link)
@

<<type Maps.map_status>>=
(* The table of client-side image maps *)
type map_status =
   KnownMap of map
 | RequestedMap of string
@

<<signature Maps.parse_coords>>=
val parse_coords : string -> int list
@

<<signature Maps.get>>=
val get : string -> map_status
@

<<signature Maps.add>>=
val add : string -> map -> unit
@


<<constant Maps.table>>=
let table = (Hashtbl.create 37 : (string, map_status) Hashtbl.t)
@

<<constant Maps.coord_sep>>=
(* Tolerance: official syntax is "," separated.
   We use instead "[ \t\n]+\|\([ \t\n]*,[ \t\n]*\)"
   that is non empty sequence of whitespace
        or comma with possible surrounding whitespace
 *)
(* let coord_sep = Str.regexp "," *)
let coord_sep = Str.regexp "[ \t\n]+\|\([ \t\n]*,[ \t\n]*\)"
@

<<function Maps.parse_coords>>=
let parse_coords s =
  List.map int_of_string (Str.split coord_sep s)
@

<<function Maps.add>>=
let add name map =
  Log.debug (sprintf "Adding map : %s" name);
  try
    match Hashtbl.find table name with
      KnownMap m -> Log.debug "Map already known !"
    | RequestedMap event ->
       Hashtbl.remove table name; (* remove it *)
       Hashtbl.add table name (KnownMap map); (* add its value *)
       Frx_synth.broadcast event (* trigger all waiting people *)
  with
    Not_found -> (* nobody requested it *)
      Hashtbl.add table name (KnownMap map)
@

<<function Maps.get>>=
let get name =
  Log.debug (sprintf "Asking map : %s" name);
  try
    Hashtbl.find table name 
  with
    Not_found ->
       let m = Mstring.gensym "map" in
         Hashtbl.add table name (RequestedMap m);
     RequestedMap m
@


\chapter{HTTP}
%Communication Protocol
% http/

% will see http://, main protocol, see also file://, mailto://
% in extra protocol chapter

<<toplevel Protos._2>>=
let _ = Hashtbl.add protos HTTP (Http.req, Cache.tobuffer)
@

<<function Http.req>>=
let req wr cont =
  let cnx = request wr cont in
    (fun () -> cnx#abort)
@


\section{Headers}

<<signature Http_headers.merge_headers>>=
val merge_headers : header list -> header list -> header list
  (* [merge_headers oldhs newhs] merges headers, overriding headers in
     [oldhs] by headers in [newhs] *)
@

<<signature Http_headers.remove_headers>>=
val remove_headers : header list -> string list -> header list
  (* [remove_headers hs field_names] returns [hs] without the headers
     with field_name present in [field_names] *)
@

<<signature Http_headers.header_type>>=
val header_type : string -> string
  (* [header_type h] returns the field_name token of [h], in lowercase *)
@



<<function Http_headers.header_type>>=
let header_type s =
  match Str.bounded_split (regexp "[:]") s 2 with
    [t;_] -> String.lowercase t
  | _ -> raise (Invalid_HTTP_header s)
@

<<function Http_headers.merge_headers>>=
(* Keep only unmodified headers *)
let merge_headers oldh newh =
  let rec filter acc = function
     [] -> acc
   | s::l ->
      if String.length s > 5 & String.sub s 0 5 = "HTTP/" then
       filter acc l
      else
       try
        let t = header_type s in
        let d = get_header t newh in
      filter acc l
       with
          Invalid_HTTP_header _ -> 
          Log.debug (sprintf "Dumping invalid header (%s)" s);
              filter acc l
        | Not_found -> filter (s::acc) l in
  (filter [] oldh) @ newh
@

<<function Http_headers.remove_headers>>=
let remove_headers hs names =
  Log.debug "remove headers";
  let rec rem acc = function
     [] -> acc
   | h::l ->
      try
       let t = header_type h in
         if List.mem t names then rem acc l
     else rem (h::acc) l
      with
        Invalid_HTTP_header s ->
      Log.debug (sprintf "Dumping invalid header (%s)" s);
          rem acc l

   in rem [] hs
@



\section{Content}

<<toplevel Http_headers._1>>=
(* If the suffix file says otherwise, it will have priority *)
let _ = List.iter (fun (s,t) -> Hashtbl.add suffixes s t)
[ 
  "html",	ContentType  "Content-Type: text/html";
  "htm",	ContentType  "Content-Type: text/html";
  "txt",  	ContentType  "Content-Type: text/plain";
  "ps",  	ContentType  "Content-Type: application/postscript";
  "dvi",  	ContentType  "Content-Type: application/x-dvi";
  "gif",	ContentType  "Content-Type: image/gif";
  "jpeg",	ContentType  "Content-Type: image/jpeg";
  "jpg",	ContentType  "Content-Type: image/jpeg";
  "tiff",	ContentType  "Content-Type: image/tiff";
  "tif",	ContentType  "Content-Type: image/tiff";
  "au",		ContentType  "Content-Type: audio/basic";
  "snd",	ContentType  "Content-Type: audio/basic";
  "wav",	ContentType  "Content-Type: audio/x-wav";
  "mid",	ContentType  "Content-Type: audio/midi";
  "mpeg",	ContentType  "Content-Type: video/mpeg";
  "mpg",	ContentType  "Content-Type: video/mpeg";
  "avi",	ContentType  "Content-Type: video/avi";
  "fli",	ContentType  "Content-Type: video/fli";
  "flc",	ContentType  "Content-Type: video/fli";
  "gz",		ContentEncoding  "Content-Encoding: gzip";
  "Z",		ContentEncoding  "Content-Encoding: compress";
  "asc",	ContentEncoding  "Content-Encoding: pgp";
  "pgp",	ContentEncoding  "Content-Encoding: pgp";
  "cmo",        ContentType "Content-Type: application/x-caml-applet; encoding=bytecode";
]
@

\subsection{Content type}

<<signature Http_headers.contenttype>>=
(* Predefined access functions *)
val contenttype : header list -> string
  (* Content-Type *)
@

\subsection{Content length}

<<signature Http_headers.contentlength>>=
val contentlength : header list -> int
  (* Content-Length *)
@

\subsection{Content encoding}

<<signature Http_headers.contentencoding>>=
val contentencoding : header list -> string
  (* Content-Encoding *)
@


\section{Status}

<<toplevel Http_headers._2>>=
let _ = List.iter (function (code, msg) ->
                     Hashtbl.add status_messages code msg)
  [ 200, "OK";

    201, "Created";
    202, "Accepted";
    204, "No Content";

    301, "Moved Permanently";
    302, "Moved Temporarily";
    304, "Not Modified";

    400, "Bad Request";
    401, "Unauthorized";
    403, "Forbidden";
    404, "Not Found";

    500, "Internal Server Error";
    501, "Not Implemented";
    502, "Bad Gateway";
    503, "Service Unavailable";

    (* These are proposed for HTTP1.1 *)
    407, "Proxy Authentication Required"
  ]
@
%404!!

<<function Http_headers.http_status>>=
(* A typical status line *)
let http_status code =
  {
   status_version = "HTTP/1.0";
   status_code = code;
   status_message = status_message code
  }
@

<<constant Http_headers.status_messages>>=
(* Messages in Status-Line *)
let status_messages = Hashtbl.create 101
@


<<function Http_headers.status_message>>=
let status_message code =  
  try Hashtbl.find status_messages code
  with Not_found -> " "
@


\section{Time}
% could be in Stdlib? with Date?

<<type Http_date.http_time>>=
(* Based on Unix.tm *)
type http_time =
  { ht_sec : int;                       (* Seconds 0..59 *)
    ht_min : int;                       (* Minutes 0..59 *)
    ht_hour : int;                      (* Hours 0..23 *)
    ht_mday : int;                      (* Day of month 1..31 *)
    ht_mon : int;                       (* Month of year 0..11 *)
    ht_year : int;                      (* Year - 1900 *)
    ht_wday : int }                     (* Day of week (Sunday is 0) *)
@

<<signature Http_date.expired>>=
val expired : http_time -> bool
  (* Determines if an http_time is in the past *)
@

<<signature Http_date.compare>>=
val compare : http_time -> http_time -> int
  (* Compares two http_times *)
@

<<signature Http_date.string_of_ht>>=
val string_of_ht : http_time -> string
  (* Text version (RFC822) of an http time stamp *)
@

<<signature Http_date.tm_of_ht>>=
val tm_of_ht : http_time -> Unix.tm
@

<<signature Http_date.stamp_of_ht>>=
val stamp_of_ht : http_time -> float
@

<<signature Http_date.ht_of_stamp>>=
val ht_of_stamp : float -> http_time
@



<<function Http_date.expired>>=
let expired ht =
  let now = gmtime(time()) in
  let lht = 
    [ht.ht_year; ht.ht_mon; ht.ht_mday; ht.ht_hour; ht.ht_min; ht.ht_sec]
  and lnow =
    [now.tm_year; now.tm_mon; now.tm_mday; now.tm_hour; now.tm_min; now.tm_sec]
  in
    compare_time (lht, lnow) <= 0
@

<<function Http_date.compare>>=
let compare ht1 ht2 =
 compare_time
  ([ht1.ht_year; ht1.ht_mon; ht1.ht_mday; ht1.ht_hour; ht1.ht_min; ht1.ht_sec],
   [ht2.ht_year; ht2.ht_mon; ht2.ht_mday; ht2.ht_hour; ht2.ht_min; ht2.ht_sec])
@

<<function Http_date.string_of_ht>>=
let string_of_ht ht =
  sprintf "%s, %02d %s %d %02d:%02d:%02d GMT"
      (asc_wkday ht.ht_wday)
      ht.ht_mday
      (asc_month ht.ht_mon)
      (ht.ht_year + 1900)
      ht.ht_hour
      ht.ht_min
      ht.ht_sec
@

<<function Http_date.tm_of_ht>>=
(* 
let has_dst = localtime(time()).tm_isdst
*)
let tm_of_ht ht = {
    tm_sec = ht.ht_sec;
    tm_min = ht.ht_min;
    tm_hour = ht.ht_hour;
    tm_mday = ht.ht_mday;
    tm_mon = ht.ht_mon;
    tm_year = ht.ht_year;
    tm_wday = ht.ht_wday;
    tm_yday = 0;
    tm_isdst = false        (* I don't have a clue here *)
   }
@

<<function Http_date.stamp_of_ht>>=
let stamp_of_ht ht =
   fst (mktime (tm_of_ht ht))
@

<<function Http_date.ht_of_stamp>>=
let ht_of_stamp ut =
  let tm = gmtime ut in {
    ht_sec = tm.tm_sec;
    ht_min = tm.tm_min;
    ht_hour = tm.tm_hour;
    ht_mday = tm.tm_mday;
    ht_mon = tm.tm_mon;
    ht_year = tm.tm_year;
    ht_wday = tm.tm_wday
     }
@
\section{Retrieving an HTTP document}

%todo: no http.mli?

<<constant Http.always_proxy>>=
let always_proxy = ref false
@

<<constant Http.timeout>>=
let timeout = ref 60		(* in seconds *)
@

<<constant Http.verbose>>=
let verbose = ref false
@

<<exception Http.HTTP_error>>=
exception HTTP_error of string
@

<<type Http.status>>=
(* Support for aborting requests while in connect/write/headers mode.
   When we start applying the document continuation, it is not our job
   anymore to abort the connection.
 *)
type status = Writing | Reading of handle | Discharged
@

<<function Http.tcp_connect>>=
(* Open a TCP connection, asynchronously (except for DNS).
   We pass the continuation *)
let tcp_connect server_name port log cont error =
  (*  Find the inet address *)
  let server_addr =
    try inet_addr_of_string server_name
    with Failure _ ->
      try
        log (I18n.sprintf "Looking for %s ..." server_name);
        let adr = (Low.busy Munix.gethostbyname server_name).h_addr_list.(0) in
      log (I18n.sprintf "%s found" server_name);
      adr
      with Not_found -> 
       raise (HTTP_error (I18n.sprintf "Unknown host: %s" server_name)) in
  (* Attempt to connect *)
  let sock = socket PF_INET SOCK_STREAM 0 in
  Unix.clear_nonblock sock;
    log (I18n.sprintf "Contacting host...");
    Unix.set_nonblock sock; (* set to non-blocking *)
  let cnx = new cnx (sock, error "User abort") in
    try
      begin try
        connect sock (ADDR_INET(server_addr, port));
        (* just in case. Normally an error should be raised *)
        Unix.clear_nonblock sock; (* set to non-blocking *)
    log (I18n.sprintf "connection established");
    Log.debug "Connect returned without error !";
    (* because we need to return cnx *)
    Timer.set 10 (fun () -> cont cnx);
        cnx
      with
       Unix_error((EINPROGRESS | EWOULDBLOCK | EAGAIN), "connect", _) -> 
         (* that is ok, we are starting something *)
      let stuck = ref true in
      Fileevent.add_fileoutput sock
          (* we are called when the cnx is established *)
         (fun () -> 
         stuck := false;
         Fileevent.remove_fileoutput sock;
         Unix.clear_nonblock sock; (* return to blocking mode *)
        begin try (* But has there been a cnx actually *)
           let _ = getpeername sock in
           log (I18n.sprintf "connection established");
           cont cnx
             with
               Unix_error(ENOTCONN, "getpeername", _) ->
             cnx#close;
         error (I18n.sprintf "Connection refused to %s" server_name)
                   false
             end);
     (* but also start the timer if nothing happens now
         * the kernel has a timeout, but it might be too long (linux) *)
         Timer.set (1000 * !timeout) 
        (fun () -> 
          if not cnx#aborted && !stuck then begin
           Fileevent.remove_fileoutput sock;
           cnx#close;
           error (I18n.sprintf "Timeout during connect to %s" server_name)
                 false
          end);
     cnx
      end
    with
      Unix_error(e,fn,_) ->  (* other errors in connect *)
        cnx#close;
        raise (HTTP_error (I18n.sprintf "Cannot establish connection\n%s:%s"
                             (error_message e) fn))
@

<<constant Http.send_referer>>=
(*
 * HTTP/1.0
 * Headers should be configurable
 *)

let send_referer = ref false
@

<<constant Http.user_agent>>=
let user_agent = ref Version.http
@

<<function Http.std_request_headers>>=
let std_request_headers() =
  Printf.sprintf "User-Agent: %s\r\n" !user_agent
@

<<function Http.full_request>>=
let full_request w proxy_mode wwwr = 
  let url = 
    if proxy_mode then Url.string_of wwwr.www_url
    else distant_path wwwr.www_url in
  let write_referer = match wwwr.www_link.h_context with
     None -> (fun () -> ())
   | Some r ->  (fun () -> if !send_referer then w ("Referer: " ^ r ^ "\r\n"))
  and write_other_headers () =
    List.iter (fun s -> w s; w "\r\n") wwwr.www_headers;
    (* If no Accept given in request, write default one *)
    begin
      try
    ignore (get_header "accept" wwwr.www_headers)
      with
    Not_found -> w "Accept: */*\r\n"
    end
  (* Host: header for virtual domains *)
  and write_host () =
    match wwwr.www_url.host with
      None -> (* never happens *) ()
    | Some h -> 
    match wwwr.www_url.port with
      None -> w ("Host: "^h^"\r\n")
    | Some p ->  w ("Host: "^h^":"^string_of_int p^"\r\n")
  (* If the request has an Authorization, write it *)
  and write_realm_auth () =
    try
      let cookie = List.assoc "realm" wwwr.www_auth in
     w ("Authorization: Basic "^cookie^"\r\n")
    with
      Not_found -> ()
  (* For proxy, we don't wait until we get an authorization error *)
  and write_proxy_auth () =
    let authspace = {
    auth_proxy = true;
    auth_host = !proxy;
    auth_port = !proxy_port;
    auth_dir = "";
    auth_realm = ""} in
      try (* do we know the cookie *)
    let cookie = Auth.get authspace in
        w ("Proxy-Authorization: Basic "^cookie^"\r\n")
      with
    Not_found -> (* is that in the request ? *)
     try
          let cookie = List.assoc "proxy" wwwr.www_auth in
          w ("Proxy-Authorization: Basic "^cookie^"\r\n")
     with
       Not_found -> ()

  in
   match wwwr.www_link.h_method with
    GET ->
      w ("GET "^url^" HTTP/1.0\r\n");
      (* No General-Header *)
      w (std_request_headers());
      write_referer ();
      write_realm_auth ();
      if proxy_mode then write_proxy_auth();
      write_other_headers();
      write_host();
      w "\r\n"
 |  HEAD ->
      w ("HEAD "^url^" HTTP/1.0\r\n");
      (* No General-Header *)
      w (std_request_headers());
      write_referer ();
      write_realm_auth ();
      if proxy_mode then write_proxy_auth();
      write_other_headers();
      write_host();
      w "\r\n"
 |  POST data ->
      w ("POST "^url^" HTTP/1.0\r\n");
      (* No General-Header *)
      w (std_request_headers());
      write_referer ();
    write_realm_auth ();
    if proxy_mode then write_proxy_auth();
      write_other_headers();
      write_host();
      (* 8.2.1 *)
      w ("Content-Type: application/x-www-form-urlencoded\r\n");
      (* 7.2 note *)
      w ("Content-Length: " ^ string_of_int (String.length data)^ "\r\n");
      w "\r\n";
      w data
@

<<function Http.failed_request>>=
(* shared error *)
let failed_request wr finish s aborted =
  finish aborted;
  Www.rem_active_cnx wr.www_url;
  wr.www_logging (I18n.sprintf "Failed");
  wr.www_error#f   (I18n.sprintf "Request for %s failed\n%s" 
            (Url.string_of wr.www_url) s)
@

<<exception Http.End_of_headers>>=
(* [read_headers fd]
 *  reads HTTP headers from a fd
 *    raises End_of_file
 *    raises Invalid_HTTP_header
 *)
exception End_of_headers
@

<<function Http.read_headers>>=
let read_headers fd previous =
  let l = Munix.read_line fd in
   if String.length l = 0 then raise End_of_headers (* end of headers *)
   else if l.[0] = ' ' or l.[0] = '\t' then  (* continuation *)
       match previous with
     [] -> raise (Invalid_HTTP_header ("invalid continuation " ^ l))
       | s :: rest -> (s^l) :: rest
   else l :: previous
@

\chapter{Network}
%Retrieving Documents}
% retrieve/

<<type Retrieve.retrievalStatus>>=
type retrievalStatus =
  Started of (unit -> unit)  | InUse
@

<<signature Retrieve.f>>=
(* f is supposed to raise only Invalid_url *)
val f : Www.request ->  (* the request *)
        (Hyper.link -> unit) -> (* the retry function *)
        Document.document_continuation -> (* the handlers *)
        retrievalStatus
@

<<type Retrieve.behaviour>>=
(* We should implement the proper behaviours for all return codes
 * defined in the HTTP/1.0 protocol draft. 
 * Return codes are HTTP specific, but since all protocols are more or
 * less mapped to http, we deal with them at the retrieval level.
 *)
type behaviour =
   Ok 			              (* process the document *)
 | Stop of string             (* stop (no document) and display message *)
 | Retry of Hyper.link        (* restart with a new link *)
 | Error of string            (* same as stop, but it's an error *)
 | Restart of (handle -> handle) (* restart the same request, but apply
                     transformation on the continuation *)
@

<<signature Retrieve.add_http_processor>>=
val add_http_processor : 
  int -> (Www.request -> handle -> behaviour) -> unit
@


<<constant Retrieve.http_process>>=
(*
 * Provision for user (re)definition of behaviours.
 *)
let http_process = Hashtbl.create 37
@

<<constant Retrieve.add_http_processor>>=
let add_http_processor = Hashtbl.add http_process
@

<<toplevel Retrieve._1>>=
(* 400 : proxies do return this code when they can satisfy the request,
 *       so we keep it as default (displayed)
 *)
let _ =
 List.iter (function (code, behave) -> Hashtbl.add http_process code behave)
  [200, code200;
   201, code200;
   202, code200;
   204, code204;

   301, forward_permanent;
   302, forward;
   (* 304, update; *)
   401, unauthorized;
   407, proxy_unauthorized]
@

% no 404? :)


<<function Retrieve.code200>>=
(* 200 OK *)
let code200 wwwr dh = Ok
(* 201 Created (same as 200) *)
(* 202 Accepted (same as 200) *)
@


<<function Retrieve.code400>>=
(* 400 Bad request *)
let code400 wwwr dh = Error (I18n.sprintf "Bad Request")
@

\section{Connections}

<<type Feed.internal>>=
(* An abstract notion of connection *)

type internal = Unix.file_descr
@

<<type Feed.t>>=
type t = {
  feed_read : string -> int -> int -> int;
  feed_schedule : (unit -> unit) -> unit;
  feed_unschedule : unit -> unit;
  feed_close : unit -> unit;
  feed_internal : internal  
  }
@

<<signature Feed.of_fd>>=
val of_fd : Unix.file_descr -> t
@

<<signature Feed.internal>>=
val internal : t -> internal
@


<<function Feed.of_fd>>=
(* We should distinguish internal/external connections *)
let of_fd fd =
  let is_open = ref true
  and action = ref None
  and condition = Condition.create()
  and first_read = ref false
  in
  (* ASSUMES: this is the first read on the fileevent *)
  let safe_read buf offs len =
    first_read := false;
    if !is_open then Low.read fd buf offs len else 0
  in
  (* In other cases : this is non blocking but not fully threaded. *)
  let special_read buf ofs len =
     (* remove the normal handler *)
     File_event.remove_fileinput fd; 
     (* add a handler to trigger the condition *)
     File_event.add_fileinput fd (fun () ->
     File_event.remove_fileinput fd; (* remove myself *)
     Condition.set condition);
     (* wait for the condition to happen *)
     Condition.wait condition;
     (* Meanwhile, someone may have unscheduled/closed the 
    feed (e.g. abort). We call safe_read, but if the feed has been
    closed, read will fail.
    To know if we have to put back on schedule, check the *current*
    state of action
      *)
     let n = try safe_read buf ofs len with _ -> 0 in
     (* reschedule; it is essential that Low.add_fileinput does not
        call the event loop, otherwise we loose sequentiality of reads *)
     (match !action with
        Some f ->
      File_event.add_fileinput fd (fun () -> first_read := true; f())
      | None -> ());
     (* and return *)
     n
  in {
   feed_read =
    (fun buf ofs len -> 
       if !first_read then safe_read buf ofs len
       else special_read buf ofs len);
   feed_schedule = 
    (function f ->
       if not !is_open then
     Log.f "ERROR: feed is closed, can't schedule"
       else match !action with
     Some f -> (* we are already scheduled ! *)
       Log.f "Warning: feed already scheduled"
       | None -> begin
        action := Some f;
        Low.add_fileinput fd (fun () -> first_read := true; f())
      end);
   feed_unschedule = 
    (function () -> 
       match !action with
     Some f -> Low.remove_fileinput fd; action := None
       | None -> (* this happens quite often (for all action codes which
            do not process the body of the document, the feed got
            unscheduled as the end of headers) *)
       ());

   (* feed_close must be called only if the feed it *not* scheduled *)
   feed_close =
    (function () -> 
       (* if we abort during a state when we are waiting on the condition,
          the feed is unscheduled but we never get out. So always change
      the state *)
       Condition.set condition;
       if !is_open then begin
     match !action with 
        Some f -> Log.f "ERROR: feed is scheduled, can't close"
      | None -> Unix.close fd;
                is_open := false;
            (* Condition.free condition RACE CONDITION HERE *)
       end);
   feed_internal = fd
     }
@

<<function Feed.internal>>=
let internal {feed_internal = fd} = fd
@


\section{Active}

<<module Www.UrlSet>>=
(* We need to keep a trace of pending connections, since there is a race
   condition when the user clicks twice rapidly on an anchor. If the second
   click occurs before the document is added to the cache, (e.g. because we
   are waiting for the headers), then the document will be retrieved twice.
   And naturally, for documents that don't enter the cache we always will
   duplicate connexions.
   Retrieve.f is a safe place to add the request to the list of pending
   connexions, because it is synchronous.
   Removing an active connexion must take place when we close the 
   dh.document_fd.
*)
module UrlSet =
  Set.Make(struct type t = Url.t let compare = compare end)
@


<<signature module Www.UrlSet>>=
(* Table of unresolved active connexions *)
module UrlSet : Set.S with type elt = Url.t
@

<<constant Www.active_connexions>>=
let active_connexions = ref UrlSet.empty
@

<<signature Www.is_active_cnx>>=
val is_active_cnx : Url.t -> bool
@
<<signature Www.add_active_cnx>>=
val add_active_cnx : Url.t -> unit
@
<<signature Www.rem_active_cnx>>=
val rem_active_cnx : Url.t -> unit
@

<<functions Www.xxx_active_cnx>>=
let is_active_cnx url = 
  UrlSet.mem url !active_connexions
let add_active_cnx url = 
  active_connexions := UrlSet.add url !active_connexions
let rem_active_cnx url =
  active_connexions := UrlSet.remove url !active_connexions
@

\section{Documents}


<<type Document.document_data>>=
(*
 * Information on a document, as could be requested by "other" clients,
 * that is clients not directly on the chain of processes dealing with
 * the handle
 *)

type document_data =
   MemoryData of Ebuffer.t
 | FileData of string * bool (* flag is true if file is temporary *)
@

<<type Document.document>>=
type document = {
  document_address : Url.t;
  mutable document_data : document_data;
  document_info : string list
  }
@

<<signature Document.dclose>>=
val dclose : bool -> handle -> unit
  (* [dclose remactive dh] closes a living dh *)
@

<<signature Document.add_log>>=
val add_log: handle -> string -> (unit -> unit) -> unit
@

<<signature Document.put_log>>=
val put_log : handle -> string -> unit
@

<<signature Document.progress_log>>=
val progress_log : handle -> int -> unit
@

<<signature Document.end_log>>=
val end_log : handle -> string -> unit
@

<<signature Document.destroy_log>>=
val destroy_log : handle -> bool -> unit
  (* logging functions *)
@



<<function Document.dclose>>=
(* Close a connexion. Should be called only by a fileinput callback
      or by somebody attempting to abort the connexion 
   We remove the fd of the select before closing it since we don't want
   a spurious read to happen. This way we are somewhat independant of the
   Tk implementation 
 *)

let dclose remactive dh =
  dh.document_feed.feed_unschedule();
  dh.document_feed.feed_close();
  if remactive then Www.rem_active_cnx dh.document_id.document_url
@


<<function Document.add_log>>=
let add_log dh initmsg abort =
  let t = 
    Toplevel.create Widget.default_toplevel [Class "MMMLog"] in
  Wm.withdraw t;
  Wm.title_set t 
      (I18n.sprintf "Document log %s" 
         (Url.string_of dh.document_id.document_url)); 
  let l = Label.create t 
    [Text initmsg; Justify Justify_Left; WrapLength (Pixels 600)]
  and fprog, set_progress = Frx_fillbox.new_horizontal t 200 10 
  and b = Button.create t 
      [Text (I18n.sprintf "Abort"); 
       Command (fun () -> dclose true dh; abort(); destroy t)] in
    pack [l;fprog;b][];
  let putmsg txt = 
    Label.configure l [Text txt] in
  let finished msg =
    putmsg msg;
    Button.configure b 
       [Text (I18n.sprintf "Ok"); 
         Command (fun () -> if Winfo.exists t then destroy t)] in
  let iconified = ref true in
  let logger = {
    logger_destroy =
      (fun delayed ->
    if Winfo.exists t then
      if !iconified then (* that was fast *)
        destroy t
      else if not delayed then destroy t
      else
              Timer.set 5000 (fun () -> if Winfo.exists t then destroy t));
    logger_progress = 
      (fun n -> if Winfo.exists t then set_progress n);
    logger_msg =
      (fun msg -> if Winfo.exists t then putmsg msg);
    logger_end = 
      (fun msg -> if Winfo.exists t then finished msg) } in

   dh.document_logger <- logger;
   (* The logger appears only after a given delay *)
     Timer.set 3000
      (fun () -> if Winfo.exists t then (Wm.deiconify t; iconified := false))
@

<<function Document.end_log>>=
let end_log dh msg =
    dh.document_logger.logger_end msg;
    destroy_log dh true
@

<<functions Document.xxx_log>>=
let put_log dh = dh.document_logger.logger_msg
let destroy_log dh = dh.document_logger.logger_destroy
let progress_log dh = dh.document_logger.logger_progress
@

<<type Document.display_info>>=
type display_info = {
    di_abort : unit -> unit;
    di_destroy : unit -> unit;
    di_fragment : string option -> unit;
    di_redisplay: unit -> unit;
    di_title : unit -> string;	      (* some title for bookmarks *)
    di_source : unit -> unit;
    di_load_images : unit -> unit
}
@

\section{Images}

<<signature Img.get>>=
val get : document_id -> Hyper.link -> (Url.t -> ImageData.t -> unit) -> 
            Scheduler.progress_func -> unit
@

<<signature Img.update>>=
val update : Url.t -> unit
@


<<function Img.get>>=
let get did link cont prog =
  let wr = Www.make link in
   wr.www_headers <- "Accept: image/*" :: wr.www_headers;
   ImageScheduler.add_request wr did cont prog
@


<<function Img.update>>=
let update url =
  try
    let (oldi,refs,headers) = ImageData.direct_cache_access url in
    let link = { h_uri = Url.string_of url;
         h_context = None;
         h_method = GET;
             h_params = []} in
    let wr = Www.make link in
    let date_received = get_header "date" headers in
    wr.www_headers <- 
       ("If-Modified-Since: "^date_received)
       :: "Pragma: no-cache"
       :: wr.www_headers;

    ImageScheduler.add_request wr (DocumentIDSet.choose !refs)
      (fun url i -> 
    match oldi, i with
      Still (ImagePhoto oldn) , Still (ImagePhoto newn) ->
        Imagephoto.copy oldn newn []
  | _, _ -> ())
      Progress.no_meter

  with
    Not_found ->  (* either not in cache (bogus) or no date *)
      ()
@


\section{Progressing}
% important in a slow word to have some feedback

<<signature Progress.no_meter>>=
val no_meter : Scheduler.progress_func
@

<<signature Progress.meter>>=
val meter : Widget.widget -> Scheduler.progress_func
@

<<constant Progress.no_meter>>=
let no_meter = (fun _ _ -> () : Scheduler.progress_func)
@


<<function Progress.meter>>=
let meter frame =
  (* expected name of "alt" widget *)
  let altw = Widget.atom frame "alt" in
  if Winfo.exists altw then
    (* the progress widget is created on the first call *)
    let bw = lazy (int_of_string (cget frame CBorderWidth)) in
    let width = lazy (Winfo.reqwidth frame - Lazy.force bw * 2)
    and height = lazy (Winfo.reqheight frame - Lazy.force bw * 2) in
    let canv = 
      lazy (
      let c = 
    Canvas.create_named frame "gauge" [ 
    Width (Pixels (Lazy.force width - 2)); (* a kind of magic... *)
    Height (Pixels 3);
    BorderWidth (Pixels 1);
    Relief Sunken ]
      in
      place c [X (Pixels 0); Y (Pixels (Lazy.force height)); Anchor SW];
      c)
    in
    let rect = lazy
      (Canvas.create_rectangle (Lazy.force canv)
     (Pixels 0) (Pixels 0) (Pixels 0) (Pixels 0) 
     [ FillColor okcolor; Outline okcolor])
    in
    let rotate = ref 0 in
    (fun total cur ->
      (* always check that alt widget is still there *)
      if Winfo.exists altw then
    if cur = -1 then
      Canvas.configure_rectangle (Lazy.force canv) (Lazy.force rect)
        [ FillColor kocolor; Outline kocolor]
    else match total with
    | Some cont -> (* expected length is known *)
        let x = 
          if cont = 0 then (Lazy.force width - 2)
          else cur * (Lazy.force width - 2) / cont + 1 in
        Canvas.coords_set (Lazy.force canv) (Lazy.force rect)
          [ Pixels 1; Pixels 1; Pixels x; Pixels 4 ]
    | None -> (* expected length is unknown *)
        if cur <> 0 then begin
          let w = Lazy.force width / 16 in
          Canvas.coords_set (Lazy.force canv) (Lazy.force rect)
           [ Pixels (1 + w * !rotate); Pixels 1; 
          Pixels (1 + w * (!rotate + 2)); Pixels 4 ];
          rotate := (!rotate + 1) mod 15
        end)
  else
    no_meter
@


\section{Scheduling}

<<type Scheduler.progress_func>>=
type progress_func = int option -> int -> unit
@


\chapter{Viewers}
% viewers/


<<type Viewers.t>>=
(* Definition of an internal viewer *)
type t = 
    Http_headers.media_parameter list -> Widget.widget -> 
    context -> handle -> display_info option
@

<<constant Viewers.viewers>>=
let viewers = Hashtbl.create 17
@

<<signature Viewers.add_viewer>>=
val add_viewer : media_type -> t -> unit
    (* [add_viewer type viewer] *)
@
<<signature Viewers.rem_viewer>>=
val rem_viewer : media_type -> unit
@

<<signature Viewers.add_builtin>>=
val add_builtin : media_type -> t -> unit
    (* [add_builtin type viewer] makes viewer a builtin for type *)
@


<<signature Viewers.view>>=
val view : Widget.widget -> context -> handle -> display_info option
@

<<signature Viewers.reset>>=
val reset : unit -> unit
@



<<type Viewers.spec>>=
type spec =
    Internal of t
  | External         (* pass to metamail *)
  | Save	     (* always save *)
  | Interactive	     (* ask what to do about it *)
@

<<constant Viewers.builtin_viewers>>=
let builtin_viewers = ref []
@

<<function Viewers.add_builtin>>=
let add_builtin t v =
  builtin_viewers := (t,v) :: !builtin_viewers
@


<<function Viewers.reset>>=
let reset () =
  (* Reset the viewer table *)
  Hashtbl.clear viewers;
  (* Restore the builtin viewers *)
  List.iter (fun (x,y) -> add_viewer x y) !builtin_viewers;
  (* Preference settings *)
  let l = Tkresource.stringlist "externalViewers" [] in
  List.iter (fun ctype -> 
    try
      let (typ,sub),pars = Lexheaders.media_type ctype in
      Hashtbl.add viewers (typ,sub) External
    with
      Invalid_HTTP_header e ->
    !Error.default#f (I18n.sprintf "Invalid MIME type %s\n%s" ctype e))
    l;
  let l = Tkresource.stringlist "savedTypes" [] in
  List.iter (fun ctype -> 
    try
      let (typ,sub),pars = Lexheaders.media_type ctype in
      Hashtbl.add viewers (typ,sub) Save
    with
      Invalid_HTTP_header e ->
    !Error.default#f (I18n.sprintf "Invalid MIME type %s\n%s" ctype e))
    l
@



\section{XXX}

<<type Viewers.vparams>>=
(* hyper functions are: "goto", "save", "gotonew" *)
type vparams = (string * string) list
@

<<type Viewers.frame_targets>>=
type frame_targets = (string * Widget.widget) list
@

<<signature Viewers.frame_adopt>>=
val frame_adopt : Widget.widget -> frame_targets -> frame_targets
    (* remap _self and _parent *)
@
<<signature Viewers.frame_fugue>>=
val frame_fugue : frame_targets -> frame_targets
    (* forget about _self and _parents *)
@

<<type Viewers.hyper_func>>=
type hyper_func = {
  hyper_visible : bool;
  hyper_title : string;
  hyper_func : frame_targets -> Hyper.link -> unit
  }
@

<<signature Viewers.di_compare>>=
val di_compare : display_info -> display_info -> bool
@


\section{Mime}

\section{Decoders}

<<signature Decoders.insert>>=
val insert  : handle -> handle
@

<<signature Decoders.add>>=
val add : string -> (handle -> handle) -> unit
@

<<constant Decoders.decoders>>=
(* Insert a decoding if necessary.
 * We don't do it in http, since we don't want do decompress when we
 * save for example.
 *)

let decoders = Hashtbl.create 37
@


<<toplevel Decoders._1>>=
let _ =  List.iter (fun (s,t) -> Hashtbl.add decoders s t)
  [ "COMPRESS", gzip;
    "X-COMPRESS", gzip;
    "GZIP", gzip;
    "X-GZIP", gzip]
@


\section{Embedded objects}

<<type Embed.embobject>>=
(* Embedded objects *)
type embobject = {
  embed_hlink : Hyper.link;               (* hyperlink to the object *)
  embed_frame : Widget.widget;  
     (* the frame where the viewers can do their stuff *)
  embed_context : Viewers.context;
  embed_map : Maps.t;                  (* associated map *)
  embed_alt : string
 }
@


<<signature Embed.add>>=
val add : embobject -> unit
@

<<signature Embed.update>>=
val update : 
    Widget.widget -> Viewers.context -> Document.document -> (unit -> unit)
    -> unit
@



<<signature Embed.add_viewer>>=
val add_viewer : 
  Http_headers.media_type -> 
  (Http_headers.media_parameter list -> Widget.widget -> Viewers.context ->
    Document.document -> unit) -> unit
@

<<signature Embed.rem_viewer>>=
val rem_viewer :  Http_headers.media_type -> unit
@


<<constant Embed.embedded_viewers>>=
(* Embedded viewers *)

let embedded_viewers = Hashtbl.create 11
@

<<function Embed.embedded_viewer>>=
let embedded_viewer frame ctx doc =
  (* Destroy the alt window *)
  List.iter Tk.destroy (Winfo.children frame);
  try
    let ctype = contenttype doc.document_info in
    let (typ,subtyp),l = Lexheaders.media_type ctype in
    try
      let viewer = 
    try Hashtbl.find embedded_viewers (typ,subtyp)
        with Not_found -> Hashtbl.find embedded_viewers (typ,"*") in
      viewer l frame ctx doc
    with
    Not_found ->
      let t = 
        I18n.sprintf "Embed Error: no viewer for type %s/%s" typ subtyp in
      let l = Label.create frame [Text t] in pack [l][]
  with
    Not_found ->
      let t = I18n.sprintf "Embed Error: no type for document %s" 
                          (Url.string_of doc.document_address) in 
      let l = Label.create frame [Text t] in pack [l][]
  | Invalid_HTTP_header e ->
      let t = 
       I18n.sprintf "Embed Error: malformed type %s (%s)"
         (contenttype doc.document_info) e in
      let l = Label.create frame [Text t] in pack [l][]
@

\section{[[text/html]]}

\section{[[text/plain]]}

<<function Plain.display_plain>>=
(* Viewing text/plain *)

let display_plain mediapars top vcontext dh =
  let viewer = new plain (top,vcontext,dh) in
  viewer#init;
  Some (viewer :> Viewers.display_info)
@

<<toplevel Plain._1>>=
let _ =
  Viewers.add_builtin ("text","plain") display_plain
@

\chapter{Rendering}
% display/
% layout engine

\section{Display primitives}

\section{Fonts}

\section{Attributes}

\section{HTML compilation}
% from html lexems to instructions to display engine

\section{HTML elememts}

\subsection{HR}

\subsection{Images}

\subsection{Forms}

\subsection{Tables}

\subsection{Frames}

\chapter{CSS}

%http://www.w3.org/TR/CSS2/
% (better spec than CSS 3 according to rubeck, more self contained)

%http://www.w3.org/TR/selectors/#specificity

% rules
% selectors

\section{Lexing}

\section{Parsing}

\chapter{Javascript}

\section{Lexing}

\section{Parsing}


\chapter{Other Features}

\section{Audio}

<<function Audio.fake_embed>>=
(* Defines embedded viewer for audio types as re-running the document *)
let fake_embed media_pars w ctx dh =
  Document.dclose true dh;
  try 
    let hlink = {h_uri = Url.string_of dh.document_id.document_url;
         h_context = None;
         h_method = GET;
         h_params = []} in
    pack [Label.create w [Text "Redispatched externally"]][];
    ctx#goto hlink
  with 
    Not_found (* goto *) -> 
      pack [Label.create w [Text "No navigation given to us"]][]
  | e ->
      pack [Label.create w [Text (Printexc.to_string e)]][]
@

<<toplevel Audio._1>>=
let _ =
  Mmm.add_embedded_viewer ("audio", "*") fake_embed
@



\section{[[mmm_remove]]}

<<function Main_remote.request>>=
let request sock cmd url =
  if cmd <> "" then ignore (write sock cmd 0 (String.length cmd));
  ignore (write sock url 0 (String.length url));
  ignore (write sock "\n" 0 1);
  let buf = String.create 1024 in
  try
    while true do
      let n = read sock buf 0 1024 in
      if n = 0 then raise End_of_file else
      ignore (write stdout buf 0 n)
    done
  with
    End_of_file -> close sock
@

<<function Main_remote.main>>=
let main () =
  let file = 
    Filename.concat (Filename.concat (Sys.getenv "HOME") ".mmm") "remote" in
  let cmd = ref "" in
  
  let s = socket PF_UNIX SOCK_STREAM 0 in
  connect s (ADDR_UNIX file);
  Arg.parse [ 
  "-get", Arg.Unit (fun () -> cmd := "GET "), "Get document";
  "-getbody", Arg.Unit (fun () -> cmd := "GETB "), "Get document body";
  "-head", Arg.Unit (fun () -> cmd := "HEAD "), "Get document headers";
  "-show", Arg.Unit (fun () -> cmd := "DISPLAY "), "Open browser on this URL";
]
    (fun url -> request s !cmd url)
    "Usage: mmm_remote [-get | -getbody | -head | -show] <url>\n
     The default is -show."
@

<<toplevel Main_remote._1>>=
let _ = Printexc.catch main ()
@




\chapter{Concurrency}
% important in browser context, servo was actually started just for that
% could also have an isolation chapter?

\chapter{Optimisations}
% could also have an parallel chapter?

\section{Caches}

\chapter{Security}


\section{Parsing}

<<signature Lexheaders.challenge>>=
val challenge : Lexing.lexbuf -> authChallenge
@

\section{Security challgenge}
% auth
% mv in later chapter? Security?


<<signature Http_headers.challenge>>=
val challenge : header list -> string
  (* WWW-Authenticate *)
@

<<signature Http_headers.proxy_challenge>>=
val proxy_challenge : header list -> string
  (* Proxy-Authenticate *)
@

<<signature Http_headers.expires>>=
val expires : header list -> Http_date.http_time option
  (* Expires *)
@

<<type Http_headers.authScheme>>=
(* Authorisation headers *)
type authScheme =
    AuthBasic
  | AuthExtend of string
@

<<type Http_headers.authChallenge>>=
type authChallenge =
    { challenge_scheme : authScheme;
      challenge_realm : string;
      challenge_params: (string * string) list
    }
@



<<type Auth.authSpace>>=
(* Authorizations are remembered on the base of the directory url and realm
 * They are kept during the whole MMM session, with expiration
 *)
type authSpace = {
   auth_proxy: bool;
   auth_host : string;
   auth_port : int;
   auth_dir : string;
   auth_realm : string
  }
@




<<signature Auth.lifetime>>=
val lifetime : int ref
@

<<signature Auth.auth_file>>=
val auth_file : string ref
@

<<signature Auth.edit>>=
val edit : unit -> unit
@

<<signature Auth.load>>=
val load : unit -> unit
@

<<signature Auth.save>>=
val save : unit -> unit
@

<<signature Auth.add>>=
val add : authSpace -> string -> unit
@

<<signature Auth.get>>=
val get : authSpace -> string
@

<<signature Auth.init>>=
val init : unit -> unit
@

<<signature Auth.check>>=
val check : Www.request -> authChallenge -> authSpace ->
                  (string * bool * authSpace) option
@




<<type Auth.authEntry>>=
type authEntry = {
   auth_cookie : string;
   mutable auth_lastused : float
   }
@

<<constant Auth.authorizations>>=
let authorizations = Hashtbl.create 37
@

<<function Auth.get>>=
let get space = 
  let entry = Hashtbl.find authorizations space in
    entry.auth_lastused <- Unix.time();
    entry.auth_cookie
@

<<constant Auth.lifetime>>=
(* Lifetime, in minutes. Default is one hour *)
let lifetime = ref 60
@

<<function Auth.lookup>>=
let rec lookup space = 
  (* Printf.eprintf "%s\n" space.auth_dir; flush Pervasives.stderr; *)
  try
    Hashtbl.find authorizations space
  with
    Not_found ->
     if space.auth_dir = "/" or space.auth_dir = "." 
     then raise Not_found 
     else
      let newdir = Filename.dirname space.auth_dir in
       lookup {auth_proxy = space.auth_proxy;
               auth_host = space.auth_host;
            auth_port = space.auth_port;
        auth_dir = newdir;
        auth_realm = space.auth_realm}
@

<<function Auth.ask_cookie>>=
let ask_cookie forwhere =
  try
    let u,p = Frx_req.open_passwd forwhere in
      Base64.encode (u^":"^p)
  with
    Failure "cancelled" -> failwith "cancelled"
  | _ -> (!Error.default)#f (I18n.sprintf "Error in base 64 encoding");
        failwith "cancelled"
@

<<function Auth.replace>>=
let replace kind cookie l =
  let rec repl acc = function
    [] -> (kind,cookie)::acc
  | (k,_)::l when k = kind -> repl (acc) l
  | p::l -> repl (p::acc) l in
  repl [] l
@

<<function Auth.add>>=
let add space cookie =
  Log.debug "adding cookie";
  Hashtbl.add authorizations 
      space 
      {auth_cookie = cookie; auth_lastused = Unix.time()}
@

<<function Auth.check>>=
(* Kind is either: realm or proxy *)
let check wwwr challenge authspace =
  let kind = if authspace.auth_proxy then "proxy" else "realm" in
  match challenge.challenge_scheme with
    AuthExtend _ -> (* we don't know how to do this *) 
       None
  | AuthBasic -> (* params are gleefully ignored *)
     try (* if the passwd request is cancelled *)
      let cookie, isnew =
        if List.mem_assoc kind wwwr.www_auth then begin
           (* we already tried, so the authorization is bad ! *)
           Hashtbl.remove authorizations authspace; (* in case *)
           ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm 
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
           true
           end
       else (* ah, it is our first try,  get the authorization *)
         if authspace.auth_proxy then 
            ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
            true
         else
           try 
             let entry = lookup authspace in
              entry.auth_lastused <- Unix.time();
              entry.auth_cookie, false
           with Not_found ->
            ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
            true
      in
      wwwr.www_auth <- replace kind cookie wwwr.www_auth;
      Some (cookie, isnew, authspace)
     with
      Failure "cancelled" -> None
@

<<function Auth.edit>>=
(* needs to be refined *)
let edit () =
  let top =
    Toplevel.create Widget.default_toplevel 
         [Class "MMMAuthorizations"] in
    Wm.title_set top (I18n.sprintf "Authorizations");
    let f,lb = Frx_listbox.new_scrollable_listbox top [TextWidth 40] in
      Hashtbl.iter (fun space cookie ->
       Listbox.insert lb End
      [Printf.sprintf "(%s) http://%s:%d/%s" 
         space.auth_realm space.auth_host space.auth_port space.auth_dir])
       authorizations;
    let buts = Frame.create top [] in
    let clearb = Button.create_named buts "clear"
       [Text (I18n.sprintf "Clear"); 
       Command (fun _ -> Hashtbl.clear authorizations; destroy top)]
    and dismissb = Button.create_named buts "dismiss"
       [Text (I18n.sprintf "Dismiss"); Command (fun _ -> destroy top)] in
      pack [clearb] [Side Side_Left; Expand true];
      pack [dismissb] [Side Side_Right; Expand true];
      pack [buts][Side Side_Bottom; Fill Fill_X];
      pack [f][Side Side_Top; Fill Fill_Both; Expand true]
@

<<constant Auth.auth_file>>=
(* Saving authorizations to file *)
let auth_file = ref ""
@

<<function Auth.save>>=
let save () =
 if !auth_file <> "" then
  let auth_file = Msys.tilde_subst !auth_file in
  try
    let o = openfile auth_file [O_WRONLY; O_CREAT] 0o600 in
    let oc = out_channel_of_descr o in
      output_value oc authorizations;
      flush oc;
      close o
  with
    Unix_error(e,_,_) ->
      !Error.default#f (I18n.sprintf "Error in authorisation save\n%s" 
                 (Unix.error_message e))
  | Sys_error s ->
      !Error.default#f (I18n.sprintf "Error in authorisation save\n%s" s)

 else 
   !Error.default#f (I18n.sprintf "No authorisation file defined")
@

<<function Auth.load>>=
let load () =
  if !auth_file <> "" then
    let auth_file = Msys.tilde_subst !auth_file in
    try
      let ic = open_in auth_file in
      let table = input_value ic
      and time = Unix.time() in
       Hashtbl.iter
          (fun spacerealm entry ->
           entry.auth_lastused <- time;
           Hashtbl.add authorizations spacerealm entry)
          table;
    close_in ic
    with
      Sys_error s ->
       !Error.default#f (I18n.sprintf "Error in authorisation load\n%s" s)
 else 
   !Error.default#f (I18n.sprintf "No authorisation file defined")
@

<<function Auth.init>>=
let init () =
  let check () =
    let remove = ref []
    and lifetime = float (60 * !lifetime)
    and time = Unix.time () in
    Hashtbl.iter 
      (fun space entry ->
       let expiration_time = entry.auth_lastused +. lifetime in
    if time > expiration_time then remove := space :: !remove)
      authorizations;
    List.iter (Hashtbl.remove authorizations) !remove
  in
  let rec tim () =
    Timer.set (!lifetime * 30000) (fun () -> check(); tim ())
  in
  tim ()
@



\chapter{Extra Protocols}


\section{[[file://]]}

<<toplevel Protos._7>>=
let _ = Hashtbl.add protos FILE (File.request, Cache.dummy)
@



<<signature File.request>>=
(* file: protocol *)
val request :  Www.request -> Document.document_continuation -> unit -> unit
    (* [request wr cont] returns [abort] *)
@

<<exception File.File_error>>=
exception File_error of string
@





<<function File.request>>=
(*
 * Display a file on the local unix file system (file:)
 *  is path really supposed to be absolute ?
 * Note: completely ignores method (GET, POST,...)
 *)

let request wr cont =
  let path = match wr.www_url.path with
    Some path -> "/" ^ (Lexurl.remove_dots path)
  | None -> "/" in
  if is_cgi path then (fake_cgi wr cont path; (fun () -> ()))
  else   (* A bit weird, but we don't want to capture errors from the cont *)
  let st =
    try stat path 
    with 
      _ -> raise (File_error (I18n.sprintf "cannot stat file")) in
    match st.st_kind with
    S_REG ->
      begin
      (* check if this is an update *)
        try 
          let since = get_header "if-modified-since" wr.www_headers in
          let ht = Lexdate.ht_of_string since 
          and filet = Http_date.ht_of_stamp st.st_mtime in
          if Http_date.compare filet ht > 0
          then raise Not_found (* fall through *)
          else begin
        let dh = { 
          document_id = document_id wr;
          document_referer = wr.www_link.h_context;
          document_status = 304;
          document_headers = [ sprintf "Date: %s" (Date.asc_now())];
          document_feed = 
             Feed.of_fd (openfile "/dev/null" [O_RDONLY] 0);
          document_fragment = wr.www_fragment;
          document_logger = tty_logger} in
       Retype.f dh;
       cont.document_process dh;
           (fun () -> ())
          end
        with
          Not_found  (* default case *)
        | Lexdate.Invalid_date (_,_) ->
        let s = 
          try openfile path [O_RDONLY] 0
          with Unix_error(_,_,_) -> 
            raise (File_error (I18n.sprintf "cannot open file")) in
       let dh =
          {document_id = document_id wr;
            document_referer = wr.www_link.h_context;
            document_status = 200;
            document_headers = 
            [sprintf "Content-Length: %d" st.st_size;
              sprintf "Date: %s" (Date.asc_now());
              sprintf "Last-modified: %s" (Date.asc st.st_mtime)];
            document_feed = Feed.of_fd s;
            document_fragment = wr.www_fragment;
            document_logger = tty_logger} in
       Retype.f dh;
       cont.document_process dh;
           (fun () -> ())
      end
      | S_DIR -> 
      let s = dir path in
        cont.document_process 
          {document_id = document_id wr;
           document_referer = wr.www_link.h_context;
           document_status = 200;
           document_headers = ["Content-Type: text/html"];
           document_feed = Feed.of_fd s;
           document_fragment = wr.www_fragment;
              document_logger = tty_logger};
            (fun () -> ())

      | _ -> raise (File_error (I18n.sprintf "cannot open file"))
@












<<function File.isdir>>=
(* 
 * Simulate directory
 *)

let isdir path f =
  let fullname = Filename.concat path f in
    (stat fullname).st_kind = S_DIR
@

<<function File.d2html>>=
let d2html path d =
  (* make sure that when path is used in url, it is / terminated *)
  let pathurl =
    let l = String.length path in
    if l = 0 then path else
    if path.[l-1] = '/' then path
    else sprintf "%s/" path
  in
  printf 
"<HTML>
<HEAD><TITLE>%s</TITLE>
<BASE HREF=\"file://localhost%s\">
</HEAD>
<BODY>
<H1>Directory list: %s</H1>
<PRE>" path pathurl path;
  let entries = ref [] in
  begin try
    while true do 
      entries := (readdir d) :: !entries
      done      	
  with 
      End_of_file -> closedir d
  end;
  entries := Sort.list (<=) !entries;
  List.iter (function
      "." -> ()
    | ".." ->
       printf "Dir   <A HREF=\"file://localhost%s\">..</A>\n"
              (Filename.concat (dirname (dirname pathurl)) "")
    | f ->
       try
         let fullname = Filename.concat path f in
     let st = stat fullname in
     match st.st_kind with
       S_DIR -> printf "Dir   <A HREF=\"%s\">%s</A>\n" f f
     | S_REG -> printf "File  <A HREF=\"%s\">%-30s</A>%8d bytes\n" 
                       f f (st.st_size)
     | S_LNK -> printf "Link  <A HREF=\"%s\">%s</A>\n" f f
     | _ -> ()
       with
     Unix_error(_,_,_) -> ())
    !entries;
  printf "</PRE></BODY></HTML>"
@

<<function File.dir>>=
(* It's easiest to do it asynchronously anyway *)
let dir path =
  try
    let d = opendir path in
    let cin, cout = pipe() in
      match Low.fork() with
       0 -> 
      close cin; dup2 cout stdout; close cout;
      begin
        try d2html path d 
        with e ->
          print_endline (Printexc.to_string e)
      end;
      flush Pervasives.stdout; (* strange bug with our at_exit stuff *)
      exit 0;
      cin (*duh*)
      | n -> closedir d; close cout; cin
  with
    Unix_error(_,_,_)  -> 
      raise (File_error (I18n.sprintf "cannot open dir"))
@

<<function File.document_id>>=
let document_id wwwr =
  { document_url = wwwr.www_url; document_stamp = no_stamp}
@

<<function File.fake_cgi>>=
(* Not true CGI interface, just a hack *)
(* TODO: headers ? *)
let fake_cgi wwwr cont path =
  try 
    let (cmd_in, cmd_out) = pipe() in
    let cmd, args = 
      try 
       let pos = String.index path '?' in
    let cmd = String.sub path 0 pos in
    if pos + 1 = String.length path then cmd, [| cmd |]
    else 
         cmd, [|cmd; String.sub path (pos+1) (String.length path - pos - 1)|]
      with
       Not_found -> path, [| path |] in
    match Low.fork() with
      0 -> 
       close cmd_in;
    dup2 cmd_out stdout; close cmd_out;
    begin try execvp cmd args 
    with
      Unix_error(e, _, _) ->
       Munix.write_string stdout "HTTP/1.0 404 Not found\r\n";
       Munix.write_string stdout "Content-Type: text/html\r\n\r\n";
       Munix.write_string stdout "<H1>Cannot execute local file</H1>";
       Munix.write_string stdout "Command \"";
       Munix.write_string stdout cmd;
       Munix.write_string stdout "\" failed:";
       Munix.write_string stdout (Unix.error_message e);
       Munix.write_string stdout "\n";
       exit 1
    end
    | n ->
         close cmd_out;
     let dh = {document_id = document_id wwwr;
           document_referer = wwwr.www_link.h_context;
           document_status = 0;
           document_headers = [];
           document_feed = Feed.of_fd cmd_in;
           document_fragment = wwwr.www_fragment;
           document_logger = tty_logger} in
      dh.document_feed.feed_schedule
        (fun () ->
           try
         if dh.document_headers = [] then begin
           (* it should be the HTTP Status-Line *)
            let l = Munix.read_line cmd_in in
              dh.document_status <- (parse_status l).status_code;
              dh.document_headers <- [l] (* keep it there *)
            end
          else 
            dh.document_headers <- 
              read_headers cmd_in dh.document_headers
           with
         End_of_headers ->
           dh.document_feed.feed_unschedule();
           cont.document_process dh
           | Not_found -> (* No HTTP/ header *)
           dh.document_feed.feed_unschedule();
           dh.document_status <- 200;
               dh.document_headers <- ["Content-Type: text/plain"];
           cont.document_process dh
           | Unix_error(_,_,_) ->
           dclose true dh;
               raise (File_error (I18n.sprintf 
               "Error while reading headers of %s\n%s" path "(read)"))
           | Invalid_HTTP_header s ->
           dclose true dh;
           raise (File_error (I18n.sprintf 
                  "Error while reading headers of %s\n%s" path s))
           | End_of_file ->
           dclose true dh;
           raise (File_error (I18n.sprintf 
               "Error while reading headers of %s\n%s" path "eof"))
          )
  with Unix_error(_,_,_) -> 
    raise (File_error (I18n.sprintf "cannot exec file"))
@

<<constant File.binary_path>>=
(* Pref stuff *)
let binary_path = ref ([] : string list)
@

<<constant File.r>>=
let r = Str.regexp ":"
@


% ???
<<signature File.pref_init>>=
val pref_init : Textvariable.textVariable -> unit
@
<<signature File.pref_set>>=
val pref_set  : Textvariable.textVariable -> unit
@



<<function File.pref_init>>=
let pref_init v =
  Textvariable.set v (String.concat ":" !binary_path)
@

<<function File.pref_set>>=
let pref_set v = 
  binary_path :=
     List.map Msys.tilde_subst (Str.split r (Textvariable.get v))
@

<<function File.is_cgi>>=
let is_cgi file =
  match !binary_path with
    [] -> false
  | path ->
      let l = String.length file in
      List.exists (fun dir ->
    let ldir = String.length dir in
    l > ldir && String.sub file 0 ldir = dir)
    path
(*
 * Display a file on the local unix file system (file:)
 *  is path really supposed to be absolute ?
 * Note: completely ignores method (GET, POST,...)
 *)
@



\section{[[mailto://]]}
% see extra

\section{Proxied protocols}

<<toplevel Protos._1>>=
let _ = Hashtbl.add protos FTP (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._3>>=
let _ = Hashtbl.add protos GOPHER (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._4>>=
let _ = Hashtbl.add protos NEWS (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._5>>=
let _ = Hashtbl.add protos NNTP (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._6>>=
let _ = Hashtbl.add protos WAIS (Http.proxy_req, Cache.tobuffer)
@


<<function Http.prox_req>>=
and proxy_req wr cont = 
  let cnx = proxy_request wr cont in
    (fun () -> cnx#abort)
@


<<function Http.proxy_request>>=
(* Process an HTTP request using the proxy.
   We pass on the continuation *)
and proxy_request wr cont =
  tcp_connect !proxy !proxy_port wr.www_logging
          (start_request true wr cont)
          (failed_request wr cont.document_finish)
@

<<global Http.proxy>>=
(* Default proxy definitions *)
let proxy = ref "no-proxy-defined"
@

<<global Http.proxy_port>>=
let proxy_port = ref 80
@

\chapter{Advanced Topics}

\section{Encodings}

% base64, 8859, url encode, etc.

\subsection{Base 64}

<<signature Base64.encode>>=
(* Base64 encoding (ONLY for Basic authentication) *)
val encode : string -> string
@

<<signature Base64.decode>>=
val decode : string -> string
@

<<constant Base64.index64>>=
(* For basic credentials only *)
(* Encoding is [A-Z][a-z][0-9]+/= *)
(* 3 chars = 24 bits = 4 * 6-bit groups -> 4 chars *)

let index64 = Array.create 128 0
(* Init the index *)
@

<<toplevel Base64._1>>=
(* Init the index *)
let _ =
  for i = 0 to 25 do index64.(i + Char.code 'A') <- i done;
  for i = 0 to 25 do index64.(i + Char.code 'a') <- i + 26 done;
  for i = 0 to 9 do  index64.(i + Char.code '0') <- i + 52 done;
  index64.(Char.code '+') <- 62;
  index64.(Char.code '/') <- 63
@

<<function Base64.decode>>=
let decode s =
  let rpos = ref 0
  and wpos = ref 0
  and len = String.length s in
  let res = String.create (len / 4 * 3) in
    while !rpos < len do
      let v1 = index64.(Char.code s.[!rpos]) in
      let v2 = index64.(Char.code s.[!rpos + 1]) in
      let v3 = index64.(Char.code s.[!rpos + 2]) in
      let v4 = index64.(Char.code s.[!rpos + 3]) in
      (* each char gives 6 bits *)
      let i = (v1 lsl 18) lor (v2 lsl 12) lor (v3 lsl 6) lor v4 in
      res.[!wpos] <- Char.chr (i lsr 16);
      res.[!wpos+1] <- Char.chr ((i lsr 8) land 0xFF);
      res.[!wpos+2] <- Char.chr (i land 0xFF);
      rpos := !rpos + 4;
      wpos := !wpos + 3
      done;
  let cut = 
    if s.[len - 1] = '=' then
      if s.[len - 2] = '=' then 2
      else 1
    else 0 
  in
  String.sub res 0 (String.length res - cut)
@

<<constant Base64.char64>>=
let char64 = Array.create 64 'a'
@

<<toplevel Base64._2>>=
let _ =
  for i = 0 to 25 do char64.(i) <- Char.chr (Char.code 'A' + i) done;
  for i = 0 to 25 do char64.(i+26) <- Char.chr (Char.code 'a' + i) done;
  for i = 0 to 9 do char64.(i+52) <- Char.chr (Char.code '0' + i) done;
  char64.(62) <- '+';
  char64.(63) <- '/'
@

<<function Base64.encode>>=
(* Encoding *)
let encode s =
  let rpos = ref 0 
  and wpos = ref 0 in
  let origlen = String.length s in
  let s,len = match origlen mod 3 with
      0 -> s, origlen
    | 1 -> s ^ "\000\000", origlen + 2
    | 2 -> s ^ "\000", origlen + 1 
    | _ -> assert false
  in
  let res = String.create (len / 3 * 4) in
    while !rpos < len do
      let i1 = Char.code s.[!rpos] in
      let i2 = Char.code s.[!rpos+1] in
      let i3 = Char.code s.[!rpos+2] in
      let i = (i1 lsl 16) lor (i2 lsl 8) lor i3 in
      res.[!wpos] <- char64.((i lsr 18) land 0x3f);
      res.[!wpos+1] <- char64.((i lsr 12) land 0x3f);
      res.[!wpos+2] <- char64.((i lsr 6) land 0x3f);
      res.[!wpos+3] <- char64.(i land 0x3f);
      rpos := !rpos + 3;
      wpos := !wpos + 4
      done;
  (* Correct padding *)
  for i = 1 to len - origlen do res.[String.length res - i] <- '=' done;
  res
@


\section{i18n}

<<function Main.localize>>=
let localize file =
  let localized = spf "%s.%s" file !I18n.language in
  if Sys.file_exists localized 
  then localized 
  else file
@





<<signature Lang.lang>>=
val lang : unit -> string
@

<<function Lang.lang>>=
let lang () =
  if !japan then "ja"
  else "iso8859"
@


<<signature I18n.message_file>>=
val message_file : string ref
@

<<signature I18n.language>>=
val language : string ref
@

<<signature I18n.sprintf>>=
val sprintf: ('a, unit, string) format -> 'a
@

<<signature I18n.menu_option>>=
@

<<signature I18n.menu_pattern>>=
@





<<function I18n.fprintf>>=
(* Internationalization (translation of error messages) *)

let fprintf x = 
  if !Lang.japan then I18nprintf.fprintf x else Printf.fprintf x
@

<<function I18n.sprintf>>=
let sprintf x = 
  if !Lang.japan then I18nprintf.sprintf x else Printf.sprintf x
@

<<constant I18n.language>>=
let language = ref ""
@

<<constant I18n.message_file>>=
let message_file = ref ""
@

<<function I18n.read_transl_file>>=
let read_transl_file msgfile =
  let ic = open_in msgfile in
  let tag_buffer = String.create 16
  and msg_buffer = String.create 1024 in
  let rec store_tag c i =
    if i >= 16 then i else (tag_buffer.[i] <- c; succ i)
  and store_msg c i =
    if i >= 1024 then i else (msg_buffer.[i] <- c; succ i)
  and read_line i =
    match input_char ic with
      '\n' -> i
    | '\\' -> begin match input_char ic with
                '\\' -> read_line(store_msg '\\' i)
              | 'n'  -> read_line(store_msg '\n' i)
              | '\n' -> skip_blanks i
              | c    -> read_line(store_msg c (store_msg '\\' i))
              end
    | c    -> read_line(store_msg c i)
  and skip_blanks i =
    match input_char ic with
      ' '|'\t' -> skip_blanks i
    | c        -> read_line(store_msg c i)
  and read_tag i =
    match input_char ic with
      ':'           -> (i, skip_blanks 0)
    | ' '|'\n'|'\t' -> read_tag i
    | c             -> read_tag(store_tag c i) in
  let transl_tbl = Hashtbl.create 37 in
  let currsrc = ref "" in
  begin try
    while true do
      let (tag_len, msg_len) = read_tag 0 in
      if String.sub tag_buffer 0 tag_len = "src" then
        currsrc := String.sub msg_buffer 0 msg_len
      else if String.sub tag_buffer 0 tag_len = !language then
        Hashtbl.add transl_tbl !currsrc (String.sub msg_buffer 0 msg_len)
      else ()
    done
  with End_of_file ->
    close_in ic
  end;
  transl_tbl
@

<<type I18n.translation_table>>=
type translation_table =
    Unknown
  | NoTranslation
  | Transl of (string, string) Hashtbl.t
@

<<constant I18n.transl_table>>=
let transl_table = ref Unknown
@

<<function I18n.translate>>=
let rec translate msg =
  match !transl_table with
    NoTranslation ->
      msg
  | Transl tbl ->
      begin try Hashtbl.find tbl msg with Not_found -> msg end
  | Unknown ->
      transl_table :=
        if String.length !language == 0 then
          NoTranslation
        else begin
          try
            if Sys.file_exists !message_file then	   
              Transl(read_transl_file !message_file)
            else NoTranslation
          with Sys_error _ | Sys.Break ->
            NoTranslation
        end;
      translate msg
@

<<function I18n.fprintf (./commons/i18n.ml)>>=
let fprintf oc (fmt : ('a, out_channel, unit) format) =
  fprintf oc
    (Obj.magic(translate(Obj.magic fmt : string)) :
                                ('a, out_channel, unit) format)
@

<<function I18n.sprintf (./commons/i18n.ml)>>=
let sprintf (fmt : ('a, unit, string) format) =
  sprintf
    (Obj.magic(translate(Obj.magic fmt : string)) :
                                ('a, unit, string) format)

@

<<function I18n.menu_option>>=
@

<<exception I18n.Found>>=
@

<<function I18n.menu_pattern>>=
@

\subsection{Accents}

<<constant Html.ampersand_table>>=
(* 
 * HTML encoding of ISO-latin1 characters
 *  cf Appendix B - Proposed Entities
 *)

let ampersand_table = (Hashtbl.create 101: (string , string) Hashtbl.t)
@

<<constant Html.latin1_normal>>=
let latin1_normal = [
  "amp", 	"&";
  "gt", 	">";
  "lt" , 	"<";
  "quot", 	"\"";
  "nbsp", 	"\160"; (* non-breaking space *)
  "iexcl",	"\161"; (*  inverted exclamation mark *)
  "cent", 	"\162"; (*  cent sign*)
  "pound",	"\163"; (*  pound sterling sign*)
  "curren",	"\164"; (*  general currency sign*)
  "yen",	"\165"; (*  yen sign*)
  "brvbar",	"\166"; (*  broken (vertical) bar *)
  "sect",	"\167"; (*  section sign *)
  "uml",	"\168"; (*  umlaut (dieresis) *)
  "copy",	"\169"; (*  copyright sign *)
  "ordf",	"\170"; (*  ordinal indicator, feminine *)
  "laquo",	"\171"; (*  angle quotation mark, left *)
  "not",	"\172"; (*  not sign *)
  "shy",	"\173"; (*  soft hyphen *)
  "reg",	"\174"; (*  registered sign *)
  "macr",	"\175"; (*  macron *)
  "deg",	"\176"; (*  degree sign *)
  "plusmn",	"\177"; (*  plus-or-minus sign *)
  "sup2",	"\178"; (*  superscript two *)
  "sup3",	"\179"; (*  superscript three *)
  "acute",	"\180"; (*  acute accent *)
  "micro",	"\181"; (*  micro sign *)
  "para",	"\182"; (*  pilcrow (paragraph sign) *)
  "middot",	"\183"; (*  middle dot *)
  "cedil",	"\184"; (*  cedilla *)
  "sup1",	"\185"; (*  superscript one *)
  "ordm",	"\186"; (*  ordinal indicator, masculine *)
  "raquo",	"\187"; (*  angle quotation mark, right *)
  "frac14",	"\188"; (*  fraction one-quarter *)
  "frac12",	"\189"; (*  fraction one-half *)
  "frac34",	"\190"; (*  fraction three-quarters *)
  "iquest",	"\191"; (*  inverted question mark *)
  "Agrave", 	"\192";	(*  capital A, grave accent *)
  "Aacute", 	"\193";	(*  capital A, acute accent *)
  "Acirc", 	"\194";	(*  capital A, circumflex accent *)
  "Atilde", 	"\195";	(*  capital A, tilde *)
  "Auml", 	"\196";	(*  capital A, dieresis or umlaut mark *)
  "Aring", 	"\197";	(*  capital A, ring *)
  "AElig", 	"\198";	(*  capital AE diphthong (ligature) *)
  "Ccedil", 	"\199";	(*  capital C, cedilla *)
  "Egrave", 	"\200";	(*  capital E, grave accent *)
  "Eacute", 	"\201";	(*  capital E, acute accent *)
  "Ecirc", 	"\202";	(*  capital E, circumflex accent *)
  "Euml", 	"\203";	(*  capital E, dieresis or umlaut mark *)
  "Igrave", 	"\204";	(*  capital I, grave accent *)
  "Iacute", 	"\205";	(*  capital I, acute accent *)
  "Icirc", 	"\206";	(*  capital I, circumflex accent *)
  "Iuml", 	"\207";	(*  capital I, dieresis or umlaut mark *)
  "ETH", 	"\208";	(*  capital Eth, Icelandic *)
  "Ntilde", 	"\209";	(*  capital N, tilde *)
  "Ograve", 	"\210";	(*  capital O, grave accent *)
  "Oacute", 	"\211";	(*  capital O, acute accent *)
  "Ocirc", 	"\212";	(*  capital O, circumflex accent *)
  "Otilde", 	"\213";	(*  capital O, tilde *)
  "Ouml", 	"\214";	(*  capital O, dieresis or umlaut mark *)
  "times",	"\215"; (*  multiply sign*)
  "Oslash", 	"\216";	(*  capital O, slash *)
  "Ugrave", 	"\217";	(*  capital U, grave accent *)
  "Uacute", 	"\218";	(*  capital U, acute accent *)
  "Ucirc", 	"\219";	(*  capital U, circumflex accent *)
  "Uuml", 	"\220";	(*  capital U, dieresis or umlaut mark *)
  "Yacute",	"\221"; (*  capital Y, acute accent *)
  "THORN", 	"\222";	(*  capital THORN, Icelandic *)
  "szlig", 	"\223";	(*  small sharp s, German (sz ligature) *)
  "agrave", 	"\224";	(*  small a, grave accent *)
  "aacute", 	"\225";	(*  small a, acute accent *)
  "acirc", 	"\226";	(*  small a, circumflex accent *)
  "atilde", 	"\227";	(*  small a, tilde *)
  "auml", 	"\228";	(*  small a, dieresis or umlaut mark *)
  "aring", 	"\229";	(*  small a, ring *)
  "aelig", 	"\230";	(*  small ae diphthong (ligature) *)
  "ccedil", 	"\231";	(*  small c, cedilla *)
  "egrave", 	"\232";	(*  small e, grave accent *)
  "eacute", 	"\233";	(*  small e, acute accent *)
  "ecirc", 	"\234";	(*  small e, circumflex accent *)
  "euml", 	"\235";	(*  small e, dieresis or umlaut mark *)
  "igrave", 	"\236";	(*  small i, grave accent *)
  "iacute", 	"\237";	(*  small i, acute accent *)
  "icirc", 	"\238";	(*  small i, circumflex accent *)
  "iuml", 	"\239";	(*  small i, dieresis or umlaut mark *)
  "eth", 	"\240";	(*  small eth, Icelandic *)
  "ntilde", 	"\241";	(*  small n, tilde *)
  "ograve", 	"\242";	(*  small o, grave accent *)
  "oacute", 	"\243";	(*  small o, acute accent *)
  "ocirc", 	"\244";	(*  small o, circumflex accent *)
  "otilde", 	"\245";	(*  small o, tilde *)
  "ouml", 	"\246";	(*  small o, dieresis or umlaut mark *)
  "divide",	"\247"; (*  divide sign *)
  "oslash", 	"\248";	(*  small o, slash *)
  "ugrave", 	"\249";	(*  small u, grave accent *)
  "uacute", 	"\250";	(*  small u, acute accent *)
  "ucirc", 	"\251";	(*  small u, circumflex accent *)
  "uuml", 	"\252";	(*  small u, dieresis or umlaut mark *)
  "yacute", 	"\253";	(*  small y, acute accent *)
  "thorn", 	"\254";	(*  small thorn, Icelandic *)
  "yuml", 	"\255" 	(*  small y, dieresis or umlaut mark *)
  ]
@


\section{Applets}

<<signature Version.applet_init>>=
(*-*)
val applet_init : (bool -> unit) ref
@
<<constant Version.applet_init>>=
(* Make it easier to compile both bytecode and native versions *)
let applet_init = ref (fun _ -> ())
@


\chapter{Conclusion}

\appendix

\chapter{Debugging}

<<signature Log.debug_mode>>=
val debug_mode : bool ref
@

<<signature Log.f>>=
val f : string -> unit
@

<<signature Log.debug>>=
val debug : string -> unit
@

<<constant Log.debug_mode>>=
let debug_mode = ref false
@

<<function Log.f>>=
(* flushes ! *)
let f s = try prerr_endline s with _ -> ()
@

<<function Log.debug>>=
let debug s = if !debug_mode then f s 
@





\section{Subsystems}

\subsection{Tty}

<<signature type logger>>=
type logger
@

<<signature Document.tty_logger>>=
val tty_logger : logger
@

<<type Document.logger>>=
type logger = {
  logger_destroy : bool -> unit;
  logger_progress : int -> unit;
  logger_msg : string -> unit;
  logger_end : string -> unit
}
@

<<constant Document.tty_logger>>=
let tty_logger = 
  { logger_destroy = (fun _ -> ());
    logger_progress = (fun _ -> ());
    logger_msg = Log.f;
    logger_end = Log.f
   }
@

\subsection{HTML}

<<signature Html.verbose>>=
val verbose : bool ref
  (* verbose mode for HTML related stuff *)
@
<<constant Html.verbose>>=
let verbose = ref false
@

<<function Html.warning>>=
let warning s (Loc(n,m)) = 
  if !verbose then begin 
    eprintf "HTML Warning: %s at (%d, %d)\n" s n m;
    flush stderr
   end
@


<<signature Html_eval.debug>>=
(* HTML Evaluation *)

val debug : bool ref
@

<<constant Html_eval.debug>>=
let debug = ref false
@

\subsection{Caches}

<<signature Cache.debug>>=
(* Configurable settings *)
val debug : bool ref
@

<<constant Cache.debug>>=
let debug = ref false
@

\subsection{Scheduler}

<<signature Scheduler.debug>>=
(*
 * Certain kind of documents need to be shared, such as in-lined images.
 * In this case, instead of working with Retrieve.f and the normal
 * document continuation, we queue the request to a scheduler, with a
 * continuation to be applied to an object representing the shared 
 * information for that document.
 * E.G: for in-lined images, the shared information is the Tk-handle to
 * the image.
 *)

val debug : bool ref
@
<<constant Scheduler.debug>>=
let debug = ref false 
@

\subsection{GUI}

<<function Debug.init>>=
let init () =
  Frx_rpc.register "cb" active_cb;
  Frx_rpc.register "cache"
     (fun _ -> Cache.postmortem(); Gcache.postmortem(); flush stderr);
  Frx_rpc.register "images" (fun _ -> Img.ImageData.dump(); flush stderr);
  Frx_rpc.register "camltkdb" (fun _ -> Protocol.debug := not !Protocol.debug)
@

<<function Debug.active_cb>>=
let active_cb _ =
  let cnter = ref 0 in
  Hashtbl.iter 
    (fun w id ->
      incr cnter;
      Printf.fprintf stdout "%s %s %b\n"
        (Widget.name w) (string_of_cbid id) (Winfo.exists w))
    callback_memo_table;
  Printf.fprintf stdout "Memo cb: %d\n" !cnter;
  cnter := 0;
  Hashtbl.iter (fun _ _ -> incr cnter) callback_naming_table;
  Printf.fprintf stdout "Active cb: %d\n" !cnter;
  flush stdout
@


\section{Dumpers}

\subsection{URLs}

<<signature Url.string_of_protocol>>=
val string_of_protocol: protocol -> string
  (* maps FTP to "ftp", etc... *)
@

<<signature Url.string_of>>=
(* These are used to get "normalized urls" *)
val string_of: t -> string
@


<<function Url.string_of_protocol>>=
let string_of_protocol = function
   FTP -> "ftp"
 | HTTP -> "http"
 | GOPHER -> "gopher"
 | MAILTO -> "mailto"
 | NEWS -> "news"
 | NNTP -> "nntp"
 | TELNET -> "telnet"
 | WAIS -> "wait"
 | FILE -> "file"
 | PROSPERO -> "prospero"
 | OtherProtocol s -> s
@


<<function Url.string_of>>=
let string_of p =
  let buf = Ebuffer.create 128 in
  let ws = Ebuffer.output_string buf
  and wc = Ebuffer.output_char buf in
  let write_userpass () =
      match p.user, p.password with
        None, None -> ()
       | Some u, Some p -> ws u; wc ':'; ws p; wc '@'
       | Some u, None ->   ws u; wc ':'; wc '@'
       | None, Some _ -> failwith "url_of_parsed"
  (* hostname is always put in lowercase *)
  and write_hostport def =
      match p.host, p.port with
        None, None -> ()
       | Some h, None -> ws (String.lowercase h)
       | Some h, Some p when p = def -> ws (String.lowercase h)
       | Some h, Some p -> 
      ws (String.lowercase h); wc ':'; ws (string_of_int p)
       | None, Some _ -> failwith "url_of_parsed"	    

  and write_pathsearch () =
      match p.path, p.search with
       None, None -> wc '/'
      | Some p, Some s -> wc '/'; ws p; wc '?'; ws s
      | Some p, None -> wc '/'; ws p
      | None, Some _ -> failwith "url_of_parsed"	    

  and write_slashpath () =
      match p.path with
       None -> ()
      | Some p -> wc '/'; ws p
  and write_path () =
      match p.path with
       None -> ()
      | Some p -> ws p
  and write_fhost () =
      match p.host with
       None -> ws "localhost"
      | Some h -> ws (String.lowercase h)
  in
  begin match p.protocol with
    FTP ->
      ws "ftp://"; write_userpass (); write_hostport 21; write_slashpath ()
  | HTTP ->
      ws "http://"; write_hostport 80; write_pathsearch ()
  | GOPHER ->
      ws "gopher://"; write_hostport 70; write_slashpath ()
  | MAILTO -> ws "mailto:"; write_path()
  | NEWS -> ws "news:"; write_path()
  | NNTP -> ws "nntp:"; write_hostport 119; write_path()
  | TELNET -> ws "telnet://"; write_userpass(); write_hostport 23
  | WAIS -> ws "wais://"; write_hostport 210; write_pathsearch()
  | FILE ->
    (* for file: we have to transform to ftp: if host is not localhost *)
    begin match p.host with
      None | Some "localhost" ->
        ws "file://"; write_fhost(); write_slashpath()
    | Some h ->
       p.protocol <- FTP;
        ws "ftp://"; write_userpass (); write_hostport 21; write_slashpath ()
    end
  | PROSPERO -> ws "prospero://"; write_hostport 1525; write_slashpath()
  | OtherProtocol s -> ws s; ws ":"; write_path()
  end;
  Ebuffer.get buf
@

\subsection{Links}

<<signature Hyper.string_of>>=
val string_of : link -> string
  (* make an absolute URI (including fragment) from link 
     raises Invalid_link(msg) *)
@

<<function Hyper.string_of>>=
let string_of link =
  let uri = resolve link in
   match uri.uri_frag with 
      None -> uri.uri_url
    | Some f -> Printf.sprintf "%s#%s" uri.uri_url f
@

\subsection{DTDs}

<<signature Dtd.dump>>=
val dump : t -> unit
@

<<function Dtd.dump>>=
let dump dtd =
  Hashtbl.iter (fun s contents -> 
      printf "Element %s %s %s\n" s 
             (if Elements.mem s dtd.open_omitted then "O" else "-")
             (if Elements.mem s dtd.close_omitted then "O" else "-");
      printf "Contains:";
      Elements.iter (fun e -> printf " %s" e) contents;
      printf "\n")
    dtd.contents
@

\subsection{HTML}

<<signature Html.print>>=
val print : token -> unit
  (* for debugging, prints an HTML token *)
@


<<function Html.print>>=
let print = function
    PCData s -> eprintf "PCData: %s\n" s
  | CData s -> eprintf "CData: %s\n" s
  | OpenTag {tag_name = n; attributes = l} ->
            eprintf "Open: %s\n" n;
         List.iter (function (a,v) ->
                   eprintf "%s=%s\n" a v) l
  | CloseTag n -> eprintf "Close: %s\n" n
  | Comment s -> eprintf "Comment: %s\n" s
  | Doctype s -> eprintf "Doctype: %s\n" s
  | EOF -> eprintf "EOF\n"
@

\chapter{Profiling}

\chapter{Error Managment}

\section{[[Error.t]]}

<<signature class Error.t>>=
class virtual t : object
 method virtual f : string -> unit
 method virtual ok : string -> unit
 method virtual choose : string -> bool
 method virtual ari : string -> int
end
@


<<signature Error.default>>=
val default : t ref
@
<<constant Error.default>>=
let default = ref (new x)
@



<<signature Error.f>>=
val f : string -> unit
@
<<signature Error.ok>>=
val ok : string -> unit
@
<<signature Error.choose>>=
val choose : string -> bool
@
<<signature Error.ari>>=
val ari : string -> int
@

<<functions Error.xxx>>=
let f msg = !default#f msg
and ok msg = !default#ok msg
and choose msg = !default#choose msg
and ari msg = !default#ari msg
@

<<class Error.t>>=
@

\section{URL}

<<exception Url.Url_Lexing>>=
exception Url_Lexing of string * int
@

<<exception Url.Invalid_url>>=
exception Invalid_url of t * string
@

\section{Links}

<<type Hyper.link_error>>=
type link_error =
    LinkResolve of string
  | UrlLexing of string * int
@

<<exception Hyper.Invalid_link>>=
exception Invalid_link of link_error
@

\section{Requests}

<<exception Www.Invalid_request>>=
exception Invalid_request of request * string
@

\section{HTML}

<<exception Html.Html_Lexing>>=
exception Html_Lexing of string * int
@

<<exception Html.Invalid_Html>>=
exception Invalid_Html of string
@

<<signature Html.warning>>=
val warning : string -> location -> unit
@

\chapter{A Preferences Library}

\chapter{Standard Library}

<<constant Common.spf>>=
let spf = Printf.sprintf
@

<<function Common.TODOOPERATOR>>=
let (|>) o f = f o
@

\section{Lists}

<<signature Mlist.hdn>>=
(* List utilities *)
val hdn : 'a list -> int -> 'a list
   (* [hdn [a1;a2;...;an;...; ak] returns [a1;a2;...;an] *)
@

<<signature Mlist.tln>>=
val tln : 'a list -> int -> 'a list
   (* [tln [a1;a2;...;an;...; ak] returns [an+1;...; ak] *)
@

<<signature Mlist.except_assoc>>=
val except_assoc: 'a -> ('a * 'b) list -> ('a * 'b) list
@

<<signature Mlist.exceptq>>=
val exceptq: 'a -> 'a list -> 'a list
@

<<signature Mlist.rev_do_list>>=
val rev_do_list : ('a -> unit) -> 'a list -> unit
@

<<signature Mlist.do_listi>>=
val do_listi : (int -> 'a -> unit) -> int -> 'a list -> unit
@




<<function Mlist.tln>>=
(* tln l n *)
let rec tln l = function
   0 -> l
 | n -> if l = [] then [] else tln (List.tl l) (pred n)
@

<<function Mlist.hdn>>=
let hdn l =
  let rec h l acc = function
    0 -> List.rev acc
  | n -> if l = [] then List.rev acc 
        else h (List.tl l) (List.hd l :: acc) (pred n) in
  h l []
@

<<function Mlist.except_assoc>>=
let except_assoc x =
  let rec ex acc = function 
      [] -> acc
    | (y,v)::l when x = y -> ex acc l
    | z :: l -> ex (z::acc) l
  in
  ex []
@

<<function Mlist.exceptq>>=
let exceptq x =
  let rec ex acc = function
     [] -> acc
   | y::l when y == x -> ex acc l
   | y::l -> ex (y::acc) l
  in
  ex []
@

<<function Mlist.rev_do_list>>=
(* List.iter from right to left *)
let rev_do_list f = 
 let rec do_list_f = function
     [] -> () | x::l -> do_list_f l; f x in
  do_list_f
@

<<function Mlist.do_listi>>=
let rec do_listi f n l =
  match l with
    [] -> ()
  | (x::l) -> f n x; do_listi f (succ n) l
@

\section{Strings}

<<signature Mstring.split_str>>=
(* String utilities *)
val split_str : (char -> bool) -> string -> string list
@

<<signature Mstring.get_suffix>>=
val get_suffix : string -> string
@

<<signature Mstring.hex_to_dec>>=
val hex_to_dec : char -> int
@

<<signature Mstring.dec_to_hex>>=
val dec_to_hex : int -> char
@

<<signature Mstring.hex_to_string>>=
val hex_to_string : string -> string
@

<<signature Mstring.gensym>>=
val gensym : string -> string
@

<<signature Mstring.egensym>>=
val egensym : string -> unit -> string
@

<<signature Mstring.rem_trailing_sp>>=
val rem_trailing_sp : string -> string
@

<<signature Mstring.catenate_sep>>=
val catenate_sep : string -> string list -> string
@

<<signature Mstring.norm_crlf>>=
val norm_crlf : bool -> string -> int -> int -> string * bool
    (* [norm_crlf last_was_cr buf offs len] returns
       buf with CRLF/CR/LF converted to LF, and a flag indicating
       whether last char was CR *)
@




<<function Mstring.split_str>>=
(* split a string according to char_sep predicate *)
let split_str char_sep str =
  let len = String.length str in
  if len = 0 then [] else
    let rec skip_sep cur =
      if cur >= len then cur
      else if char_sep str.[cur] then skip_sep (succ cur)
      else cur  in
    let rec split beg cur =
      if cur >= len then 
    if beg = cur then []
    else [String.sub str beg (len - beg)]
      else if char_sep str.[cur] 
       then 
         let nextw = skip_sep cur in
          (String.sub str beg (cur - beg))
        ::(split nextw nextw)
       else split beg (succ cur) in
    let wstart = skip_sep 0 in
    split wstart wstart
@

<<function Mstring.get_suffix>>=
(* extract the . suffix (dot excluded) of a string *)
let get_suffix s =
  try
    let dotpos = succ (String.rindex s '.') in
      String.sub s dotpos (String.length s - dotpos)
  with
    Not_found -> ""
@

<<function Mstring.hex_to_dec>>=
(* HEX/DEC conversions *)
let hex_to_dec c = match c with
    '0'..'9' -> Char.code c - 48
  | 'a'..'f' -> Char.code c - 87 (* 87 = Char.code 'a' - 10 *)
  | 'A'..'F' -> Char.code c - 55 (* 55 = Char.code 'A' - 10 *)
  | _ -> failwith "hex_to_dec"
@

<<function Mstring.dec_to_hex>>=
let dec_to_hex i =
  if i < 10 then Char.chr (i + 48)  (* 48 = Char.code '0' *)
  else Char.chr (i + 55)            (* 55 = Char.code 'A' - 10 *)
@

<<function Mstring.hex_to_string>>=
(* Converting a hex stored string *)
let hex_to_string s =
  let len = String.length s / 2 in
  let res = String.create len in
    for i = 0 to len - 1 do
      res.[i] <- Char.chr ( 16 * (hex_to_dec s.[i+i]) + hex_to_dec s.[i+i+1])
      done;
    res
@

<<constant Mstring.gensym>>=
let gensym =
  let cnter = ref 0 in
  (fun n ->
    incr cnter;
    n ^ string_of_int !cnter)
@

<<function Mstring.egensym>>=
let egensym s =
  let cnter = ref 0 in
  (fun () ->
    incr cnter;
    s ^ string_of_int !cnter)
@

<<function Mstring.rem_trailing_sp>>=
let rem_trailing_sp s =
  let l = String.length s in
  let pos = ref (l - 1) in
  while !pos >= 0 && List.mem s.[!pos] [' '; '\t'] do decr pos done;
  if !pos = l - 1 then s
  else String.sub s 0 (succ !pos)
@

<<function Mstring.catenate_sep>>=
let catenate_sep sep =
  function 
      [] -> ""
    | x::l -> List.fold_left (fun s s' -> s^sep^s') x l
@

<<function Mstring.norm_crlf>>=
(* Filters CRLF:
 *  CR -> LF
 *  CRLF -> LF
 *  LF -> LF
 * We do this on successive chunks of a stream, so we need to consider
 * the case when the chunk finishes on CR.
 * Assume len > 0
 *)

let norm_crlf lastwascr buf offs len =
  let rpos = ref offs
  and wpos = ref 0
  and dest = String.create (len + 1) (* we need one more char *)
  and limit = offs + len - 1  
  and lastiscr = ref false in
  if lastwascr then
    if buf.[!rpos] = '\n' then begin
      dest.[!wpos] <- '\n';
      incr rpos; incr wpos
    end
    else begin
      dest.[!wpos] <- '\n'; incr wpos
    end;

  while !rpos < limit do
    match buf.[!rpos] with
      '\n' -> dest.[!wpos] <- '\n'; incr rpos; incr wpos
    | '\r' -> 
    if buf.[!rpos + 1] = '\n'
    then begin dest.[!wpos] <- '\n'; rpos := !rpos + 2; incr wpos end
    else begin dest.[!wpos] <- '\n'; incr rpos; incr wpos end
    | c -> dest.[!wpos] <- c; incr rpos; incr wpos 
  done;
  begin match buf.[offs+len-1] with
    '\n' -> dest.[!wpos] <- '\n'; incr wpos
  | '\r' -> lastiscr := true
  | c -> dest.[!wpos] <- c; incr wpos
  end;
  String.sub dest 0 !wpos, !lastiscr
@

\section{Files}

<<signature Msys.tilde_subst>>=
val tilde_subst : string -> string
    (* substitute ~ at beginning of file path *)
@

<<signature Msys.rm>>=
val rm: string -> unit
    (* quiet unlink *)
@

<<signature Msys.fsize>>=
val fsize: string -> int
    (* file size *)
@

<<signature Msys.mktemp>>=
val mktemp : string -> string
@

<<function Msys.next_slash>>=
(* skip to next / *)
let rec next_slash s n =
  if  n >= String.length s or s.[n] = '/' 
  then n
  else next_slash s (succ n)
@

<<function Msys.tilde_subst>>=
let tilde_subst s =
 try
  if s = "" or s.[0] <> '~' then s 
  else
    let len = String.length s in
    if len = 1 then Sys.getenv "HOME"
    else match s.[1] with
      '/' -> 
        Filename.concat (Sys.getenv "HOME") (String.sub s 2 (len - 2))
     | _ ->
       let final = next_slash s 1 in
       let user = String.sub s 1 (pred final) in
       let pwnam = getpwnam user in
         if succ final >= len then pwnam.pw_dir
         else
          Filename.concat pwnam.pw_dir 
               (String.sub s (succ final) (len - (succ final)))
 with
    Unix_error(_,_,_) -> s
  | Sys_error _ -> s
  | Not_found -> s
@

<<function Msys.rm>>=
(* Quiet unlink *)
let rm s = try unlink s with Unix_error _ -> ()
@

<<function Msys.rmdir>>=
let rmdir dir =
  try
    let dh = opendir dir 
    and l = ref [] in
    try while true do
      let f = readdir dh in
      if f <> "." && f <> ".." then l := f :: !l
    done
    with
      End_of_file -> 
    closedir dh;
    List.iter (fun f -> rm (Filename.concat dir f)) !l;
    Unix.rmdir dir
  with
    Unix_error _ -> ()
@

<<function Msys.fsize>>=
let fsize f =
  try (Unix.stat f).st_size
  with Unix_error(_,_,_) -> raise Not_found
@

<<constant Msys.tmp_dir>>=
let tmp_dir = ref "/tmp"
@

<<constant Msys.mktemp>>=
(* We know use our own private directory in /tmp, cleared at exit-time,
   so no one can snoop our temporary files *)
let mktemp =
  let cnter = ref 0 
  and pid = Unix.getpid() 
  and id = ref 0 in
  let thisdir = 
    let testdir = ref "" in
    try while true do
      testdir := Filename.concat !tmp_dir ("mmm" ^ string_of_int pid
                         ^ "_" ^ string_of_int !id);
      if not (Sys.file_exists !testdir) then raise Exit;
      incr id;
      if !id >= 16 then 
    raise (Failure ("Too many MMM temporary directory in " ^ !tmp_dir ^
            ". Clean them first."))
    done; "" (* cannot reach *)
    with
      Exit -> !testdir
  in
  Unix.mkdir thisdir 0o700;
  at_exit (fun () -> rmdir thisdir);
  (function prefx -> 
      incr cnter; 
      (Filename.concat thisdir (prefx ^ string_of_int !cnter)))
@


\section{Dates}


<<signature Date.asc_wkday>>=
val asc_wkday : int -> string
    (* [asc_wkday n] maps 0..6 to Sun..Sat *)
@

<<signature Date.asc_month>>=
val asc_month : int -> string
    (* [asc_month n] maps 0..11 to Jan..Dec *)
@

<<signature Date.asc>>=
val asc : float -> string
    (* [asc uxtime] RFC822 of unix time *)
@

<<signature Date.asc_now>>=
val asc_now : unit -> string
    (* [asc_now ()] RFC822 of now *)
@

<<signature Date.commonlog>>=
val commonlog : float -> string
  (* Text version (Common log format) of an Unix time value *)
@

<<signature Date.compare_time>>=
val compare_time : int list * int list -> int
    (* [compare_time l1 l2] compare lists encodings of timestamps
       Encoding must be:
        [year; month; mday; hour; min; sec]
     *)
@



<<function Date.asc_wkday>>=
let asc_wkday = function
   0 -> "Sun"
 | 1 -> "Mon"
 | 2 -> "Tue"
 | 3 -> "Wed"
 | 4 -> "Thu"
 | 5 -> "Fri"
 | 6 -> "Sat"
 | _ -> assert false
@

<<function Date.asc_month>>=
let asc_month = function
   0 -> "Jan"
 | 1 -> "Feb"
 | 2 -> "Mar"
 | 3 -> "Apr"
 | 4 -> "May"
 | 5 -> "Jun"
 | 6 -> "Jul"
 | 7 -> "Aug"
 | 8 -> "Sep"
 | 9 -> "Oct"
 | 10 -> "Nov"
 | 11 -> "Dec"
 | _ -> assert false
@

<<function Date.asc>>=
(* Produces RFC822 style *)
let asc ut =
  let tm = gmtime ut in
    sprintf "%s, %02d %s %d %02d:%02d:%02d GMT"
        (asc_wkday tm.tm_wday)
    tm.tm_mday
    (asc_month tm.tm_mon)
    (tm.tm_year + 1900)
    tm.tm_hour
    tm.tm_min
    tm.tm_sec
@

<<function Date.asc_now>>=
let asc_now () = asc (time())
@

<<function Date.commonlog>>=
(* Timezone ??? *)
let commonlog int =
  let tm = localtime int in
  sprintf "%02d/%s/%d:%02d:%02d:%02d"
      tm.tm_mday
      (asc_month tm.tm_mon)
      (tm.tm_year + 1900)
      tm.tm_hour
      tm.tm_min
      tm.tm_sec
@

<<function Date.compare_time>>=
let rec compare_time = function
   [], [] -> 0
 | (x::xx), (y::yy) when x = y -> compare_time (xx, yy)
 | (x::_), (y::_) when x < y -> -1
 | (x::_), (y::_) when x > y -> 1
 |  _, _ -> assert false
@



\chapter{Extra Code}

\ifallcode
#include "Browser_extra.nw"
\fi

\chapter{Changelog}
\label{sec:changelog}

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
URL  = Uniform Resource Locator
URI  = Universal Resource Identifier
HTML =
DOM  = Document Object Model
CSS  = Cascading Style Sheets
JS   = Javascript
HTTP =
WWW  = World Wide Web
MIME = ??
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{99}

% see mmm-gdr-fr.ps biblio, main RFCs are there.

\bibitem[1]{wp-literate-programming} Donald Knuth,,
{\em Literate Programming}, 
\url{http://en.wikipedia.org/wiki/Literate\_Program}

\bibitem[2]{noweb} Norman Ramsey,
{\em Noweb}, 
\url{http://www.cs.tufts.edu/~nr/noweb/}

\bibitem[3]{syncweb} Yoann Padioleau,
{\em Syncweb, literate programming meets unison}, 
\url{http://padator.org/software/project-syncweb/readme.txt}

\end{thebibliography}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}

