\documentclass[twocolumn]{report}

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, changed for the better a few things:
% - deadcode?

%thx to codemap/codegraph/scheck:
% - use cg to reduce backward deps (but ocaml linker enforces that),
%   and to reduce dependencies to graphic toolkit tk
%   (harder to understand non layered code)
% - TODO use scheck to remove deadcode, dead prototypes, useless export
%   or mv as forward decl
%   (harder to understand big interface files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand web browsers?:
% - TODO encodings, accents, base64, iso8559, etc
% - TODO better understand html, cs, js?

%history LP-ization:
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * TODO ctor/dtor, dumper
%    * TODO [[xxx]] other fields, [[xxx]] extra fields
% - SEMI read Extra section, identify concepts, first TOC
% - SEMI distribute parts of the Extra section in the main file
% - TODO understand main(), LP split main, improve TOC
% - TODO understand main functions, LP split, cluster, improve TOC
% - TODO LP split the structures, use datalog for flow to field info
% - TODO nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - TODO aspecify advanced features! remove useless features
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{xspace}
\usepackage{verbatim}
%note: required by noweblatexpad for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\iffinal
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\fi
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
%\usepackage{cleveref} %\cref
%\usepackage{multirow}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}
 %\usepackage[margin=0.5in]{geometry}
 %  but eat the bottom when very low
 %\usepackage{fullpage} is deprecated 
 % => do the more manual below:
 \addtolength{\oddsidemargin}{-.850in}
 \addtolength{\evensidemargin}{-.850in}
 \addtolength{\textwidth}{1.70in}
 \addtolength{\topmargin}{-.850in}
 \addtolength{\textheight}{1.70in}
%\usepackage{minitoc}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% used for forward decl, pragmas, func decl, extern decl, stats, #ifdef,
% debugging macros

%\setcounter{tocdepth}{1}

%******************************************************************************
% Title
%******************************************************************************

\begin{document}

\title{
{\Huge 
Principia Softwarica: The Web Browser [[mmm]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}
}

\maketitle 
\onecolumn
\hrule
\begin{quote}
    Copyright \copyright{} 2015 Yoann Padioleau \\
    Permission is granted to copy, distribute and/or modify this document,
    except all the source code it contains, under the terms of the GNU Free
    Documentation License, Version 1.3.
\end{quote}
\hrule

%CONFIG: \dominitoc

\iffinal
\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\twocolumn
\tableofcontents
\endgroup
\else
\tableofcontents
\fi

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

\section{Motivations}

The goal of this book is to present in full details the source code of
a web browser.
Why? Because I think it makes you a better programmer if
you fully understand how things work under the hood.

% chose mmm, written in ocaml, small, elegant.

Here are other candidates that were considered but ultimately discarded:
\begin{itemize}
\item nexus
% original one, objective C, 8000 LOC?
\item mosaic
% maybe good. but 130 000 LOC (vs 30 000 LOC for mmm)
\item gecko (firefox)
% descendant of mosaic, netscape, introduced IMG
% huge now
\item khtml/webkit/blink (kconqueror, chrome, safari)
% started from scratch by kde people originally, now used by google/apple
% huge
\item netsurf
% with subprojects like hubhub, libcss, libdom, etc
%... was used originally by servo
\item servo
% already lots of LOC actually
% https://github.com/servo/servo/wiki/Design
\end{itemize}

% see wikipedia page on history of web browser, pretty good,
% I have it printed.
%todo: my todo-browser/ somewhere

%todo:
%https://github.com/servo/servo/wiki/Relevant-spec-links

%good: http://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html
%todo: http://www.html5rocks.com/en/tutorials/internals/howbrowserswork/
% HBW

%todo: look at ocamlnet? more up to date web components?

\section{Getting started}

\section{Requirements}

\section{About this document}
#include "docs/latex/About.nw"

\section{Copyright}

Most of this document is actually source code from MMM, so
those parts are copyright by INRIA.

<<copyright header v6>>=
(***********************************************************************)
(*                                                                     *)
(*                           The V6 Engine                             *)
(*                                                                     *)
(*          Francois Rouaix, projet Cristal, INRIA Rocquencourt        *)
(*                                                                     *)
(*  Copyright 1996 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@

The prose is mine and is licensed under the GNU Free Documentation
License.

\section{Acknowledgments}

I would like to thank of course Francois Rouaix
the main author of MMM.


\chapter{Overview}

\section{Web browser principles}

% before seing the browser, first expose web principles: world wide web.
% a "web" of interconnected machines with:
%  - "resources": html documents, images
%  - URL to reference a resource; an html document contains itself
%    possible links to other documents or resources (e.g. images) => a web
%  - http protocol to fetch the resources
%  - client/server around this protocol

% a web browser is then a special kind of interface on top of that:
% a navigator interface! (history, forward, click etc).
% One important thing is that it must provide feedback, especially
% when connect with network, you want to see if something is stucked
% or is progressing (hence the complex passing of continuation,
% error hook, etc)

% see mmm-gdr-fr.ps


%"The main function of a browser is to present the web resource you
%choose, by requesting it from the server and displaying it in the
%browser window. The resource is usually an HTML document, but may also
%be a PDF, image, or some other type of content. The location of the
%resource is specified by the user using a URI (Uniform Resource
%Identifier)." HBW

\section{[[mmm]] services}

<<constant Main.usage_str>>=
let usage_str =
  "Usage: meuh <opts> <initial url>"
@
% meuh :)

<<signature Version.http>>=
val http : string              (* the version in User-Agent field *)
@
% full_request -> std_request_headers -> user_agent (alias <>)
<<constant Version.http>>=
(* User-Agent field *)
let http = "MMM/0." ^ string_of_int number
@

<<signature Version.number>>=
(* Version and other builtin strings *)
val number : int
@
<<constant Version.number>>=
(* Version *)
let number = 418
@



<<signature Version.about>>=
val about : string -> string   (* dialog *)
@
<<function Version.about>>=
(* dialog uses an gigantic font ! *)
let about = function
  | "iso8859" ->
"MMM Version 0." ^ version_number ^
"\nWritten by Fran\231ois Rouaix
Contributions by Jun P. Furuse and Jacques Garrigue
Ported to O'Caml 3 by Jun P. Furuse and Pierre Weis
\169 Copyright INRIA

Projet Cristal
INRIA Rocquencourt
Domaine de Voluceau
78153 Le Chesnay Cedex
France

Francois.Rouaix@inria.fr
http://pauillac.inria.fr/~rouaix/
"
  | s -> failwith (Printf.sprintf "language not supported: %s" s)
@
%old: assert false



<<constant Version.version_number>>=
let version_number = 
  string_of_int number
@


\section{HTML document language}

\section{[[hello.html]]}


\section{CSS style language}

\section{[[hello.css]]}

\section{Javascript dynamic language}

\section{[[hello.js]]}

\section{Code organization}

% commons/: utilities
% globals/: config
% www/: uri, url, request
% html/: html parsing
% http/: http protocol
% protocols/: more protocols
% retrieve/: networking stuff, connexions
% viewers/: viewing stuff
% display/: rendering engine
% gui/: chrome

% skipped for now: 
% i18n/japan/ 
% applets/ sandbox/ crcs/ 
% extensions/
% demos/ 

\section{Software architecture}

% complicated archi in the end, because need to handle
% network error, user action such as abort, timeout,
% and want to have multiple requests going at the same time
% possibly (if have many tabs), so it's a mini OS in some sense,
% managing multiple tasks. Don't want a slow server
% to hang the whole thing, so need to manage async requests,
% and so have callbacks (called continuation here) when things
% are ready.

\section{Trace of a web request}
% enter url in address bar and type enter, what happens?
% lots of components involved I think

\section{Trace of a mouse click}

% see mmm-gdr-fr.ps
% mouse click -> fetch doc (async), wait server, header parsing, 
%  adequat viewer, 

%###############################################################################

\chapter{Core Data Structures}

% url -> uri -> link -> request, bigger and bigger structure
% and then
% request -> document -> data -> ast

\section{URLs and co}

% url -> uri -> link -> request, bigger and bigger structure

% URLs are URIs? who is more general?
% URL is uniform, URIs is universal, so URI is more general

\subsection{URLs and protocols, [[Url.t]]}
% =~ protocol://user:pass@host:port/paths?search
% (not too bad syntax)

<<type Url.t>>=
(* URLs as defined by RFC 1738 *)

(* Not all components are used for all protocols. See RFC. *)
type t = 
  { mutable protocol : protocol;

    mutable user : string option;
    mutable password: string option;

    mutable host : string option;
    mutable port : int option;

    mutable path : string option;

    mutable search: string option
  }
@
% search?
% "Relative adressing in anchors, fragments are NOT URLs, but URI" ???
% to say that there is no fragment here, anchor = #xxx
%less: need to be mutable? really?

<<type Url.protocol>>=
type protocol =
 | HTTP 
 | FILE | FTP
 | MAILTO | NNTP
 | GOPHER | NEWS | WAIS | PROSPERO
 | TELNET 
 | OtherProtocol of string
@

% will see later parsing function for url
% Lexurl.make()

\subsection{URIs, [[Uri.abs_uri]]}
% =~ http://..../path/elements/foo.html#fragment
% =~ URL + fragment

<<type Uri.abs_uri>>=
(* URI utilities. RFC 1630 *)

type abs_uri = {
   uri_url : string;
   uri_frag : string option
 }
@
%abs for absolute! we want those URI to have been "resolved"
%fragment is for the #xxx
%  "Relative adressing in anchors, fragments are NOT URLs, but URI" ???
%less: uri_url, hmmm should be uri_path no?
%less: why not parse uri_url and make it a Url.t?


<<signature Uri.is_absolute>>=
val is_absolute : string -> bool
   (* [is_absolute uri] determines if [uri] is absolute according to
      rules of RFC 1630 *)
@
<<function Uri.is_absolute>>=
(* RFC 1630, partial forms *)
let is_absolute uri =
  try
    let colonpos = String.index uri ':' in
    try 
      let slashpos = String.index uri '/' in
      colonpos < slashpos (* colon must occur before slash *)
    with
      Not_found -> true (* colon occurs before slash *)
  with
    Not_found -> false (* absolute must have a : *)
@
% ?? examples? 
% unit tests!

\subsection{Hypertext Links, [[Hyper.link]]}
%=~ <a href="..."> with implicit METHOD=GET

<<type Hyper.link>>=
(* An hypertext(media) link on the Web *)
type link = {
  h_uri : string;
  h_context: string option;

  h_method : link_method;		(* default is GET *)
  h_params : (string * string) list
}
@
% context? useful for relative uri, seems to be a URL too.
% Why not parse h_uri? and make it a Uri.t?

<<type Hyper.link_method>>=
(* This is currently for HTTP and derived, but ... *)
(* Contains only the one we support *)
type link_method =
   GET 
 | HEAD
 | POST of string
@
% HEAD?

\subsection{Web requests, [[Www.request]]}
% =~ url + some state info in the browser (e.g. authentification, cookie?)

<<type Www.request>>=
(*
 * Requests
 *)
type request =  { 
    www_link : Hyper.link;        (* the link that produced this request *)

    www_url : Url.t;	          (* parsed version *)
    www_fragment : string option; (* because viewer is passed down *)

    mutable www_auth : (string * string) list;  (* basic auth *)
    mutable www_headers : string list;		  (* additional headers *)

    mutable www_logging : string -> unit;	  (* logging *)
    mutable www_error : Error.t;
  }
@
% fragment is for the URI, the #xxx
%less: merge www_url in link?
%less: LP split fields
%todo: why need pass the logger? can't just use a global
% logger always? which flexibility it brings?
% www_logging, document_logger, Log.f, too many no?
%it's ok though probably to have a www_error, because
% we may want to print the error message of the request at different
% places (e.x. if use different tabs)

<<signature Www.make>>=
val make : Hyper.link -> request
  (* raises: Url_Lexing | Invalid_link *)
@
<<function Www.make>>=
let make hlink =
  let absuri = Hyper.resolve hlink in 
  let url = Lexurl.make absuri.uri_url in
  try (* search for space in network URI *)
    if List.mem url.protocol [FILE; MAILTO] 
    then raise Not_found
    else
      (* will raise Not_found if no space found *)
      let n = Str.search_forward sp absuri.uri_url 0 in
      raise (Hyper.Invalid_link (Hyper.UrlLexing ("suspicious white space", n)))
  with Not_found -> 
    { www_link = hlink;

      www_url = url; (* should not fail ? *)
      www_fragment = absuri.uri_frag;

      www_auth = [];
      www_headers = [];

      www_logging = (fun _ -> ());
      www_error = !Error.default
    }
@
%todo: abuse exn too much, the regular flow is actually the exceptional flow

<<constant Www.sp>>=
let sp = Str.regexp "[ \t\n]"
@

% will see later Hyper.resolve and Lexurl.make


\section{Documents}

<<type Document.document>>=
type document = {
  mutable document_data : document_data;

  document_address : Url.t; (* origin? *)
  document_info : string list
}
@
%less: LP split document_info?
%note that it's a mutable field!

% used by Protos.get
<<type Document.document_data>>=
(*
 * Information on a document, as could be requested by "other" clients,
 * that is clients not directly on the chain of processes dealing with
 * the handle
 *)

type document_data =
 | MemoryData of Ebuffer.t
 | FileData of string * bool (* flag is true if file is temporary *)
@
%less: the comment is enigmatic

\subsection{Document ID}

<<type Document.document_id>>=
(* Document Id is a reference to a document in the browser.
   For some documents, e.g. results of POST queries, the URL is not a
   sufficient description. Stamp is 0 for unique documents.
*)
type document_id = {
  document_url : Url.t;
  document_stamp : int
}
@

<<signature Document.no_stamp>>=
val no_stamp : int
@
<<constant Document.no_stamp>>=
let no_stamp = 0
@



<<constant Document.stamp_counter>>=
let stamp_counter = ref 0
@
<<signature Document.new_stamp>>=
val new_stamp : unit -> int
@
<<function Document.new_stamp>>=
let new_stamp () =
  incr stamp_counter; !stamp_counter
@


% get a new document_id!
<<signature Document.document_id>>=
val document_id : Www.request -> document_id
@
<<function Document.document_id>>=
let document_id wwwr =
  match wwwr.www_link.h_method with
  | POST _  ->
         { document_url = wwwr.www_url; document_stamp = new_stamp()}
  | _ -> { document_url = wwwr.www_url; document_stamp = no_stamp}
@



<<module Document.DocumentIDSet>>=
module DocumentIDSet =
  Set.Make(struct type t = document_id let compare = compare end)
@


\subsection{Document cache}

<<signature Cache.add>>=
val add : document_id -> document -> unit
@
<<signature Cache.find>>=
val find : document_id -> document
@
% see below
<<signature Cache.finished>>=
val finished : document_id -> unit
@
% will see add and finished later in optimisation section.
<<signature Cache.touch>>=
val touch : document_id -> unit
@
% refresh for cache


<<signature Cache.kill>>=
val kill : document_id -> unit
@
%less: diff with finished?


<<constant Cache.memory>>=
let memory = ref ([] : (Document.document_id * entry) list)
@

<<type Cache.entry>>=
(* A cache entry *)
type entry = {
  mutable cache_document : Document.document;

  mutable cache_pending : bool;
  cache_condition : Condition.t;

  mutable cache_lastused : float
      (* cache_lastused is specified as max_int (0x3fffffff) when we don't
       * want the entry to be flushed. This will break around
       * Sat Jan 10, 2004 13:37 GMT on 32 bits machines
       *) (* JPF: it is now float! max_int -> max_float *)
  }
@
%less: LP split?
%todo: hmm the comment seems to indicate it's a bad thing in 2015 :)

<<constant Cache.max_lastused>>=
let max_lastused = 100000000000.0
@


<<function Cache.find>>=
(* Find a document*)
let find did =
  let entry = List.assoc did !memory in
  entry.cache_lastused <- Unix.time();
  if entry.cache_pending 
  then Condition.wait entry.cache_condition;
  entry.cache_document
@

% add, will see later

% hmm but what is the value of cache_document at first when we
% don't have the data yet, that the cache is pending?
% should be document option no?

\section{Protocols and document flow}

% Nav.request -> Retrieve.f -> <>
<<signature Protos.get>>=
val get: Url.protocol ->
  (Www.request -> Document.document_continuation -> 
      (unit -> unit)) 
  *
  (Document.handle -> 
      Document.document_data * Cache.cache_fill)
@
% will see below what are those Document.xxx
%less: define a record type?
% the unit -> unit is actually a returned aborter hook! so caller
%  can abort the request, maybe could do a type?

<<constant Protos.protos>>=
let protos = Hashtbl.create 11
@

<<constant Protos.get>>=
let get = Hashtbl.find protos
@

%will see code like:
%<<toplevel Protos._2>>=
%let _ = Hashtbl.add protos HTTP (Http.req, Cache.tobuffer)
%@

\subsection{Document continuation}

% used by Protos.get
<<type Document.document_continuation>>=
type document_continuation = {
  document_process : handle -> unit;
    (* What to do one we have a dh on the real document *)
  document_finish :  bool -> unit
    (* What to do if a request does not yield a document *)
}
@
% to pass to the protocol handler, callback to called
% when he got the data.
% bool is true when things were aborted

% often build a serie of continuations for document_process
% where you add some intermediate processing.
% ex:
%  let foo doc_cont ... =
%     let req,cache = Protos.get request.www_url.protocol in
%      Started (req request
%        { doc_cont with
%          document_process = http_check cache retry doc_cont request})

\subsection{Document handle}


% used by Protos.get
<<type Document.handle>>=
(* This is passed around by request continuations. It represents a handle
   on a connexion for retrieving a document *)
type handle = {
  document_id : document_id;

  mutable document_status : int;
    (* Status code of response *)

  document_feed : Feed.t;
    (* where to get the data *)

  document_referer : string option;
    (* URL of refering document, if any *)
  mutable document_headers : string list;
    (* HTTP headers of document, or faked ones *)
  document_fragment : string option;
    (* fragment (#foo) if any *)


  mutable document_logger : logger
    (* how to log information relative to this document processing *)
}
@
%less: typedef for document_status int?
%todo: LP split!
%less: why not take Www.request and put it here? so less need to
% have document_headers, fragment
%note: this will be produced by the http_req, and then
% passed to the document_continuation.document_process,
% which then will pass it down to the Cache.tobuffer

% TODO: figure with the flow! who is building the handle, who
%  is consuming it

\section{HTTP}

% apparently mmm handles http 1.0 and 0.9
% there is also 1.1.
% 2.0 just got published I think

%(* HTTP messages: requests and responses
% *  What a client sends to a server is called a request 
% *  What a server answers is called a response
% *)

\subsection{Requests}

%todo: rename messages.mli to http_messages.mli?

<<type Messages.request_message>>=
(* HTTP-Message *)
type request_message = {
  request : request;

  request_auth : (string * string) option;
           (* have we authentified the emitter (authtype, authuser) *)
  request_headers : header list;

  request_body : string;
}
@
%less: aspectize security
% diff with Www.request? it also has _headers and _auth.
% but Www.request is the general case for any request (file://, mailto://)
% here request_message is the Www.request specialized for http:/
%what is body? Www.request didn't have that. It's a subpart of
% Www.www_headers?

<<type Messages.request>>=
(* Request-Line of a Request *)
type request = {
  request_version: string;	(* HTTP/1.0 *)
  request_method : string;	(* GET, POST, etc... *)

  request_uri : string		(* the uri *)
}
@
%less: why not use method type for request_method instead of a string?


<<type Messages.header>>=
(* Other headers *)
type header = string
@


\subsection{Responses}

<<type Messages.response_message>>=
type response_message = {
  status : status;

  response_headers : header list;
  response_body : string;        (* responde body is *not* the document body *)
}
@

% ok so we will get some response, and then we
% need to transform that into a document handle that then
% can be processed by the http independent core of mmm

<<type Messages.status>>=
(* Status-Line of a Response *)
type status =  { 
    status_version : string;	(* HTTP/1.0 *)
    status_code : int;		(* http return codes *)
    status_message : string	(* http return message *)
}
@






\section{DOM}

%https://dom.spec.whatwg.org/

\section{Abstract syntax trees}

% html
% css
% js

\subsection{HTML}

<<type Html.token>>=
type token =
 | OpenTag of tag
 | CloseTag of string

 | PCData of string
 | CData of string

 | Comment of string
 | Doctype of string

 | EOF
@
%less: need doctype? diff PCData and CData?
% where is the tree? the full AST?
% token is really the main thing returned
% by the lexer/parser. You have to rebuild the tree from it
% but it is easy since the tokens contain Opentag, Closetag, etc
%less: could do such a dumper, a la pfff


%https://html.spec.whatwg.org/multipage/introduction.html#a-quick-introduction-to-html

<<type Html.tag>>=
type tag = {
  tag_name : string;
  attributes: attributes
}
@

%concepts:
% - tags
% - attributes
% - entities
% - ???

<<type Html.attributes>>=
type attributes = (attribute_name * attribute_value) list
@

<<type Html.attribute_name>>=
(* HTML tokens *)
type attribute_name = string 
@
<<type Html.attribute_value>>=
type attribute_value = string
@



\subsection{CSS}

\subsection{Javascript}





\section{Viewers}

\subsection{[[Viewers.context]]}

<<signature class Viewers.context>>=
(* The context given to a viewer *)
(* Standard hyper functions are: "goto", "save", "gotonew" *)
class virtual context : (Document.document_id * vparams) -> object ('a)

  method base : Document.document_id
  method params : vparams

  method goto : Hyper.link -> unit
  method gotonew : Hyper.link -> unit
  method save : Hyper.link -> unit
  method invoke : string -> Hyper.link -> unit    

  method virtual log : string -> unit
  method add_nav : string * hyper_func -> unit
  (*-*)
  method for_embed : vparams -> frame_targets -> 'a
  method in_embed : Document.document_id -> 'a
  method hyper_funs : (string * hyper_func) list

  (* pad: this is just because of some bugs in camlp4o *)
  method with_target: frame_targets -> 'a
  method with_viewer_params: (string * string) list -> 'a

end
@

<<type Viewers.vparams>>=
(* hyper functions are: "goto", "save", "gotonew" *)
type vparams = (string * string) list
@
% ???

\subsection{[[Viewers.display_info]]}

<<signature class Viewers.display_info>>=
class  virtual display_info : (unit) -> object ('a)
  method virtual di_widget : Widget.widget
  method virtual di_abort : unit		(* stop display *)
  method virtual di_destroy : unit		(* die *)
  method virtual di_fragment : string option -> unit	(* for # URIs *)
  method virtual di_redisplay : unit		(* redisplay *)
  method virtual di_title : string		(* some visible title *)
  method virtual di_source : unit 	        (* source viewer *)
  method virtual di_load_images : unit	        (* load images *)
  method virtual di_update : unit
  method di_last_used : int
  method di_touch : unit
end
@


\section{Display}

\chapter{[[main()]]}

<<[[Main.main()]] locals>>=
let init_urls = ref [] in
@
% possible command line arguments, 
%   $ mmm http://www.google.com

% _ -> Main.postmortem -> <>
<<function Main.main>>=
let main () =
  <<[[Main.main()]] tk backends setup>>

  (* As always, we must parse argument first, using references... *)
  <<[[Main.main()]] locals>>
  Arg.parse [
   <<[[Main.main()]] command line options>>
  ]
    (fun s -> init_urls := s :: !init_urls)
    usage_str
  ;
  <<[[Main.main()]] signal handling>>
  <<[[Main.main()]] initialisation>>

  let url_opt = 
    match !init_urls with 
    | []     -> None 
    | x :: l -> Some x
  in
  let user_preferences_file =
    <<[[Main.main()]] user preferences file>>
  in
  (* Start the initial navigator *)
  Mmm.initial_navigator user_preferences_file url_opt;

  safe_loop();
  <<[[Main.main()]] after event loop, if debug mode>>
  ()
@
%$



\ifallcode
<<[[Main.main()]] tk backends setup>>=
Error.default                    := new Tk_error.t Widget.default_toplevel;
Condition.backend                := Tk_condition.backend ();
Timer_.add_ref                   := (fun a b -> Timer.add a b |> ignore);
Timer_.set_ref                   := Timer.set;
Low.update_idletasks_backend     := Tk.update_idletasks;
Fileevent_.add_fileinput_ref     := Fileevent.add_fileinput;
Fileevent_.remove_fileinput_ref  := Fileevent.remove_fileinput;
Fileevent_.add_fileoutput_ref    := Fileevent.add_fileoutput;
Fileevent_.remove_fileoutput_ref := Fileevent.remove_fileoutput;
Document.add_log_backend         := Tk_document.add_log;
Maps.broadcast_backend           := Frx_synth.broadcast;
Auth.open_passwd_ref             := Frx_req.open_passwd;
Auth.edit_backend                := Tk_auth.edit;
Mailto.internal_backend          := Tk_mailto.internal;
@
\fi



\section{Initialisations}

<<[[Main.main()]] initialisation>>=
<<[[Main.main()]] tk initialisation>>
<<[[Main.main()]] resource initialisation>>
<<[[Main.main()]] tk libs initialisation>>
<<[[Main.main()]] local initialisation>>
<<[[Main.main()]] suffix initialisation>>
<<[[Main.main()]] misc initialisation>>
<<[[Main.main()]] html entities initialisation>>
<<[[Main.main()]] applet system initialisation>>
<<[[Main.main()]] mmm server initialisation>>
@
% for suffix, html entities, applet and mmm server, see
% in later chapters.

\subsection{Graphics initialisation}

<<[[Main.main()]] tk initialisation>>=
let top = Tk.openTkDisplayClass !display "mmm" in
Wm.withdraw top;
@
% withdraw??

%(*
%(* Just after the init. of Tk, we have to detect the Tk is under
% * Latin or Japanese mode at first. 
% *)
%Lang.japan := Jtk.is_japanese_mode () && Lang.is_japanese ();
%(* Run Tcl in JIS (ISO2022-jp) Mode *)
%if !Lang.japan 
%then Jtk.Kanji.internal_code_set Jtk.JIS;
%*)


% main -> Tk.openTkDisplayClass(<>)
<<[[Main.main()]] locals>>=
let display = ref (try Sys.getenv("DISPLAY") with Not_found -> "") in
@
<<[[Main.main()]] command line options>>=
"-d", Arg.String (fun s -> display := s),
"<foo:0>\t\tDisplay";
@
<<[[Main.main()]] command line options>>=
"-display", Arg.String (fun s -> display := s),
"<foo:0>\tDisplay";
@



<<[[Main.main()]] tk libs initialisation>>=
(* Initialisations in frx library : kbd navigation, search 
 * No prerequisite except Tk *)
Frx_text.init ();
(* Initialisations in jpf's balloon library *)
Balloon.init ();
(* Initialisations in jpf's GIF ANIMATION library *)
Tkaniminit.f ();
@


\subsection{Resources initialisation}
% and localization

% site file
<<[[Main.main()]] resource initialisation>>=
(* Default values for navigator window *)
Resource.add "*MMM.Width" "640" Tk.WidgetDefault;
Resource.add "*MMM.Height" "480" Tk.WidgetDefault;

(* Resources *)
let site_resfile =
  localize (Filename.concat (Filename.dirname Sys.argv.(0)) "MMM.ad") in
(* Site specific resource file usually in INSTALLDIR=/usr/local/lib/mmm *)
if Sys.file_exists site_resfile 
then Tkresource.readfile site_resfile Tk.StartupFile;
@

<<function Main.localize>>=
let localize file =
  let localized = spf "%s.%s" file !I18n.language in
  if Sys.file_exists localized 
  then localized 
  else file
@
% see more later in i18n chapter



\subsection{Local initialisation}
% bad section title

<<[[Main.main()]] local initialisation>>=
(* Local initialisations *)
Low.init();                         (* start regular tasks *)
Cache.init();                       (* builtin document *)
Auth.init();                        (* start expiration timer *)
Debug.init();                       (* debugging RPC *)
@
%Low.init(), see Concurrency chapter
%Cache.init(), see next section
%Auth.init(), see Security chapter
%Debug.init(), see Debugging in appendix

\subsection{Initial fake URL and HTML document}

% could maybe be moved earlier
<<signature Cache.init>>=
val init : unit -> unit
@
% main -> <>
<<function Cache.init>>=
let init () =
  let initurl = Lexurl.make (Version.initurl (Lang.lang ())) in

  let b = Ebuffer.create 128 in
  Ebuffer.output_string b (Version.inithtml (Lang.lang ()));

  let docid = { 
    document_url = initurl;
    document_stamp = Document.no_stamp
  } in
  let doc = { 
    document_address = initurl;
    document_data = MemoryData b;
    document_info = ["Content-Type: text/html"]
  } in
  let docentry = { 
    cache_document = doc;
    cache_pending = false;
    cache_condition = Condition.create();
    cache_lastused = max_lastused;
  }
  in

  memory := [docid, docentry];
  current := 1
@
% not pending, it is there!

<<signature Version.initurl>>=
val initurl : string -> string (* fake initial url *)
@
<<function Version.initurl>>=
(* MUST BE NORMALIZED *)
let initurl = function
  | "iso8859" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/v%d/about.html" number
  | s -> failwith (Printf.sprintf "language not supported: %s" s)
@
% comment? NORMALIZED?

% so Version.initurl and Version.html

<<signature Version.html>>=
val inithtml : string -> string    (* fake initial document *)
@
%old: I rename inithtml, to match initurl
%less: type language = string
<<function Version.html>>=
let inithtml = function
  | "iso8859" ->
"<HTML><HEAD><TITLE>MMM 0." ^ version_number ^ "</TITLE></HEAD>
<BODY>
<H1> The MMM navigator Version 0." ^ version_number ^ "</H1>
<H2 ALIGN=CENTER> Written by Fran\231ois Rouaix </H2>
<H2 ALIGN=CENTER> Contributions by Jun P. Furuse and Jacques Garrigue</H2>
<H3 ALIGN=CENTER> Port to O'Caml V3.0 by Jun P. Furuse and Pierre Weis</H3>
<H2 ALIGN=CENTER> \169 Copyright INRIA </H2>

<H4 ALIGN=CENTER> Using Objective Caml \169 Copyright INRIA </H4>
<H4 ALIGN=CENTER> And Tcl8.0/Tk8.0 (John Ousterhout and al.)<BR>
 \169 Copyright The Regents of the University of California<BR>
 and Sun Microsystems, Inc </H4>
<BLOCKQUOTE>
Please note that the software is a product currently being developed.
INRIA shall not be responsible in any way concerning conformity, and in
particular shall not be liable should the software not comply with the
requirements of the user, INRIA not being obliged to repair any
possible direct or indirect damage.
</BLOCKQUOTE>
<P>
The MMM home page is 
<A HREF=\"http://pauillac.inria.fr/mmm/\">here</A>,
and there is also some
<A HREF=\"http://pauillac.inria.fr/mmm/doc.html\">documentation</A>
and
<A HREF=\"http://pauillac.inria.fr/mmm/releases.html\">release notes</A>.
<BR>
Join the author by clicking
<A HREF=\"mailto:Francois.Rouaix@inria.fr\">here.</A>
<P>
<BLOCKQUOTE>
This document is included in your browser. Click on <TT>Reload</TT> to
get an updated copy.
</BLOCKQUOTE>
</BODY>
</HTML>
"
  |  s -> failwith (Printf.sprintf "language %s not supported here" s)
@
%$


\subsection{Misc initialisation}

<<[[Main.main()]] misc initialisation>>=
(* Various stuff for the HTML viewer, needing Tk *)
Ctext.init();
Attrs.init !Textw_fo.html_bg; (* built the bullet images *)
@
% ???


\section{[[Mmm.initial_navigator()]]}

% in main():
%  (* Start the initial navigator *)
%  Mmm.initial_navigator user_preferences_file url_opt |> ignore;

% file pref and url opt
<<signature Mmm.initial_navigator>>=
val initial_navigator : string -> string option -> unit
@
% main -> <>
<<function Mmm.initial_navigator>>=
let initial_navigator preffile init_url =
  <<[[Mmm.initial_navigator()]] set preferences>>
  <<[[Mmm.initial_navigator()]] set initial page based on init_url>>
  main_navigator :=
     navigator true 
       (match !initial_page with Some u -> u | None -> assert false)
@
%old: used to return !main_navigator, but it was ignored anyway
% so I simplified the code

% main_navigator will be described far later, it's for multi windows
% navigator

% the set preferences will be exposed in extra features,
% let's focus for now on initial URL and navigator call

\subsection{Initial URL}

<<constant Mmm.initial_page>>=
let initial_page = ref None
@
% why need to store? if create a new window?

<<[[Mmm.initial_navigator()]] set initial page based on init_url>>=
initial_page := Some (
   match init_url with
   | None -> Lexurl.make !Mmmprefs.home
   | Some x -> 
       begin
         try Lexurl.make x 
       with _ -> (* If fails, try to use file: *)
        <<[[Mmm.initial_navigator()]] if cannot parse init_url>>
       end
);
@
% why need to store that? can't just be a let?
% again I think it's because of the multi windows

<<[[Mmm.initial_navigator()]] if cannot parse init_url>>=
let path = 
  if x.[0] = '/' 
  then x
  else Filename.concat (Unix.getcwd ()) x
in
Lexurl.make ("file://localhost" ^ path)
@
% so can do
%    $ ./mmm docs/website/tech.html
% cool :)

\subsection{[[Mmm.navigator()]] and [[Nav.t]]}

<<signature Mmm.navigator>>=
val navigator : bool -> Url.t -> Nav.t option
@
% has_tachy means also main window

% main -> Mmm.initial_navigator -> <>(, true, )
<<function Mmm.navigator>>=
let rec navigator has_tachy initial_url =
  <<[[Mmm.navigator()]] new navigator hook>>

  (* The first navigator is named, so we can put special information in
   * window manager configurations, such as sticky 
   *)
  let top = 
    if has_tachy 
    then Toplevel.create_named Widget.default_toplevel "mmm" [Class "MMM"]
    <<[[Mmm.navigator()]] if not main window, create default toplevel>>
  in
  Wm.title_set top (I18n.sprintf "MMM Browser");
  <<[[Mmm.navigator()]] setup top packing>>

  <<[[Mmm.navigator()]] locals>>

  (* protect all the other initialisations *)
  try 
    (* The frame in which a viewer might want to display *)
    let viewer_frame = Frame.create_named top "viewer" [] in
    
    <<[[Mmm.navigator()]] locals before nav setting>>
    let nav = { 
      <<[[Mmm.navigator()]] set nav fields>>
    }
    in
    <<[[Mmm.navigator()]] nested functions>>
    <<[[Mmm.navigator()]] widgets setting>>

    absolutegoto nav (Url.string_of initial_url);
    Some nav

  with e -> 
    !Error.default#f (I18n.sprintf "Can't view initial document: %s\n%s"
                      (Url.string_of initial_url)
                      (Printexc.to_string e));
    if !navigators = 1 then begin
      destroy Widget.default_toplevel;
      raise e
    end 
    <<[[Mmm.navigator()]] exn handler, else if multiple navigators>>
@
% => top widget
%less: rewrite !Error.default#f -> Error.f ?


% absolutegoto!! initiate the whole thing!

\ifallcode
<<[[Mmm.navigator()]] locals before nav setting>>=
<<local Mmm.navigator.hist>>
<<local function Mmm.navigator.show_current>>
<<local function Mmm.navigator.add_hist>>
<<local object Mmm.navigator.error>>
<<local Mmm.navigator.loggingv>>
<<local Mmm.navigator.actives>>
@


<<[[Mmm.navigator()]] nested functions>>=
(* The navigation functions *)

<<function Mmm.navigator.back>>
<<function Mmm.navigator.forward>>
<<function Mmm.navigator.reload>>
<<function Mmm.navigator.update>>

(* A bunch of other functions *)

<<function Mmm.navigator.abort>>
<<function Mmm.navigator.open_sel>>
<<function Mmm.navigator.open_file>>
<<function Mmm.navigator.save>>
<<function Mmm.navigator.print>>
<<function Mmm.navigator.close>>
<<function Mmm.navigator.really_quit>>
<<function Mmm.navigator.gohome>>
<<function Mmm.navigator.redisplay>>
<<function Mmm.navigator.add_to_hotlist>>
<<function Mmm.navigator.load_images>>
<<function Mmm.navigator.view_source>>
@

\fi

%\subsection{[[Nav.t]]}

<<type Nav.t>>=
type t = {
  nav_viewer_frame : Widget.widget;
  <<[[Nav.t]] other fields>>
 }
@
% this will be full of hooks
%todo: could classify other fields, like active hooks, error hook,
% etc

<<[[Mmm.navigator()]] set nav fields>>=
nav_viewer_frame = viewer_frame;
@


\subsection{[[Nav.absolutegoto()]]}

<<signature Nav.absolutegoto>>=
val absolutegoto : t -> string -> unit
@
% navigator -> (enter on URL entry | explicit call)  -> <>
<<function Nav.absolutegoto>>=
(* Used outside an hyperlink *)
let absolutegoto nav uri =
  follow_link nav { 
    h_uri = uri; 
    h_context = None; 
    h_method = GET; 
    h_params = []
  }
@
%old: duplicated code
%  let follow_link = 
%    request nav true id_wr 
%      (process_viewer true make_ctx) (specific_viewer true)
%  in

<<signature Nav.follow_link>>=
val follow_link : t -> Hyper.link -> unit
@
<<function Nav.follow_link>>=
let follow_link nav lk =
  request 
   nav 
   true 
   id_wr 
   (fun nav wr dh -> process_viewer true make_ctx nav wr dh) 
   (specific_viewer true)
   lk
@
% all those true booleans ... hard to read

<<function Nav.id_wr>>=
let id_wr wr = wr
@
%todo: when want to pass something else? and want to transform the wr?

\subsection{[[Nav.request()]]}

<<signature Nav.request>>=
val request :
  t ->
  bool ->
  (Www.request -> Www.request) ->
  (t -> Www.request -> Document.handle -> unit) ->
  (t -> Document.document_id -> Www.request -> unit) -> 
  Hyper.link -> 
  unit
@
%todo: wow, complicated type, change order and LP aspectize the hooks!

<<function Nav.request>>=
(* [request nav usecache wrapwr process specific] produces a function that
   takes an hyperlink, and apply the given behavior to it.
   [usecache] : do we look in the cache to see if we have it already
   [process nav wr dh] : what to to with the retrieved document
   [specific nav did wr] : some specific behavior, checked before we
     look in the cache. Must either raise Not_found or process completely
     the link
   [wrapwr wr] : returns a modified wr
 *)
let request nav  usecache wrapwr  process  specific lk =

  <<function Nav.request.retrieve_and_handle>>
  <<function Nav.request.handle_wr>>
  <<function Nav.request.handle_link>>
  handle_link lk
@
%old: I eta expanded with lk, again

% link -> wr -> ...
<<function Nav.request.handle_link>>=
and handle_link h =
  try (* Convert the link into a request *)
    let wr = Plink.make h in
    wr.www_error <- nav.nav_error;
    wr |> wrapwr |> handle_wr
  with
  | Invalid_link msg ->
      nav.nav_error#f (I18n.sprintf "Invalid link")
  | Invalid_request (wr, msg) ->
      nav.nav_error#f (I18n.sprintf "Invalid request %s\n%s"
                        (Url.string_of wr.www_url) msg)
in
@

% wr (-> cache) -> ...
<<function Nav.request.handle_wr>>=
(* Wrapper to deal with general/specific cache *)
and handle_wr wr =
  try
    match wr.www_url.protocol with
    <<[[Nav.request.handle_wr()]] match protocol cases>>
    | _ ->
       if (not usecache) || dont_check_cache wr 
       then retrieve_and_handle wr
       else
         <<[[Nav.request.handle_wr()]] if use cache>>
  with Duplicate url ->
    wr.www_error#f (I18n.sprintf 
        "The document %s\nis currently being retrieved for some other purpose.\nMMM cannot process your request until retrieval is completed." (Url.string_of url))
@
% you want exception analysis ... this gets tricky

<<function Nav.request.retrieve_and_handle>>=
(* Normally execute the request and process its answer (dh) *)
let rec retrieve_and_handle wr =
  let cont = 
    { document_process = (fun dh ->
        process nav wr dh;
        nav.nav_rem_active wr.www_url);
      document_finish = (fun _ -> 
        nav.nav_rem_active wr.www_url);
    }
  in
  match Retrieve.f wr handle_link cont with
  | Retrieve.Started abort -> 
      nav.nav_add_active wr.www_url abort
  | Retrieve.InUse -> 
      raise (Duplicate wr.www_url)
@
% will se Retrieve.f later      

\subsubsection{[[Nav.process_viewer()]]}

% Nav.absolutegoto | ... -> Nav.request -> <> 
%  (as Nav.request.process <- follow_link (<>) <- Nav.absolutegoto )
<<function Nav.process_viewer>>=
(* Specific handling of "view" requests *)
let process_viewer addhist make_ctx = 
 fun nav wr dh ->
  let ctx = make_ctx nav dh.document_id in
  match Viewers.view nav.nav_viewer_frame ctx dh with
  | None -> () (* external viewer *)
  | Some di ->
      <<[[Nav.process_viewer()]] add in cache and history the document>>
      nav.nav_show_current di dh.document_fragment
@
% compute the graphic, and then show it in the nav at the right
% anchor! Finally made the link from user url request -> graphic display

% so request -> retrieve -> view -> display

% will see viewer later, Viewers.view, and make_ctx
% will see nav.nav_show_current later





\section{The event loop}

<<function Main.safe_loop>>=
let rec safe_loop() =
  try
    Printexc.print Tk.mainLoop () (* prints and reraises *)
  with
  | Out_of_memory -> raise Out_of_memory
  | Sys.Break -> raise Sys.Break
  | Stack_overflow -> raise Stack_overflow
  | e -> 
      flush Pervasives.stderr; 
      safe_loop()
@



\chapter{Navigator Interface}
% The chrome
% gui/

\section{Layout}


<<[[Mmm.navigator()]] widgets setting>>=
(* Short cuts *)
<<[[Mmm.navigator()]] short cuts>>

(* Invariable part (the rest being the di stuff)
   hgroup: blah and tachymeter
 *)
let hgroup = Frame.create_named top "hgroup" [] in
let vgroup = Frame.create_named hgroup "vgroup" [] in (* Menus, open entry *)

(* Menus *)
let mbar = Frame.create_named vgroup "menubar" [] in
<<[[Mmm.navigator()]] setup menu>>
<<[[Mmm.navigator()]] setup open url entry>>

(* Navigation buttons *)
let fb = Frame.create_named vgroup "buttons" [] in
<<[[Mmm.navigator()]] navigation buttons>>

<<[[Mmm.navigator()]] packing part one>>
(* Initial window only *)
if has_tachy then begin
  <<[[Mmm.navigator()]] set geometry if specified>>
  <<[[Mmm.navigator()]] set tachy>>
end;
<<[[Mmm.navigator()]] packing part two>>

<<[[Mmm.navigator()]] handling destroy event>>
Tkwait.visibility hgroup;

<<[[Mmm.navigator()]] call update_vhistory>>
<<[[Mmm.navigator()]] touch current>>
@
%less: put call to update_vhistory close to absolutegoto? can
% exchange with touch_current? in both case they initialize things
% and initiate the "big bang"


<<[[Mmm.navigator()]] setup top packing>>=
(* the size of the navigator MUST NOT depend on what is displayed inside *)
(* Instead, we rely on defaults for class MMM, *MMM.Width, *MMM.Height   *)
Pack.propagate_set top false;
@

% menubar, buttons, entry, buttons
<<[[Mmm.navigator()]] packing part one>>=
pack [mbar][Anchor NW; Side Side_Top; Fill Fill_X];
pack [backb;homeb;forwardb;reloadb;abortb; loggingb]
       [Side Side_Left; Fill Fill_X];
pack [f][Fill Fill_X; Expand true; Side Side_Bottom; Anchor SW];
pack [fb][Fill Fill_X];
@


<<[[Mmm.navigator()]] packing part two>>=
(* Pack last to avoid lossage when resizing *)
pack [vgroup][Fill Fill_X; Expand true; Side Side_Left];
pack [hgroup][Fill Fill_X];
pack [viewer_frame][Fill Fill_Both; Expand true];
@


\subsection{Destroy event}

<<[[Mmm.navigator()]] handling destroy event>>=
(* We receive this event for each children destroyed because we are
   a toplevel *)
bind top [[], Destroy] (BindSet ([Ev_Widget], (fun ei -> 
  if ei.ev_Widget = top then begin
    decr navigators;
    Gcache.kill hist.h_key;

    (* we were destroyed by wm *)
    if !navigators = 0 && Winfo.exists Widget.default_toplevel
    then destroy Widget.default_toplevel
  end
)));
@
% Gcache.kill
% G??

\subsection{Timer}

<<[[Mmm.navigator()]] touch current>>=
(* Yet another timer to avoid flushing displayed documents *)
let rec touch_current () =
  if Winfo.exists top then begin
    Cache.touch hist.h_current.h_did;
    Timer.set 10000 touch_current
  end 
in
touch_current();
@

% Gcache.touch




\section{Address bar}

<<[[Mmm.navigator()]] locals>>=
let entryv = Textvariable.create_temporary top in
@

<<[[Mmm.navigator()]] setup open url entry>>=
(* URL display and edit *)
let f,e = Frx_entry.new_label_entry vgroup (I18n.sprintf "Open URL:")
                   (fun url -> Nav.absolutegoto nav url)
in
Entry.configure e [TextVariable entryv; TextWidth 40];
@
% absolutegoto!
% f is the widget that will be packed


\section{Display}

% Nav.absolutegoto -> request -> process_viewer -> <>
<<[[Nav.t]] other fields>>=
nav_show_current: Viewers.display_info -> string option -> unit;
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_show_current = show_current;
@

% Nav.absolutegoto -> request -> process_viewer -> <> (as Nav.nav_show_current)
<<local function Mmm.navigator.show_current>>=
(* Change view, independantly of history manip *)
let show_current di frag =
  di#di_touch;
  (match !current_di with
  | None -> display di
  | Some olddi -> 
     if olddi == di 
     then () 
     else begin
       undisplay olddi;
       display di
     end
  );
  current_di := Some di;
  (* bogus if two views with fragment on the same pending document *)
  di#di_fragment frag;
  (* Bof *)
  Textvariable.set entryv (Url.string_of hist.h_current.h_did.document_url)
in
@

<<[[Mmm.navigator()]] locals>>=
let current_di = ref None in
@

<<function Mmm.undisplay>>=
let undisplay di = 
  if Winfo.exists di#di_widget 
  then Pack.forget [di#di_widget]
@

<<function Mmm.display>>=
let display di = 
  if Winfo.exists di#di_widget
  then pack [di#di_widget][Fill Fill_Both; Expand true]
  else !Error.default#f "fatal error: window was destroyed";

  let tl = Winfo.toplevel di#di_widget in
  let title = I18n.sprintf "MMM Browser@%s" di#di_title in
  if Widget.known_class tl = "toplevel" 
  then begin 
    Wm.title_set tl title; 
    Wm.iconname_set tl title
  end
@


\section{History}

<<local Mmm.navigator.hist>>=
let initial_did = 
  { document_url = initial_url; 
    document_stamp = Document.no_stamp
  } 
in
let hist = History.create initial_did in
@


<<[[Nav.process_viewer()]] add in cache and history the document>>=
if addhist 
then nav.nav_add_hist dh.document_id dh.document_fragment;
@

% ?? -> <>
<<local function Mmm.navigator.add_hist>>=
let add_hist did frag =
  History.add hist did frag;
  !update_vhistory ()
in
@

%XXX
<<[[Nav.t]] other fields>>=
nav_id : int;  (* key for the gfx cache *)
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_id = hist.h_key;
@


<<[[Nav.t]] other fields>>=
nav_add_hist : Document.document_id -> string option -> unit;
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_add_hist = add_hist;
@



<<[[Mmm.navigator()]] locals>>=
let update_vhistory = ref (fun () -> ()) (* duh *) in
@
% because of mutual deps, needed for nav
<<[[Mmm.navigator()]] History menu>>=
(* The history menu is destroyed and rebuild each time. 
 * Deleting all entries will cause a callback leak since
 *  entries are associated to the menu itself 
 *)
let history_mindex = Pattern (I18n.sprintf "History") in
let hmenu = ref (Menu.create_named navm "history" []) in 
Menu.add_cascade navm [Label (I18n.sprintf "History")];
update_vhistory := (fun () ->
  destroy !hmenu;
  hmenu := Menu.create_named navm "history" [];
  History.contents hist |> List.iter (fun e ->
    let label = ref (Url.string_of e.h_did.document_url) in
    (match e.h_fragment with
    | None -> ()
    | Some f -> label := !label^"#"^f
    );
    (match e.h_did.document_stamp with
    | 0 -> ()
    | n -> label := !label^"("^string_of_int n^")"
    );
    Menu.add_command !hmenu 
       [Label !label;
        Command (fun () ->
          let cure = hist.h_current in
          History.set_current hist e;
          if not (historygoto nav e.h_did e.h_fragment true)
          then History.set_current hist cure)
        ]
    );
    Menu.configure_cascade navm history_mindex [Menu !hmenu]
);

@

<<[[Mmm.navigator()]] call update_vhistory>>=
!update_vhistory();
@

\section{Back and forward}

<<[[Mmm.navigator()]] navigation buttons>>=
let backb = Button.create_named fb 
  "back" [Text (I18n.sprintf "Back"); Command back ] in
@

<<function Mmm.navigator.back>>=
(*  The cache may have been cleared, so the document may be lost.
 *  historygoto implements the proper logic for this, taking care
 *  of non-unique documents.
 *)
let back () = 
  match History.back hist with
   | None -> ()
   | Some (did, frag) -> 
       if not (historygoto nav did frag true) 
       then History.forward hist |> ignore
in
@

<<[[Mmm.navigator()]] navigation buttons>>=
let forwardb = Button.create_named fb 
  "forward" [Text (I18n.sprintf "Forward"); Command forward] in
@

<<function Mmm.navigator.forward>>=
let forward () =
  match History.forward hist with
  | None -> ()
  | Some (did, frag) -> 
      if not (historygoto nav did frag true) 
      then History.back hist |> ignore
in
@


\section{Home}

<<[[Mmm.navigator()]] navigation buttons>>=
let homeb = Button.create_named fb "home"
  [ Text (I18n.sprintf "Home"); Command gohome] in
@

<<function Mmm.navigator.gohome>>=
let gohome () = 
  absolutegoto nav !Mmmprefs.home
in
@


<<signature Mmmprefs.home>>=
val home : string ref
@
<<constant Mmmprefs.home>>=
(* There is no right place for this *)
let home = ref ""
@



<<signature Version.home>>=
val home : string -> string    (* MMM home page *)
@
<<function Version.home>>=
let home = function 
  | "iso8859" -> "http://pauillac.inria.fr/mmm/"
  | _ -> assert false
@

\section{Refresh and stop}

<<[[Mmm.navigator()]] navigation buttons>>=
let reloadb = Button.create_named fb
  "reload" [Text (I18n.sprintf "Reload"); Command reload] in
@

<<function Mmm.navigator.reload>>=
let reload () =
  let did = hist.h_current.h_did in
  let frag = hist.h_current.h_fragment in
  if did.document_stamp = no_stamp then begin
    (* kill both in cache and in gcache *)
    Cache.kill did; 
    Gcache.remove hist.h_key did;
    historygoto nav did frag false |> ignore
  end
    else error#f (I18n.sprintf 
      "Document cannot be reloaded from its url\n(probably a POST request)")
in
@

% see also update_true alias
<<function Mmm.navigator.update>>=
let update nocache =
  let did = hist.h_current.h_did in
  if did.document_stamp = no_stamp then
    Nav.update nav did nocache
  else (* POST result *)
    error#f (I18n.sprintf "Can't update document\n(probably a POST request)")
in
@



<<[[Mmm.navigator()]] navigation buttons>>=
let abortb = Button.create_named fb 
  "abort" [Text (I18n.sprintf "Abort"); Command abort] in
@

<<local Mmm.navigator.actives>>=
let actives = Hashtbl.create 37 in
@

<<function Mmm.navigator.abort>>=
let abort () =
  actives |> Hashtbl.iter (fun _url abort -> abort());
  Hashtbl.clear actives;
  match !current_di with
  | None -> ()
  | Some di -> di#di_abort
in
@

% Nav.request -> <>
<<[[Nav.t]] other fields>>=
nav_add_active : Url.t -> (unit -> unit) -> unit;
nav_rem_active : Url.t -> unit;
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_add_active = Hashtbl.add actives;
nav_rem_active = Hashtbl.remove actives;
@


\section{Menus}

<<[[Mmm.navigator()]] setup menu>>=
<<function Mmm.navigator.configure_menu_elements>>
<<[[Mmm.navigator()]] MMM menu>>
<<[[Mmm.navigator()]] Navigation menu>>
<<[[Mmm.navigator()]] History menu>>
<<[[Mmm.navigator()]] Document menu>>
<<[[Mmm.navigator()]] Other menu>>
<<[[Mmm.navigator()]] Help menu>>
<<[[Mmm.navigator()]] User menu>>

pack [mmm; navb; docb; othersb][Side Side_Left];
pack [helpb; userb] [Side Side_Right];
@


<<function Mmm.navigator.configure_menu_elements>>=
let configure_menu_elements menu xs =
  let rec list_assoc_address k = function
    | (k',v)::_ when k == k' -> v
    | _::xs -> list_assoc_address k xs
    |	[] -> raise Not_found
  in
  xs |> List.iter (fun l ->
    let opts = 
     List.fold_right (fun opt st ->
       (match opt with
       | Command f -> 
           begin
            Command f :: 
              try
                [ Accelerator (Tkresource.short_event_sequence
                               (list_assoc_address f my_short_cuts))]
              with Not_found -> []
           end
       | _ -> [opt])
       @ st
     ) l []
    in
    match opts with
    | [] -> Menu.add_separator menu
    | _  -> Menu.add_command menu opts
 )
in
@

\subsection{MMM menu}

<<[[Mmm.navigator()]] MMM menu>>=
(* MMM menu *)
let mmm = Menubutton.create_named mbar "mmm" [Text (I18n.sprintf "MMM")] in
let mmmm = Menu.create_named mmm "menu" [] in
Menubutton.configure mmm [Menu mmmm];
configure_menu_elements mmmm [
  [Label (I18n.sprintf "About")            ; Command About.f];
  [];
  [Label (I18n.sprintf "New Window")       ; Command new_window];
  [Label (I18n.sprintf "Open Selection")   ; Command open_sel];
  [Label (I18n.sprintf "Open File...")     ; Command open_file];
  [Label (I18n.sprintf "Save document...") ; Command save];
  [Label (I18n.sprintf "Print document")   ; Command print];
  [Label (I18n.sprintf "Preferences...")   ; Command !preferences];
  [];
  [Label (I18n.sprintf "Close Window")     ; Command close];
  [];
  [Label (I18n.sprintf "Quit")             ; Command really_quit]
];
@

<<function Mmm.navigator.open_sel>>=
let open_sel () =
  try 
    let url = Selection.get [] in
    absolutegoto nav url
  with _ -> ()
in
@

<<function Mmm.navigator.open_file>>=
let open_file () =
  Fileselect.f (I18n.sprintf "Open File") (function
    | [] -> ()
    | [s] -> 
        let path = Msys.tilde_subst s in
        absolutegoto nav ("file://localhost/"^path)
    | l -> raise (Failure "multiple selection")
   )
     "*" 
     ""
     false
     false
in
@

<<function Mmm.navigator.save>>=
let save () = 
 Save.document hist.h_current.h_did None 
in
@

<<function Mmm.navigator.print>>=
let print () = 
  Save.document hist.h_current.h_did 
     (Some (sprintf "|%s" !Save.print_command))
in
@

<<function Mmm.navigator.close>>=
let close () =
  if !navigators = 1 
  then quit true
  else destroy top
in
@

<<function Mmm.navigator.really_quit>>=
let really_quit () = 
  quit false
in
@



<<function Mmm.quit>>=
let quit confirm =
  if confirm then
    match Frx_dialog.f Widget.default_toplevel (gensym "quit")
      (I18n.sprintf "Confirm") 
      (I18n.sprintf "Do you really want to quit ?")
       (Predefined "question") 0 
       [I18n.sprintf "Yep"; I18n.sprintf "Nope"] 
    with
    |  0 -> destroy Widget.default_toplevel
    | _ -> ()
  else destroy Widget.default_toplevel
@

\subsection{Navigation menu}

<<[[Mmm.navigator()]] Navigation menu>>=
(* Navigation menu *)
let navb = Menubutton.create_named mbar "navigate" [Text (I18n.sprintf "Navigate")] in
let navm = Menu.create_named navb "menu" [] in
Menubutton.configure navb [Menu navm];
configure_menu_elements navm [ 
  [Label (I18n.sprintf "Home"); Command gohome];
  [Label (I18n.sprintf "Back"); Command back];
  [Label (I18n.sprintf "Forward"); Command forward];
  []
];
@

\subsection{Document menu}

<<[[Mmm.navigator()]] Document menu>>=
let docb = Menubutton.create_named mbar "document" [Text (I18n.sprintf "Document")] in
let docm = Menu.create_named docb "menu" [] in
Menubutton.configure docb [Menu docm];
configure_menu_elements docm [	    
  [Label (I18n.sprintf "Abort")          ; Command abort];
  [Label (I18n.sprintf "Reload")         ; Command reload];
  [Label (I18n.sprintf "Update")         ; Command update_true];
  [Label (I18n.sprintf "Redisplay")      ; Command redisplay];
  [Label (I18n.sprintf "Add to hotlist") ; Command add_to_hotlist];
  [Label (I18n.sprintf "Load Images")    ; Command load_images];
  [Label (I18n.sprintf "View Source")    ; Command view_source]
];
@

<<function Mmm.navigator.add_to_hotlist>>=
let add_to_hotlist () =
  match !current_di with
  | None -> ()
  | Some di -> 
      Hotlist.f (Url.string_of hist.h_current.h_did.document_url)
                  di#di_title
in
@

<<function Mmm.navigator.load_images>>=
let load_images () =
  match !current_di with
  | None -> ()
  | Some di -> di#di_load_images
in
@

<<function Mmm.navigator.view_source>>=
let view_source () =     
  match !current_di with
  | None -> ()
  | Some di -> di#di_source
in
@

<<function Mmm.navigator.redisplay>>=
let redisplay () =
  match !current_di with
  | None -> ()
  | Some di -> di#di_redisplay
in
@


\subsection{Other menu}

<<[[Mmm.navigator()]] Other menu>>=
(* Other stuff *)
let othersb = Menubutton.create_named mbar "others" [Text (I18n.sprintf "Others")] in
let othersm = Menu.create_named othersb "menu" [] in
Menubutton.configure othersb [Menu othersm];
Menu.add_command othersm
  [Label (I18n.sprintf "Load Authorizations..."); Command Auth.load];
Menu.add_command othersm
  [Label (I18n.sprintf "Edit Authorizations..."); Command Auth.edit];
Menu.add_command othersm
  [Label (I18n.sprintf "Save Authorizations..."); Command Auth.save];
@
% (*      Menu.add_command othersm
%     [Label (I18n.sprintf "Caml Modules"); 
%      Command (fun _ -> Applets.edit())];
%    Menu.add_command othersm
%     [Label (I18n.sprintf "Load Caml Extension");
%   Command (fun _ ->
%              Fileselect.f (I18n.sprintf "Load Caml Extension")
%          (function [] -> ()
%                  | [s] -> Applets.load_local s
%              | l -> raise (Failure "multiple selection"))
%          "*.cmo"
%          ""
%          false
%          false)
%      ];
% *)

\subsection{Help menu}

<<[[Mmm.navigator()]] Help menu>>=
(* Help menu *)
let helpb = Menubutton.create_named mbar "help" [Text (I18n.sprintf "Help")] in
let helpm = Menu.create_named helpb "menu" [] in
Menubutton.configure helpb [Menu helpm];
Menu.add_command helpm
  [Label (I18n.sprintf "Version information");
   Command (fun () -> absolutegoto nav (Version.initurl (Lang.lang ())))];
Menu.add_command helpm
  [Label (I18n.sprintf "Help on MMM");
   Command (fun () -> navigator false !helpurl |> ignore)];
Menu.add_command helpm
  [Label (I18n.sprintf "Home Page of MMM");
   Command (fun () -> 
     navigator false (Lexurl.make (Version.home (Lang.lang ()))) |> ignore)];
@

%\subsection{Applet user menu}
% see later

\section{Status bar}
% it's actually on the right of the buttons for now,
% but should be in status bar I think

<<[[Mmm.navigator()]] navigation buttons>>=
let loggingb = Label.create_named fb "logging"
  [TextWidth 40; TextVariable loggingv; Anchor W] in
@

<<local Mmm.navigator.loggingv>>=
let loggingv = Textvariable.create_temporary top in
@


<<[[Nav.t]] other fields>>=
nav_log : string -> unit;
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_log = (fun s -> Textvariable.set loggingv s);
@




<<[[Nav.t]] other fields>>=
nav_error : Error.t;			(* popping error dialogs *)
@
<<local object Mmm.navigator.error>>=
let error = new Tk_error.t top in
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_error = error;
@


\section{Shortcuts}

<<[[Mmm.navigator()]] short cuts>>=
(* All the available shortcuts functions and their short cut keys. *)
(* If you put a new function with its short cut key here, then *)
(* Short cut string will be displayed automatically, when these *)
(* functions are added as menu elements. *)

(* Sorry, we use function equality, so we cannot use lambdas in the list *)
let update_true = fun () -> update true in

(* The shortcuts and the default settings *)
let all_short_cuts = [
  (* function    resource name      default key sequence *)
  About.f,     "About",           [[], KeyPressDetail "F1"]; 
  new_window,    "NewWindow",       [[Alt], KeyPressDetail "n"];
  open_sel,      "OpenSelection",   [[Alt], KeyPressDetail "y"];
  open_file,     "OpenFile",        [[Alt], KeyPressDetail "o"];
  save,          "Save",            [[Alt], KeyPressDetail "s"];
  print,         "Print",           [];
  !preferences,  "Preference",      [[Alt], KeyPressDetail "p"];
  close,         "Close",           [[Alt], KeyPressDetail "c"];
  really_quit,   "Quit",            [[Alt], KeyPressDetail "q"];

  gohome,        "Home",            [];
  back,          "Back",            [[Alt], KeyPressDetail "Left"];
  forward,       "Forward",         [[Alt], KeyPressDetail "Right"];
  reload,        "Reload",          [[Alt], KeyPressDetail "r"];
  abort,         "Abort",           [[], KeyPressDetail "Escape"];

  update_true,   "Update",          [[Alt], KeyPressDetail "u"];
  redisplay,     "Redisplay",       [[Control], KeyPressDetail "l"];
  add_to_hotlist, "AddToHotlist",   [[Alt], KeyPressDetail "a"];
  load_images,   "LoadImages",      [[Alt], KeyPressDetail "i"];
  view_source,   "ViewSource",      [[Alt], KeyPressDetail "e"]
] 
in

(* Real shortcuts information actually used *)
let my_short_cuts = List.map (fun (f,r,d) ->
  f, Tkresource.event_sequence ("shortcut" ^ r) d) all_short_cuts
in

(* we break after each event so that All bindings, such as menu traversal,
 * dont get invoked if we destroyed the window for some reason
 * may be required only for things like reload
 *)
my_short_cuts |> List.iter (fun (f, eventl) -> 
  if eventl <> [] 
  then bind top eventl (BindSetBreakable ([], fun _ -> f(); break()))
);
@


\chapter{Parsing}
% www/ html/ http/

\section{URLs}

<<signature Lexurl.f>>=
val f : Lexing.lexbuf -> Url.t
@
%todo: rename?

<<signature Lexurl.make>>=
val make : string -> Url.t
   (* raise Url_Lexing(msg,pos) *)
@
<<function Lexurl.make>>=
let make s = 
  f (Lexing.from_string s)
@



% =~ protocol://user@host:port/paths?search

\subsection{Protocol}

<<function Lexurl.f>>=
(* We don't actually need all of this *)
rule f = parse
  [ 'a'-'z' 'A'-'Z' '0'-'9' '+' '.' '-' ]+ ":" 	(* absolute url *)
    { let lexeme = Lexing.lexeme lexbuf in
      let result =
        { protocol = HTTP; (* will be adjusted later *)
          user = None; password = None;
          host = None; port = None;
          path = None; search = None
         } 
      in
      let protocol =
        String.uppercase (String.sub lexeme 0 (String.length lexeme - 1)) in
      (match protocol with
      <<[[Lexurl.f]] protocol cases>>
      | s ->
          result.protocol <- OtherProtocol s;
          result.path <- any lexbuf
      );
      result
    }
 | _ { raise (Url_Lexing ("not an URL", Lexing.lexeme_start lexbuf)) }
@
% less: use 'as' of ocamllex so less need String.sub
% less: could have a Url.default()

<<[[Lexurl.f]] protocol cases>>=
| "HTTP" ->
    slashslash lexbuf;
    let h, po = hostport lexbuf in
    let pa, se = pathsearch lexbuf in
    result.protocol <- HTTP;
    result.host <- h;
    result.port <- normalize_port (HTTP, po);
    result.path <- pa;
    result.search <- se
@
% no user?
% can see other protocols in section in advanced topics
%less: rewrite so less need to use <- and have mutable fields

<<function Lexurl.slashslash>>=
and slashslash =  parse
  "//" { () } 
| ""   { raise (Url_Lexing ("// expected", Lexing.lexeme_start lexbuf)) }
@

<<function Lexurl.normalize_port>>=
let normalize_port = function
  | HTTP, Some 80 -> None
  | FTP, Some 21 -> None
  (* incomplete, but we don't care yet *)
  | _, p -> p
@

\subsection{Host, port}

<<function Lexurl.hostport>>=
(* _ is not legal in hostnames, but some people use it. *)
and hostport = parse
| ['A'-'Z' 'a'-'z' '0'-'9' '.' '-' '_']+ ':' ['0'-'9']+
    { let lexeme = Lexing.lexeme lexbuf in
      let pos = String.index lexeme ':' in
      let portstring =
        String.sub lexeme (succ pos) (String.length lexeme - 1 - pos) in
      Some (normalize_host (String.sub lexeme 0 pos)),
      Some (int_of_string portstring)
    }
| ['A'-'Z' 'a'-'z' '0'-'9' '.' '-' '_']+ 
    { Some (normalize_host (Lexing.lexeme lexbuf)), None }
| "" (* file:///home/... *)
    { None, None }
@
%less: use 'as' again

<<function Lexurl.normalize_host>>=
(* lowercase, don't use final . in FQDN *)
let normalize_host s = 
  let s = String.lowercase s in
  let l = String.length s in
  if s.[l-1] = '.' 
  then String.sub s 0 (l-1)
  else s
@

\subsection{Path, search}


<<function Lexurl.pathsearch>>=
(* /<path>?<search> *)
and pathsearch = parse
| "/" [^ '?']* '?' 
    { let lexeme = Lexing.lexeme lexbuf in
      let search = any lexbuf in
      Some (String.sub lexeme 1 (String.length lexeme - 2)), search 
    }
| "/" [^ '?']*
    { let lexeme = Lexing.lexeme lexbuf in
      Some (String.sub lexeme 1 (String.length lexeme - 1)), None 
    }
| "" 
    { None, None }
@
%less: use 'as'

<<functions Lexurl.xxx>>=
and any = parse
  [^ '\n']*  { Some (Lexing.lexeme lexbuf) }    (* in fact any char *)
@






\subsection{Normalization}

% how this normalize? because make() does a few normalization?
%  like normalize_host, normalize_port?
<<signature Lexurl.normalize>>=
val normalize : string -> string
@
<<function Lexurl.normalize>>=
let normalize url =
  let urlp = make url in
  Url.string_of urlp
@
%less: could rename make to of_string
%todo: rename normalize_host_and_port?



% make normalize
% for context parsing?
<<signature Lexurl.maken>>=
val maken : string -> Url.t
   (* raise Url_Lexing(msg,pos) *)
@
%todo: rename to make_normalize_host_port_path?
% Hyper.resolve -> <> (for the h_context for relative URI)
<<function Lexurl.maken>>=
(* Extra normalisation at lexing time 
 *  remove ../ and /. as in RFC 1630
 *  unquote %
 *)
let maken s =
  let url = make s in
  (match url.protocol with
  | HTTP ->  
      (match url.path with
      | None -> ()
      | Some p -> url.path <- Some (Urlenc.unquote (remove_dots p))
      )
  | _ -> ()
  );
  url
@

% it can not contain '#' because it's the fragment marker
% so at least need # to be escaped


\subsubsection{dots}

<<signature Lexurl.remove_dots>>=
val remove_dots : string -> string
@
% Lexurl.maken -> <>
<<function Lexurl.remove_dots>>=
let remove_dots s =
  let b = Ebuffer.create 32 in
  rev_do_list 
    (Ebuffer.output_string b)
    (pathcomponents (Lexing.from_string s) []);
  Ebuffer.get b
@

<<functions Lexurl.xxx>>=
and pathcomponents = parse
  [ ^ '/']* '/'
    { (fun l ->
         let newl = 
           match Lexing.lexeme lexbuf with
          | "./" -> l
           | "../" -> (match l with | [] -> [] | _ :: tl -> tl)
           | p -> (p :: l)
          in
        pathcomponents lexbuf newl)
     }
| [ ^ '/']+
    { (fun l -> 
        match Lexing.lexeme lexbuf with
        | "." -> l
        | ".." -> (match l with [] -> [] | _ :: tl -> tl)
        | p -> p :: l 
       )
    }
| "" { (fun l -> l) }
@
% why want to normalize? anyway the server will resolve no?


\subsubsection{Percents}

<<signature Urlenc.unquote>>=
(*-*)
val unquote : string -> string
@

<<function Urlenc.unquote>>=
let unquote s =
  try
    (* optim *)
    let _ = String.index s '%' in
    let l = String.length s in
    let target = Ebuffer.create l in
    let pos = ref 0 in
    (try
      while !pos < l do
       let perpos = String.index_from s !pos '%' in
       if perpos > !pos 
       then Ebuffer.output target s !pos (perpos - !pos);
       pos := perpos;
       if s.[!pos] = '%' & !pos + 2 < l  
       then begin
         let c = 16 * hex_to_dec s.[!pos+1] + hex_to_dec s.[!pos+2] in
         let substc = Char.chr c in
         if List.mem substc keep_quoted 
         then
           for i = 0 to 2 do
             Ebuffer.output_char target s.[!pos];
             incr pos
           done
         else begin
             Ebuffer.output_char target (Char.chr c);
             pos := !pos + 3
         end
       end else begin
        Ebuffer.output_char target s.[!pos];
        incr pos
       end
     done;
     Ebuffer.get target
   with Not_found -> (* no more substitutions *)
     Ebuffer.output target s !pos (l - !pos);
     Ebuffer.get target
   )
  with Not_found -> s
@

<<constant Urlenc.keep_quoted>>=
(* Unquote an url path:
   We decode all % except those corresponding to significative
   characters for parsing: /, ?, #, sp, :
 *)
let keep_quoted = 
  ['/'; '?'; '#'; ' '; '\t'; '\r'; '\n'; ':'; '%'; '&'; '='; '+']
@


\subsection{Encoding}
% unparsing? escaping?

\subsubsection{Decoding}

% ??? -> <>
<<signature Urlenc.decode>>=
(* URL encoding *)
val decode : string -> string
@
<<function Urlenc.decode>>=
(* Decode escaped characters *)
(* Note: beware of order of splitting wrt '&' and decoding *)
let decode s =
  let l = String.length s in
  let target = Ebuffer.create l in
  let pos = ref 0 in
  while !pos < l do
    if s.[!pos] = '%' & !pos + 2 < l  then begin
       let c = 16 * hex_to_dec s.[!pos+1] + hex_to_dec s.[!pos+2] in
       Ebuffer.output_char target (Char.chr c);
    pos := !pos + 3
    end else if s.[!pos] = '+' then begin
      Ebuffer.output_char target ' ';
      incr pos
    end else begin
      Ebuffer.output_char target s.[!pos];
      incr pos
      end
  done;
  Ebuffer.get target
@
%less: rewrite match ()

\subsubsection{Encoding}

% ??? -> <>
<<signature Urlenc.encode>>=
val encode : string -> string
    (* encoding and decoding for an arbitrary string *)
@
<<function Urlenc.encode>>=
let encode s =
  let target = Ebuffer.create (String.length s) in
  for pos = 0 to String.length s - 1 do
    match s.[pos] with
      ' ' -> Ebuffer.output_char target '+'
    | '0'..'9' | 'a'..'z' | 'A'..'Z' as c -> Ebuffer.output_char target c
    | '\n' -> Ebuffer.output_string target "%0D%0A"
    | c -> Ebuffer.output_string target (hexchar c)
    done;
  Ebuffer.get target
@

<<function Urlenc.hexchar>>=
let hexchar c = 
  let s = String.make 3 '%'
  and i = Char.code c in
  s.[1] <- dec_to_hex (i/16);
  s.[2] <- dec_to_hex (i mod 16);
  s
@


\subsubsection{Forms}

<<signature Urlenc.form_decode>>=
val form_decode : string -> (string * string) list
    (* application/x-www-form-urlencoded encoding *)
@
<<constant Urlenc.form_decode>>=
let form_decode =
  let ampersand c = c = '&' and equals c = c = '=' in
  (function  s ->
     List.map (fun encp ->
       match split_str equals encp with
       [x;y] -> (decode x, decode y)
     | [x] -> (decode x, "")
     | _ -> invalid_arg "form_decode")
       (split_str ampersand s))
@



<<signature Urlenc.form_encode>>=
val form_encode : (string * string) list -> string
@
<<function Urlenc.form_encode>>=
let form_encode = function 
 | [] -> ""
 | (e,v)::l ->
    let b = Ebuffer.create 512 in
    Ebuffer.reset b;
    Ebuffer.output_string b (encode e);
    Ebuffer.output_char b '=';
    Ebuffer.output_string b (encode v);
    l |> List.iter (fun (e,v) ->
         Ebuffer.output_char b '&';
         Ebuffer.output_string b 
            (if !strict_form_standard 
             then encode e
             else e
             );
         Ebuffer.output_char b '=';
         Ebuffer.output_string b (encode v)
    ) ;
    Ebuffer.get b
@

<<signature Urlenc.strict_form_standard>>=
val strict_form_standard : bool ref
    (* if true, we take RFC1866 8.2.1 case 1 strictly, and encode any 
       non-alphanumeric character in the field name
       else, we encode only values, but not field names *)
@
<<constant Urlenc.strict_form_standard>>=
let strict_form_standard = ref true
@








\section{Links}

% Www.make -> <>
<<signature Hyper.resolve>>=
val resolve : link -> Uri.abs_uri
  (* raises Invalid_link(msg) *)
@
<<function Hyper.resolve>>=
(* Produces an URI *)
let resolve link =
  (* First remove the possible fragment of the uri *)
  let newuri, frag =
    try
       let pos = String.index link.h_uri '#' in
       String.sub link.h_uri 0 pos, 
       Some (String.sub link.h_uri (succ pos) 
                        (String.length link.h_uri - pos - 1))
    with Not_found -> link.h_uri, None 
  in
  if Uri.is_absolute newuri 
  then
    try
      { uri_url = Lexurl.normalize newuri;
        uri_frag = frag 
      }
    with Url_Lexing _ ->
      raise (Invalid_link
              (LinkResolve (I18n.sprintf "not a legal absolute uri")))

  else begin (* It is a relative uri *)
    let context =
      match link.h_context with 
      | None -> 
         raise (Invalid_link (LinkResolve (I18n.sprintf 
                  "no context and not an absolute url")))
      | Some c -> c 
    in
    let contextp = 
       try Lexurl.maken context
       with Url_Lexing (err,pos) ->
             raise (Invalid_link (UrlLexing (err,pos)))
    in
    { uri_url = urlconcat contextp newuri;
      uri_frag = frag
    }
  end
@
% will se urlconcat later
%old: (* Produces an URL *) but it's actually really an URI!


% Hyper.resolve -> <> (for relative links)
<<signature Hyper.urlconcat>>=
val urlconcat: Url.t -> string -> string
   (* [urlconcat url relurl] resolves the relative URL [relurl] in the
       context of the URL [url]
      Doesn't handle fragments
    *)
@
<<function Hyper.urlconcat>>=
(* parsed Absolute URL + URL -> Absolute URL *)
(* NO FRAGMENT HANDLING *)

let urlconcat contextp newuri =
  let l = String.length newuri in 
    if l = 0 then string_of contextp 
    else if l > 2 & newuri.[0] = '/' & newuri.[1] = '/' then
      (* this is probably a gopher relative uri *)
      sprintf "%s:%s" (string_of_protocol contextp.protocol) newuri
    else if newuri.[0] = '/' then (* start from root *)
      string_of {
        protocol = contextp.protocol;
     user = contextp.user;
     password = contextp.password;
        host = contextp.host;
        port = contextp.port;
     path = Some (Urlenc.unquote 
                (String.sub newuri 1 (String.length newuri - 1)));
     search = None }
    else if newuri.[0] = '?' then (* change only search part *)
      string_of {
        protocol = contextp.protocol;
     user = contextp.user;
     password = contextp.password;
        host = contextp.host;
        port = contextp.port;
     path = contextp.path;
     search = Some (String.sub newuri 1 (String.length newuri - 1))}
    else 
      let pathpart,searchpart =
    try
      let n = String.index newuri '?' in
      String.sub newuri 0 n,
      Some (String.sub newuri (n+1) (l - n - 1))
    with
      Not_found -> newuri, None
      in
      match contextp.path with
      None | Some "" -> 
        string_of {
        protocol = contextp.protocol;
        user = contextp.user;
        password = contextp.password;
        host = contextp.host;
        port = contextp.port;
        path = Some (Urlenc.unquote (Lexurl.remove_dots pathpart));
        search = searchpart}
    | Some old ->
        (* only the "dirname" part of the context path is important *)
        (* e.g  .../d/e/f becomes /d/e/ *)
       let path = sprintf "%s/%s" (Filename.dirname old) pathpart in
        (* we then have to remove dots *)
    let reduced = Lexurl.remove_dots path in
        string_of {
        protocol = contextp.protocol;
        user = contextp.user;
        password = contextp.password;
        host = contextp.host;
        port = contextp.port;
        path = Some (Urlenc.unquote reduced);
        search = searchpart}
@



% ??? -> <>
<<signature Hyper.parse_method>>=
val parse_method : string -> link_method
@
<<function Hyper.parse_method>>=
let parse_method = function
   "GET" -> GET
 | "HEAD" -> HEAD
 | "POST" -> POST ""
 | _ -> raise Not_found (* other cases should be caught by caller ! *)
@






\section{HTML}

%https://html.spec.whatwg.org/multipage/syntax.html#parsing


\subsection{Lexing}

% see type Html.token in core DS


<<signature Lexhtml.html>>=
val html : Lexing.lexbuf -> t -> warnings * Html.token * Html.location
@
<<signature Lexhtml.cdata>>=
val cdata : Lexing.lexbuf -> t -> warnings * Html.token * Html.location
@

<<type Html.location>>=
type location = Loc of int * int
@
% start x end  charpos, classic
<<type Lexhtml.warnings>>=
type warnings = (string * int) list
@
% charpos



\subsubsection{Reentrant lexers}
% need that?
% put in concurrency section?

<<signature type Lexhtml.t>>=
type t
@
<<signature Lexhtml.new_data>>=
val new_data : unit -> t
    (* instance data for a lexer; must be allocated for each instance, in
       order to get reentrant lexers
     *)
@


<<type Lexhtml.t>>=
(* Smart hack to make lexers reentrant.
 * Make each action a function taking "private" data as argument.
 * Invoke each action with additionnal argument.
 *  
 * This works only because calls to actions in csllex generated code
 * are terminal.
 *)
type t = {
  buffer : Ebuffer.t;
  mutable start : int;
  mutable pos_fix : int
}
@

<<function Lexhtml.new_data>>=
let new_data () = {
  buffer = Ebuffer.create 512;
  start = 0;
  pos_fix = 0 
}
@
% only way to build abstract type t
% who change pos_fix??


\subsubsection{Helpers}

<<helper functions Lexhtml.xxx>>=
let noerr = []
@

<<helper functions Lexhtml.xxx>>=
let mk_start lexbuf lexdata =
  Lexing.lexeme_start lexbuf - lexdata.pos_fix
let mk_end lexbuf lexdata =
  Lexing.lexeme_end lexbuf - lexdata.pos_fix
let mk_loc lexbuf lexdata =
  Loc (mk_start lexbuf lexdata, mk_end lexbuf lexdata)
@





%japan
%and kanji = parse
%  | ['\033' - '\126']+ 
%    { (fun lexdata charset ->
%      match charset with
%    '\064' | '\066' | '\068' (* JISX0208/JISX0212 *) ->
%      let lexeme = Lexing.lexeme lexbuf in
%      let rawlength = String.length lexeme in
%      if rawlength mod 2 = 1 then 
%        Log.f ("Warning: Lexhtml: Odd bytes Kanji string length");
%      let klength = rawlength / 2 in
%      lexdata.pos_fix <- lexdata.pos_fix + klength;
%      Ebuffer.output_string lexdata.buffer lexeme;
%      kanji lexbuf lexdata charset
%      | _ -> raise (Failure (Printf.sprintf "Lexhtml: Unknown charset %d" 
%                   (Char.code charset))) 
%    )}
%  | ['\000' - '\026' '\028' - '\032' '\127'] (* Control codes *) 
%    { (fun lexdata charset ->
%      Ebuffer.output_char lexdata.buffer (Lexing.lexeme_char lexbuf 0);
%      kanji lexbuf lexdata charset )}
%  | ['\128' - '\255'] (* Right side *)
%    { (fun lexdata charset ->
%        raise (Failure "Lexhtml: Unexpected right side character") )}
%  | "" (* Must be escape *)
%    { (fun lexdata charset -> () )}


<<function Lexhtml.html>>=
rule html = parse
<<[[Lexhtml.html()]] rule cases>>
 | "\r\n" 
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       Ebuffer.reset lexdata.buffer;
       Ebuffer.output_char lexdata.buffer '\n'; 
       text lexbuf lexdata )}
 | "\r" 
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       Ebuffer.reset lexdata.buffer;
       Ebuffer.output_char lexdata.buffer '\n'; 
       text lexbuf lexdata )}
| eof 
    { (fun lexdata -> 
        (noerr, EOF, mk_loc lexbuf lexdata)) }
| _ { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       Ebuffer.reset lexdata.buffer;
       Ebuffer.output_char lexdata.buffer (Lexing.lexeme_char lexbuf 0); 
       text lexbuf lexdata )}
@
%(*
% | "\027\036" '\040'? ['\064' - '\068'] (* KANJI *)
%     {(fun lexdata ->
%       let lexeme = Lexing.lexeme lexbuf in
%       let len = String.length lexeme in
%       lexdata.start <- Lexing.lexeme_start lexbuf - lexdata.pos_fix;
%       lexdata.pos_fix <- lexdata.pos_fix + len;
%       Ebuffer.reset lexdata.buffer;
%       Ebuffer.output_string lexdata.buffer lexeme;
%       let c = Lexing.lexeme_char lexbuf (len - 1) in
%       if !Lang.japan then kanji lexbuf lexdata c;
%       text lexbuf lexdata )}
%*)
% need all those \027\040\066 cases? japanese stuff?
% | "\027\040\066" (* ASCII *)
%    { (fun lexdata ->
%       lexdata.start <- mk_start lexbuf lexdata;
%       lexdata.pos_fix <- lexdata.pos_fix + 3;
%       Ebuffer.reset lexdata.buffer;
%       text lexbuf lexdata )}


\subsubsection{Comments}

<<[[Lexhtml.html()]] rule cases>>=
| "<!>" 
    { (fun lexdata ->
       noerr, Comment "", mk_loc lexbuf lexdata)}
@

<<[[Lexhtml.html()]] rule cases>>=
(* If you think it is possible to deal with malformed comments adaptatively,
   that is switching to lenient mode only after we detected an error
   in comment syntax, then ponder the following example: <!-- -- --> *)
 | "<!--"
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       Ebuffer.reset lexdata.buffer;
       if !strict 
       then comment lexbuf lexdata
       else lenient_end_comment lexbuf lexdata
       )
    } 
@


<<function Lexhtml.lenient_end_comment>>=
(* call this ONLY if we are not in strict mode *)
and lenient_end_comment = parse
| "-->"
    {(fun lexdata -> 
      noerr, Comment (Ebuffer.get lexdata.buffer),
      Loc(lexdata.start, mk_end lexbuf lexdata))}
| _
    {(fun lexdata ->
      Ebuffer.output_char lexdata.buffer (Lexing.lexeme_char lexbuf 0);
      lenient_end_comment lexbuf lexdata )}
| ""
    {(fun lexdata ->
       raise (Html_Lexing ("unterminated comment", mk_start lexbuf lexdata))
    )}
@
%| "\027\040\066" (* ASCII *)
%    {(fun lexdata ->
%      lexdata.pos_fix <- lexdata.pos_fix + 3;
%      Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
%      lenient_end_comment lexbuf lexdata )}
%(*
%  | "\027\036" '\040'? ['\064' - '\068'] (* KANJI *)
%      {(fun lexdata ->
%    let lexeme = Lexing.lexeme lexbuf in
%    Ebuffer.output_string lexdata.buffer lexeme;
%    let len = String.length lexeme in
%    lexdata.pos_fix <- lexdata.pos_fix + len; 
%    let c = Lexing.lexeme_char lexbuf (len - 1) in
%    if !Lang.japan then kanji lexbuf lexdata c; 
%    lenient_end_comment lexbuf lexdata )}
%*)


<<function Lexhtml.comment>>=
(* we're looking for the end of a comment : skip all characters until next   *)
(*  -- included, and then look for next -- or > *)
and comment = parse
  (* normal case *)
| "--"
    { (fun lexdata -> 
       next_comment lexbuf lexdata)}
| _  
    { (fun lexdata ->
       Ebuffer.output_char lexdata.buffer (Lexing.lexeme_char lexbuf 0);
       comment lexbuf lexdata )}
| ""
    { (fun lexdata ->
       raise (Html_Lexing ("unterminated comment", mk_start lexbuf lexdata))
    )}
@
%| "\027\040\066" (* ASCII *)
%    { (fun lexdata ->
%       Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
%       lexdata.pos_fix <- lexdata.pos_fix + 3;
%       (* do nothing except position fix *)
%       comment lexbuf lexdata )}
%(*
%  | "\027\036" '\040'? ['\064' - '\068'] (* KANJI *)
%      {(fun lexdata ->
%    let lexeme = Lexing.lexeme lexbuf in
%    Ebuffer.output_string lexdata.buffer lexeme;
%    let len = String.length lexeme in
%    lexdata.pos_fix <- lexdata.pos_fix + len; 
%    let c = Lexing.lexeme_char lexbuf (len - 1) in
%    if !Lang.japan then kanji lexbuf lexdata c; 
%    comment lexbuf lexdata )}
%*)


<<function Lexhtml.next_comment>>=
(* the normal next comment search *)      
and next_comment = parse
    [' ' '\t' '\r' '\n']* "--"
    { (fun lexdata -> comment lexbuf lexdata )}
  | [' ' '\t' '\r' '\n']* '>'
    { (fun lexdata ->
      [],
      Comment (Ebuffer.get lexdata.buffer),
      Loc(lexdata.start, mk_end lexbuf lexdata))}
  | "" 
    { (fun lexdata ->
      raise (Html_Lexing ("invalid comment", mk_start lexbuf lexdata)))
     }
@



\subsubsection{Tags}

<<type Lexhtml.tagtoken>>=
type tagtoken =
   Attribute of string * string
 | Closetag of int
 | Bogus of string * int   (* Bogus(s,n) == bug at pos [n] for reason [s] *)
@

% opening tags
<<[[Lexhtml.html()]] rule cases>>=
| '<' 
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       opentag lexbuf lexdata
     )}
@

<<function Lexhtml.opentag>>=
(* TODO 2.0: 
 *   syntax for SHORTTAG YES (need to know the DTD for this !).
 *
 *)
and opentag = parse
| ['a'-'z' 'A'-'Z' '0'-'9' '.' '-']+
    { (fun lexdata ->
       let tagname = String.lowercase (Lexing.lexeme lexbuf) in
       let attribs = ref [] in
       let bugs = ref [] in
       let rec read_attribs () =
         match attrib lexbuf lexdata with
         | Closetag n -> 
             n
         | Attribute(p1, p2) ->
             attribs := (p1, p2) :: !attribs; 
             read_attribs()
         | Bogus (reason,pos) ->
             bugs := (reason,pos) :: !bugs; 
             read_attribs() 
       in
       let e = read_attribs() in
       (!bugs, 
       OpenTag {tag_name = tagname; attributes = List.rev !attribs },
       Loc(lexdata.start, e)
       )
      )}
  
(* Tolerance *)
| ""  
    { (fun lexdata ->
       Ebuffer.reset lexdata.buffer;
       Ebuffer.output_char lexdata.buffer '<';
       text lexbuf lexdata )}
@


% closing tags

<<[[Lexhtml.html()]] rule cases>>=
| '\n'? "</"
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       closetag lexbuf lexdata
      )}
@

<<function Lexhtml.closetag>>=
and closetag = parse
  | ['a'-'z' 'A'-'Z' '0'-'9' '.' '-']+
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
    let e = skip_to_close lexbuf lexdata in
    [],
    CloseTag (String.lowercase lexeme), Loc(lexdata.start,e))}
(* Tolerance *)
  | ""  
    { (fun lexdata ->
          Ebuffer.reset lexdata.buffer;
          Ebuffer.output_string lexdata.buffer "</";
          text lexbuf lexdata)}
@

<<function Lexhtml.skip_to_close>>=
and skip_to_close = parse
   [^'>']* '>' { (fun lexdata -> mk_end lexbuf lexdata)}
  | "" { (fun lexdata -> 
      raise (Html_Lexing ("unterminated tag", 
              mk_start lexbuf lexdata)) )}
@

\subsubsection{Attributes}

% opentag -> <>
<<function Lexhtml.attrib>>=
and attrib = parse
| [' ' '\t' '\n' '\r']+ 
    { (fun lexdata -> attrib lexbuf lexdata )}
| ['a'-'z' 'A'-'Z' '0'-'9' '.' '-']+ 
    { (fun lexdata ->
        let name = String.lowercase(Lexing.lexeme lexbuf) in
        try
          match tagattrib lexbuf lexdata with
          | Some s -> Attribute (name, s)
          | None -> Attribute (name, name)
        with Html_Lexing(reason,pos) -> 
          if !strict 
          then raise (Html_Lexing(reason,pos));
          Bogus(reason,pos)
      )}
  (* added '_' so we can parse Netscape bookmark files, 
      but it should NOT be there *)
| ['a'-'z' 'A'-'Z' '0'-'9' '.' '-' '_']+ 
    { (fun lexdata ->
       let name = String.lowercase(Lexing.lexeme lexbuf) in
       if !strict 
       then raise (Html_Lexing ("illegal attribute name: " ^ name,
                                 mk_start lexbuf lexdata))
       else
         try
           match tagattrib lexbuf lexdata with
           | Some s -> Attribute (name, s)
           | None -> Attribute (name, name)
         with Html_Lexing(reason,pos) -> Bogus(reason,pos)
      )}
| '>' '\n'?
    { (fun lexdata -> Closetag (mk_end lexbuf lexdata) )}
| eof 
    { (fun lexdata -> raise (Html_Lexing ("unclosed tag",
                               mk_start lexbuf lexdata)))}

(* tolerance: we are expecting an attribute name, but can't get any *)
(* skip the char and try again. (The char cannot be > !) *)
| _
    { (fun lexdata ->
        if !strict 
        then raise (Html_Lexing ("invalid attribute name",
                                  mk_start lexbuf lexdata));
        Bogus ("invalid attribute name", mk_start lexbuf lexdata)
    )}
@

% attrib -> <>
<<function Lexhtml.tagattrib>>=
and tagattrib = parse
| [' ' '\t' '\n' '\r']* '=' [' ' '\t' '\n' '\r']*
    { (fun lexdata -> Some (attribvalue lexbuf lexdata) )}
| "" 
    { (fun lexdata -> None )}
@  

% opentag -> attrib -> tagattrib -> <>
<<function Lexhtml.attribvalue>>=
(* This should be dependent on the attribute name *)
(* people often forget to quote, so try to do something about it *)
(* but if a quote is not closed, you are dead *)
and attribvalue = parse
| ['a'-'z' 'A'-'Z' '0'-'9' '.' '-']+ 
    { (fun lexdata -> Lexing.lexeme lexbuf )}
| '"' 
    { (fun lexdata ->
       Ebuffer.reset lexdata.buffer; 
       inquote lexbuf lexdata )}
| '\''
    { (fun lexdata ->
       Ebuffer.reset lexdata.buffer; 
       insingle lexbuf lexdata )}
| "" 
    { (fun lexdata ->
        raise (Html_Lexing ("illegal attribute val",
                              Lexing.lexeme_start lexbuf)) )}
@
%  | ("\027\036" '\040'? ['\064' - '\068'] (* remove control codes *)
%        ['\033' - '\126']+ | (* suppose we have no empty KANJI seq *)
%     [^ '"' '\'' '>' '\027']) 
%    ("\027\036" '\040'? ['\064' - '\068'] ['\033' - '\126']+ |
%     "\027\040\066" |
%     [^ ' ' '\t' '\n' '\r' '>' '\027']*)
%    { (fun lexdata ->
%       let lexeme = Lexing.lexeme lexbuf in
%       lexdata.pos_fix <- String.length lexeme - Lexkanji.length lexeme;
%       lexeme )}


<<function Lexhtml.inquote>>=
and inquote = parse
| [^ '"' '&' '\027']+
    { (fun lexdata ->
       Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
       inquote lexbuf lexdata )}
| '"'
    { (fun lexdata ->
       Html.beautify true (Ebuffer.get lexdata.buffer) )}
| '&'
    { (fun lexdata ->
       Ebuffer.output_string lexdata.buffer (ampersand lexbuf lexdata);
       inquote lexbuf lexdata )}
| ""
    { (fun lexdata ->
       raise (Html_Lexing ("unclosed \"", mk_start lexbuf lexdata))
     )}
@
%  | "\027\040\066" (* ASCII *)
%      { (fun lexdata ->
%    lexdata.pos_fix <- lexdata.pos_fix + 3;
%    Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
%    inquote lexbuf lexdata )}
%(*
%  | "\027\036" '\040'? ['\064' - '\068'] (* KANJI *)
%      {(fun lexdata ->
%    let lexeme = Lexing.lexeme lexbuf in
%    Ebuffer.output_string lexdata.buffer lexeme;
%    let len = String.length lexeme in
%    lexdata.pos_fix <- lexdata.pos_fix + len; 
%    let c = Lexing.lexeme_char lexbuf (len - 1) in
%    if !Lang.japan then kanji lexbuf lexdata c;
%    inquote lexbuf lexdata )}
%*)

<<function Lexhtml.insingle>>=
and insingle = parse
| [^ '\'' '&']+
    { (fun lexdata ->
       Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
       insingle lexbuf lexdata )}
| '\''
    { (fun lexdata -> 
       Html.beautify true (Ebuffer.get lexdata.buffer) )}
| '&'
    { (fun lexdata ->
       Ebuffer.output_string lexdata.buffer (ampersand lexbuf lexdata);
       insingle lexbuf lexdata )}
| ""
    { (fun lexdata ->
       raise (Html_Lexing ("unclosed '", mk_start lexbuf lexdata))
    )}
@



<<signature Html.beautify>>=
val beautify: bool -> string -> string
  (* [beautify remove_leading_space s] removes sequences of SP *)
@

% (attrib -> insingle) | ...  -> <> 
<<function Html.beautify>>=
(*
 * Remove sequences of white
 *   turns out to be faster than global_replace in libstr
 *   could use String.blit to avoid char copying
 * NOTE: add \0 detection here (we need it for Tk)
 *)
let beautify remove_leading s =
  let j = ref 0 in
  let white = ref remove_leading in
  for i = 0 to String.length s - 1 do
    match s.[i] with
    | ' ' | '\t' | '\r' | '\n' | '\000' -> 
       if not !white 
       then begin
         s.[!j] <- ' '; 
         incr j; 
         white := true
       end
    | c -> 
       s.[!j] <- c; 
       white := false; 
       incr j
  done;
  String.sub s 0 !j
@


\subsubsection{Doctype}

% doctype indeed
<<[[Lexhtml.html()]] rule cases>>=
| "<!" ['D''d']['O''o']['C''c']['T''t']['Y''y']['P''p']['E''e'] [^ '>']* '>'
    { (fun lexdata ->
       noerr, Doctype (Lexing.lexeme lexbuf), mk_loc lexbuf lexdata )}
@

\subsubsection{Text}

<<function Lexhtml.text>>=
and text = parse
| [^ '<' '&' '\r' '\027']+
    { (fun lexdata ->
      let _sTODO = Lexing.lexeme lexbuf in
      Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);  
      text lexbuf lexdata )}
| [^ '<' '&' '\r' '\027']* '&'
    { (fun lexdata ->
       let lexeme = Lexing.lexeme lexbuf in
       Ebuffer.output lexdata.buffer lexeme 0 (String.length lexeme -1) ;
       Ebuffer.output_string lexdata.buffer (ampersand lexbuf lexdata); 
       text lexbuf lexdata )}
| [^ '<' '&' '\r' '\027']* '\r' '\n'
    { (fun lexdata ->
       let lexeme = Lexing.lexeme lexbuf in
       Ebuffer.output lexdata.buffer lexeme 0 (String.length lexeme - 2);
       Ebuffer.output_char lexdata.buffer '\n';
       text lexbuf lexdata )}
| [^ '<' '&' '\r' '\027']* '\r'
    { (fun lexdata ->
       let lexeme = Lexing.lexeme lexbuf in
       Ebuffer.output lexdata.buffer lexeme 0 (String.length lexeme - 1);
       Ebuffer.output_char lexdata.buffer '\n';
       text lexbuf lexdata )}
| ""
    { (fun lexdata ->    
       noerr, 
       PCData (Ebuffer.get lexdata.buffer), 
       Loc(lexdata.start, mk_end lexbuf lexdata)
      )}
 (* no default case needed *)
@
% | "\027\040\066" (* ASCII *)
%     { (fun lexdata ->
%     lexdata.start <- mk_start lexbuf lexdata;
%     lexdata.pos_fix <- lexdata.pos_fix + 3;
%     Ebuffer.output_string lexdata.buffer (Lexing.lexeme lexbuf);
%     text lexbuf lexdata )}
%(*
% | "\027\036" '\040'? ['\064' - '\068'] (* KANJI *)
%     {(fun lexdata ->
%       let lexeme = Lexing.lexeme lexbuf in
%       let len = String.length lexeme in
%       lexdata.start <- mk_start lexbuf lexdata;
%       lexdata.pos_fix <- lexdata.pos_fix + len;
%       Ebuffer.output_string lexdata.buffer lexeme;
%       let c = Lexing.lexeme_char lexbuf (len - 1) in
%       if !Lang.japan then kanji lexbuf lexdata c;
%       text lexbuf lexdata )}
%*)

\subsubsection{Data}

% ??? -> <>
<<function Lexhtml.cdata>>=
and cdata = parse
| [^ '<']* (['<']+ [^ '/']) ? 
    { (fun lexdata ->
        noerr, CData(Lexing.lexeme lexbuf), mk_loc lexbuf lexdata)}
      
| "</" ['a'-'z' 'A'-'Z' '0'-'9' '.' '-']+
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
        let _eTODO = skip_to_close lexbuf lexdata in
        noerr,
        CloseTag (String.lowercase 
                      (String.sub lexeme 2 (String.length lexeme - 2))),
        mk_loc lexbuf lexdata)}
| "</" 
    { (fun lexdata ->
        noerr, CData(Lexing.lexeme lexbuf), mk_loc lexbuf lexdata) }

| eof
    { (fun lexdata ->
        noerr, EOF, mk_loc lexbuf lexdata) }
@

\subsubsection{Entities, [[&xxx;]]}

<<[[Lexhtml.html()]] rule cases>>=
 | '&' 
    { (fun lexdata ->
       lexdata.start <- mk_start lexbuf lexdata;
       Ebuffer.reset lexdata.buffer;
       Ebuffer.output_string lexdata.buffer 
         (ampersand lexbuf lexdata);
       text lexbuf lexdata )}
@


<<function Lexhtml.ampersand>>=
and ampersand = parse
| '#' ['0'-'9']+ ';' 
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
        let code = String.sub lexeme 1 (String.length lexeme - 2) in
        try 
          String.make 1 (Char.chr (int_of_string code))
        with (* #350 ... *) Invalid_argument _ -> " "
      )}
| ['a'-'z' 'A'-'Z'] ['a'-'z' 'A'-'Z' '0'-'9']* ';'
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
        let entity = String.sub lexeme 0 (String.length lexeme - 1) in
        try 
          get_entity entity
        with (* 4.2.1 undeclared markup error handling *) Not_found ->
          ("&" ^ lexeme)
      )}
  (* terminating ; is not required if next character could not be 
     part of the lexeme *)
| '#' ['0'-'9']+
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
        let code = String.sub lexeme 1 (String.length lexeme - 1) in
        try 
          String.make 1 (Char.chr (int_of_string code))
        with Invalid_argument _ -> " "
      )}
 | ['a'-'z' 'A'-'Z'] ['a'-'z' 'A'-'Z' '0'-'9']*
    { (fun lexdata ->
        let lexeme = Lexing.lexeme lexbuf in
        try 
          get_entity lexeme
        with (* 4.2.1 undeclared markup error handling *) Not_found -> 
          ("&"^lexeme)
      )}
  (* Tolerance ... *)
| ""
    { (fun lexdata -> "&" )}
@
%        (*if !Lang.japan then
%         "\027\040\066" ^ String.make 1 (Char.chr (int_of_string code))
%        else
%         *)
%      (*if !Lang.japan then
%        "\027\040\066" ^ String.make 1 (Char.chr (int_of_string code))
%      else
%      *)







% Lexhtml.html -> ampersand -> <>
<<signature Html.get_entity>>=
val get_entity : string -> string
  (* [get_entity "amp"] returns "&" *)
@

<<constant Html.get_entity>>=
let get_entity = Hashtbl.find ampersand_table
@


<<constant Html.ampersand_table>>=
(* 
 * HTML encoding of ISO-latin1 characters
 *  cf Appendix B - Proposed Entities
 *)

let ampersand_table = 
  (Hashtbl.create 101: (string , string) Hashtbl.t)
@





%\subsection{HTML initialisation}

<<[[Main.main()]] html entities initialisation>>=
(* Initialization of HTML entities *)
Html.init (Lang.lang());
@

<<signature Html.init>>=
val init : string -> unit 
@

<<function Html.init>>=
let init _lang =
  latin1_normal |> List.iter (fun (str, c) -> 
    Hashtbl.add ampersand_table str c) 
@
%  (* (if japan then latin1_japan else latin1_normal)  *)

<<constant Html.latin1_normal>>=
let latin1_normal = [
  "amp", 	"&";
  "gt", 	">";
  "lt" , 	"<";
  "quot", 	"\"";

  <<[[latin1_normal]] elements>>
]
@
% see more in language or special chars section

\subsubsection{Strict mode}

<<signature Lexhtml.strict>>=
val strict : bool ref
    (* if true, use strict parsing; else, activate leniency on some
       lexing decisisons such as: comments, attribute names and values
     *)
@
<<global Lexhtml.strict>>=
let strict = ref false
@

%todo: aspectize strict

\subsection{Parsing part 1, the DTD}
% it's not really parsing though, it's really more adjusted lexing no?

% for 3.2
% html 4.0 and 5.0 has been published
% TODO: add 4.0 with span element


<<module Dtd.elements>>=
module Elements = Set.Make(struct type t = string let compare = compare end)
@

<<type Dtd.t>>=
type t = {
  dtd_name : string;
  contents : (string, Elements.t) Hashtbl.t;
    (* for each element, give the set of included elements *)

  mutable open_omitted : Elements.t;
    (* set of elements for which opening tag may be omitted *)
  mutable close_omitted : Elements.t
    (* set of elements for which closing tag may be omitted *)
 } 
@

<<signature Dtd.dtd32>>=
val dtd32 : t
@

<<signature Dtd.name>>=
val name : t -> string
@
<<function Dtd.name>>=
let name t = 
  t.dtd_name
@


<<function Dtd.sol>>=
(* Utils *)
let sol l =
  List.fold_right Elements.add l Elements.empty
@

<<function Dtd.sos>>=
let sos l =
  List.fold_right Elements.union l Elements.empty
@



%(* #PCDATA and #CDATA are considered as elements, but they will never
%   be pushed on the stack during evaluation. Moreover, since they are
%   not in open_omitted/close_omitted, minimization algorithm will not
%   attempt to choose them
% *)

%todo: copy the comments made on dtd20 to dtd32
% and adapt to latest dtd of html5?
<<constant Dtd.dtd32>>=
let dtd32 =
  let dtd = {
    dtd_name = "HTML 3.2";
    contents = Hashtbl.create 53;
    open_omitted = Elements.empty;
    close_omitted = Elements.empty
     } in
  let omit_open el =
    dtd.open_omitted <- Elements.add el dtd.open_omitted
  and omit_close el =
    dtd.close_omitted <- Elements.add el dtd.close_omitted
  and add_elem = Hashtbl.add dtd.contents
  in

  let head_misc_E = sol ["script"; "style"; "meta"; "link"]
  and heading_E = sol ["h1"; "h2"; "h3"; "h4"; "h5"; "h6"]
  and list_E = sol ["ul"; "ol"; "dir"; "menu"]
  and preformatted_E = sol ["pre"; "xmp"; "listing"]
  and font_E =
     sol ["tt"; "i"; "b"; "u"; "strike"; "big"; "small"; "sub"; "sup"]
  and phrase_E =
     sol ["em"; "strong"; "dfn"; "code"; "samp"; "kbd"; "var"; "cite"]
  and special_E =
     sol ["a"; "img"; "applet"; "font"; "basefont"; "br"; "script"; "map"]
  and form_E =
     sol ["input"; "select"; "textarea"]
  in
  (* EMBED is not in the original DTD ! *)
  let text_E =
     sos [sol ["#pcdata"; "embed"]; font_E; phrase_E; special_E; form_E]
  in
  Elements.iter (fun e -> add_elem e text_E) font_E;
  Elements.iter (fun e -> add_elem e text_E) phrase_E;
  add_elem "font" text_E;
  add_elem "basefont" Elements.empty;
  omit_close "basefont";
  add_elem "br" Elements.empty;
  omit_close "br";

  let block_E =
    sos [sol ["p"; "dl"; "div"; "center"; "blockquote"; "form"; "isindex";
              "hr"; "table"];
         list_E; preformatted_E]
  in
  let flow_E = sos [text_E; block_E]
  in
  let body_content_E = sos [sol ["address"]; heading_E; text_E; block_E]
  in
  add_elem "body" body_content_E;
  omit_open "body";
  omit_close "body";

  let address_content_E = sos [sol ["p"]; text_E] in
  add_elem "address" address_content_E;
  
  add_elem "div" body_content_E;
  add_elem "center" body_content_E;

  add_elem "a" (Elements.remove "a" text_E);
  
  add_elem "map" (sol ["area"]);
  add_elem "area" Elements.empty;
  omit_close "area";

  add_elem "link" Elements.empty;
  omit_close "link";
   
  add_elem "img" Elements.empty;
  omit_close "img";

  add_elem "applet" (Elements.add "param" text_E);
  add_elem "param" Elements.empty;
  omit_close "param";

  add_elem "hr" Elements.empty;
  omit_close "hr";

  add_elem "p" text_E;
  omit_close "p";

  Elements.iter (fun e -> add_elem e text_E) heading_E;

  let pre_exclusion_E = sol ["img"; "big"; "small"; "sub"; "sup"; "font"]
  in
  add_elem "pre" (Elements.diff text_E pre_exclusion_E);

  List.iter (fun e -> add_elem e (sol ["#cdata"])) ["xmp"; "listing"];

  add_elem "blockquote" body_content_E;

  add_elem "dl" (sol ["dt"; "dd"]);
  add_elem "dt" text_E; omit_close "dt";
  add_elem "dd" flow_E; omit_close "dd";

  List.iter (fun e -> add_elem e (sol ["li"])) ["ol"; "ul"];
  List.iter (fun e -> add_elem e (sol ["li"])) ["dir"; "menu"];

  add_elem "li" flow_E;
  omit_close "li";


  add_elem "form" (Elements.remove "form" body_content_E);
  add_elem "input" Elements.empty;
  omit_close "input";
  add_elem "select" (sol ["option"]);
  add_elem "option" (sol ["#pcdata"]);
  omit_close "option";
  add_elem "textarea" (sol ["#pcdata"]);


  add_elem "table" (sol ["caption"; "tr"]);
  add_elem "tr" (sol ["th"; "td"]);
  omit_close "tr";
  List.iter (fun e -> add_elem e body_content_E; omit_close e) ["th"; "td"];
  add_elem "caption" text_E;


  let head_content_E = sol ["title"; "isindex"; "base"]
  in

  add_elem "head" (Elements.union head_content_E head_misc_E);
  omit_close "head";
  omit_open "head";

  add_elem "title" (sol ["#pcdata"]);
  add_elem "isindex" Elements.empty;
  omit_close "isindex";
  add_elem "base" Elements.empty;
  omit_close "base";
  add_elem "meta" Elements.empty;
  omit_close "meta";

  add_elem "script" (sol ["#cdata"]);
  add_elem "style" (sol ["#cdata"]);

  let html_content_E = sol ["head"; "body"] in

  add_elem "html" html_content_E;
  omit_open "html";
  omit_close "html";

  (* fake element PCDATA for minimisation rules *)
  add_elem "#pcdata" Elements.empty;

  (* embed is an extension *)
  add_elem "embed" Elements.empty;
  omit_close "embed";

  dtd
@



<<constant Dtd.table>>=
let table = Hashtbl.create 11
@

<<signature Dtd.add>>=
val add : t -> unit
@

<<signature Dtd.get>>=
(* A table of DTDs for preferences *)
val get : string -> t
@

<<signature Dtd.names>>=
val names : unit -> string list
@

<<signature Dtd.current>>=
val current : t ref 
@
<<constant Dtd.current>>=
let current = ref dtd32
@



<<function Dtd.add>>=
let add t = 
  Hashtbl.add table t.dtd_name t
@

<<constant Dtd.get>>=
let get = 
  Hashtbl.find table
@

<<function Dtd.names>>=
let names () =
  let names = ref [] in
   Hashtbl.iter (fun name _ -> names := name :: !names) table;
   !names
@



<<constant Dtd.dtd32f>>=
(* Add frames somwhere to dtd32.
 * Luckily we chose sets, and they are functional
 *)
let dtd32f =
  let dtd = {
    dtd_name = "HTML 3.2 + frames";
    contents = Hashtbl.create 101;
    open_omitted = dtd32.open_omitted;
    close_omitted = dtd32.close_omitted;
  } in
  let omit_open el =
    dtd.open_omitted <- Elements.add el dtd.open_omitted
  and omit_close el =
    dtd.close_omitted <- Elements.add el dtd.close_omitted
  and add_elem = 
   Hashtbl.add dtd.contents
  in
  (* first : copy in the 3.2 contents *)
  Hashtbl.iter add_elem dtd32.contents;

  (* frameset and frames is pretty simple *)
  add_elem "frameset" (sol ["frameset"; "frame"; "noframes"]);
  add_elem "frame" Elements.empty;
  omit_close "frame";
  (* we say that noframes contains the same thing as body in 3.2 *)
  add_elem "noframes" (Hashtbl.find dtd.contents "body");
  (* and we say that frameset can occur in html *)
  let html_contents = Hashtbl.find dtd.contents "html" in
  Hashtbl.remove dtd.contents "html";
  add_elem "html" (Elements.add "frameset" 
             (Elements.add "noframes" html_contents));
  dtd
@

<<toplevel Dtd._1>>=
let _ = add dtd20; add dtd32
@

<<toplevel Dtd._2>>=
let _ = add dtd32f
@


\subsection{Parsing part 2, the SGML evaluator}

\subsubsection{[[automat()]]}

% Htparse.html_lex | ... -> <>
<<signature Html_eval.automat>>=
val automat : 
  Dtd.t -> Lexing.lexbuf -> 
  (Html.location -> Html.token -> unit) -> (* action callback *)
  (Html.location -> string -> unit) -> (* error callback *)
  unit
@
% main parsing function apparently

<<function Html_eval.automat>>=
let automat dtd lexbuf action error =
  try
    let lexer = sgml_lexer dtd in
    while true do
      try 
        let warnings, correct, tokens, loc = lexer lexbuf in
        warnings |> List.iter (fun (reason, pos) -> 
          error (Loc(pos,succ pos)) reason
        );
        (match correct with
        | Legal -> ()
        | Illegal reason -> error loc reason
        );
        tokens |> List.iter (function token -> 
          (try 
            (* calling the callback *)
            action loc token
          with Invalid_Html s -> error loc s
          );
          if token = EOF 
          then failwith "quit_html_eval"
        )
      with Html_Lexing (s,n) -> error (Loc(n,n+1)) s
    done
  with Failure "quit_html_eval" -> ()
@



\subsubsection{[[sgml_lexer()]]}

<<type Html_eval.minimization>>=
(* Wrapped up lexer to insert open/close tags in the stream of "normal"
   tokens, according to some DTD, in order to always get fully parenthesized
   streams *)

type minimization =
  Legal | Illegal of string
@

<<signature Html_eval.sgml_lexer>>=
val sgml_lexer :
  Dtd.t -> Lexing.lexbuf -> 
  (Lexhtml.warnings * minimization * Html.token list * Html.location)
@



<<function Html_eval.sgml_lexer>>=
let sgml_lexer dtd =
  let current_lex = ref Lexhtml.html in
  let stack = ref [] in
  let lexdata = Lexhtml.new_data () in

  (* currently allowed elements *)
  let allowed () = 
    match !stack with
    | [] -> initial
    | (elem, cts)::_ -> cts 
  in
  (* whatever the situation (but close), if the previous element is empty
     with an omittable close, close it *)
  let close_empty () = 
    match !stack with
    | [] -> []
    | (elem, ctx)::l ->
        if Elements.is_empty ctx && Elements.mem elem dtd.close_omitted
        then (stack := l; [CloseTag elem])
        else []
  in  
  (fun lexbuf ->
    let warnings, token, loc = !current_lex lexbuf lexdata in
    if !debug 
    then begin prerr_string "got "; Html.print token; prerr_newline() end;
    let status, tokens = 
      match token with
      | OpenTag t ->
          begin try (* first check that we know this element *)
            let contents = Hashtbl.find dtd.contents t.tag_name in
            let extraclose = close_empty() in    
            (* check changing of lexers; this works only if error recovery
               rules imply that the tag will *always* be open
             *)
            if is_cdata contents 
            then current_lex := Lexhtml.cdata
            else current_lex := Lexhtml.html;

            (* is it allowed in here ? *)
            if Elements.mem t.tag_name (allowed()) then begin
              (* push on the stack *)
              stack := (t.tag_name, contents) :: !stack;
              Legal, extraclose @ [token]
            end else begin (* minimisation or error *)
              let flag, (res, l) = ominimize dtd t !stack in
              stack := l;
              flag, extraclose @ res
            end
          with Not_found -> 
            (* Not in the DTD ! We return it, but don't change our state
               or stack. An applet extension to the HTML display machine
               can attempt to do something with it *)
            Illegal (sprintf "Element %s not in DTD" t.tag_name),
            [token]
         end
        
      | CloseTag t ->
          begin try (* do we know this element *)
            let _ = Hashtbl.find dtd.contents t in
            match !stack with
            | [] -> 
              Illegal(sprintf "Unmatched closing </%s>" t), []
            | (elem, cts)::l when elem = t -> (* matching close *)
                 stack := l; (* pop the stack *)
                 (* the lexer has to be "normal" again, because CDATA
                    can't be nested anyway *)
                 current_lex := Lexhtml.html;
                 Legal, [token]
            | (elem, cts)::l -> (* unmatched close ! *)
                (* if we were in cdata, change the token to cdata *)
                 if is_cdata cts 
                 then Legal, [CData (sprintf "</%s>" t)]
                 else begin
                   current_lex := Lexhtml.html;
                   let flag, (res, l) = cminimize dtd t !stack in
                   stack := l;
                   flag, res
                 end
        with Not_found ->
          Illegal (sprintf "Element %s not in DTD" t),
          [token]
        end
     | PCData s ->
         let extraclose = close_empty() in    
         (* is it allowed in here ? *)
         if Elements.mem "#pcdata" (allowed()) 
         then  Legal, extraclose @ [token]
          (* ignore PCData made of spaces if not relevant to the context *)
         else 
           if issp s 
           then Legal, extraclose
           else begin	    
              (* bad hack. make believe that we try to open the #pcdata element *)
             let flag, (res, l) = 
             ominimize dtd {tag_name = "#pcdata"; attributes = []} !stack in
             stack := l;
             flag,  extraclose @ res @ [token]
           end

    (* CData never happens with an empty stack *)
    | CData s ->
        let extraclose = close_empty() in    
        if Elements.mem "#cdata" (allowed()) 
        then Legal, extraclose @ [token]
        else
           Illegal(sprintf "Unexpected CDATA in %a" dump_stack !stack),
           extraclose @ [token]
        
    (* See if the stack is empty *)
    | EOF ->
       begin 
        match !stack with
        | [] -> Legal, [EOF]
        | l ->
           (* we must be able to close all remaining tags *)
           let rec closethem tokens = function
           | [] -> None, EOF :: tokens
           | (last,_) :: l ->
               if Elements.mem last dtd.close_omitted 
               then closethem (CloseTag last::tokens) l
               else
                 let status, tokens = 
                   closethem (CloseTag last::tokens) l in
                 let err = sprintf "</%s>" last in
                 let newstatus = 
                   match status with
                   | Some s -> Some (err^s)
                   | None -> Some err 
                 in
                 newstatus, tokens
         in
         match closethem [] l with
         | None, tokens -> Legal, List.rev tokens
         | Some s, tokens -> Illegal ("Missing "^s), List.rev tokens
       end

    | _ ->  Legal, [token] (* ignore all other cases *)
      
  in
  warnings, status, tokens, loc)
@


<<function Html_eval.dump_stack>>=
let dump_stack () = function
    (x,_)::(y,_)::(z,_)::_ -> sprintf "..<%s><%s><%s>" z y x
  | [x,_;y,_] -> sprintf "<%s><%s>" y x
  | [x,_] -> sprintf "<%s>" x
  | [] -> "empty stack"
@

<<constant Html_eval.initial>>=
(* initial element of the DTD *)
let initial = Elements.add "html" Elements.empty
@

<<function Html_eval.is_cdata>>=
let is_cdata cts =
  Elements.cardinal cts = 1 && Elements.mem "#cdata" cts
@

\subsubsection{Minimizations}

<<function Html_eval.ominimize>>=
(* open minimize 
   [ominimize dtd open_tag current_stack]
   returns a list of inferred open/close tags and the new stack
 *)
let ominimize dtd t stack =
  let elem = t.tag_name in

  (* Is elem allowed for the given stack ? *)
  let goodpos = function
      [] -> Elements.mem elem initial
    | (_, cts)::l -> Elements.mem elem cts

  (* Return with inferred and stack.
     The stack has been reduced during the inference, so it is enough
     to push the opened element *)
  (* Special hack when t is fake #pcdata... *)
  and return inferred stack =
    if elem = "#pcdata" then
      List.rev inferred, stack
    else
      List.rev ((OpenTag t) :: inferred),
      (elem, Hashtbl.find dtd.contents elem) :: stack
      
  in
  (* [attempt_close mods_so_far current_stack] *)
  let rec attempt_close accu = function
     [] -> (* reached all the possible closing, attempt to open again *)
        attempt_open accu []
   | ((last, _)::l) as stack ->
       if Elements.mem last dtd.close_omitted then
          (* we can attempt to close the previous element *)
      if goodpos l then 
        (* good position, we're done *)
        return ((CloseTag last) :: accu) l
          else (* attempt to open in this new position *)
        try 
              attempt_open ((CloseTag last) :: accu) l
            with
          CantMinimize -> (* try once more to close *)
             attempt_close ((CloseTag last)::accu) l
       else begin (* since we can't close, try to open *)
      attempt_open accu stack
       end

   (* [attempt_open mods_so_far currentstack] *)
   and attempt_open accu = function
     [] -> 
       (* open HTML, and retry from there *)
       (* should actually iterate on all elements in initial *)
       let newstack = ["html", Hashtbl.find dtd.contents "html"]
       and newaccu = (OpenTag {tag_name = "html"; attributes = []}) :: accu
       in
      if goodpos newstack then return newaccu newstack
          else attempt_open newaccu newstack

   | ((_, cts)::l ) as stack ->
       (* check if, in contents, there is an element with implicit omission
          that would help *)
       let possible = Elements.inter cts dtd.open_omitted in
        match Elements.cardinal possible with
      0 -> (* argh *) raise CantMinimize
        | 1 -> 
      (* open this element and try from there *)
      let newelem = Elements.choose possible in
      let newaccu = (OpenTag {tag_name = newelem; attributes = []})::accu
          and newstack = (newelem, Hashtbl.find dtd.contents newelem)::stack
          in
        if goodpos newstack 
        then return newaccu newstack
        else attempt_open newaccu newstack (* maybe more ? *)
        | n -> (* since we have the choice, examine all possibilities *)
       let elems = Elements.elements possible in
       let rec backtrack = function 
             [] -> raise CantMinimize
        | x::l -> 
        try
          let newaccu = (OpenTag {tag_name = x; attributes = []})::accu
          and newstack = (x, Hashtbl.find dtd.contents x)::stack
                  in
            if goodpos newstack then return newaccu newstack 
            else attempt_open newaccu newstack
        with
         CantMinimize -> backtrack l
           in 
       backtrack elems
  in
   (* now do some error recovery *)   
   try Legal, attempt_close [] stack
   with
     CantMinimize ->
       (* what the hell, dammit, open it anyway, who cares, duh *)
       let _currentTODO = match stack with (x,_)::l -> x | [] -> "" in
       Illegal (sprintf "illegal <%s> in %a, keep it though"
                t.tag_name dump_stack stack),
       return [] stack
@

<<function Html_eval.cminimize>>=
(* close minimize
   [cminimize dtd elem current_stack]
   returns a list of inferred open/close tags and the new stack
 *)
let cminimize dtd tagname stack =
  (* Is elem allowed for the given stack ? *)
  let goodpos = function
      [] -> false
    | (elem, cts)::l -> tagname = elem

  and return inferred stack =
     List.rev ((CloseTag tagname) :: inferred), stack

  in
  (* [attempt_close mods_so_far current_stack] *)
  let rec attempt_close accu = function
     [] -> raise CantMinimize
   | ((last, _)::l) as _stackTODO ->
       if Elements.mem last dtd.close_omitted then
          (* we can attempt to close the previous element *)
      if goodpos l then 
        (* good position, we're done *)
        return (CloseTag last :: accu) (List.tl l)
          else (* close a bit more ? *)
        attempt_close ((CloseTag last)::accu) l
       else 
     (* there's no reason we should have to open a new element in order
        to close the current one, is it ? *)
          raise CantMinimize
  in
  (* error recovery strategy *)
  let rec attempt_matching accu = function
     [] -> raise Not_found (* didn't find a matching open at all ! *)
   | (curelem,_):: l when curelem = tagname ->
     (* so, consider we match this open, and close them all *)
     return accu l
   | (curelem,_):: l  -> (* otherwise, find something up there *)
     attempt_matching (CloseTag curelem :: accu) l
   in
   (* now do some error recovery *)   
   try Legal, attempt_close [] stack
   with
     CantMinimize ->
       try
     Illegal (sprintf "unmatched </%s> in %a, close closest match"
                  tagname dump_stack stack),
         attempt_matching [] stack 
       with
     Not_found -> 
       Illegal (sprintf "unmatched </%s> in %a, skipped"
                    tagname dump_stack stack),
           ([], stack) (* just skip the damn thing *)
@

<<exception Html_eval.CantMinimize>>=
exception CantMinimize			            (* bogus HTML *)
@

\subsubsection{Filters}

<<signature Html_eval.add_html_filter>>=
(* test suit *)
val add_html_filter : ((Html.token -> unit) -> Html.token -> unit) -> unit
(* [add_html_filter filter] adds an HTML filter between the lexing and
  displaying of HTML. So, the filters do not affect the source (and
  the source display), change the content of HTML silently, and affect
  the display. The filter function [filter pfilter] receives a HTML token
  for each time, and do some job, and send a token to the parent filter 
  pfilter if possible. The filters will receive a correct HTML token
  stream (all the tags are placed and closed correctly due to the DTD),
  and they must send the correct stream to the parent filter also. 
*)
@
<<function Html_eval.add_html_filter>>=
let add_html_filter f =
  filters := f :: !filters
@


<<constant Html_eval.filters>>=
let filters = ref []
@


<<function Html_eval.sgml_lexer (./html/html_eval.ml)>>=
(* Redefine sgml_lexer with filters *)
let sgml_lexer dtd = 
  let org_lexer = sgml_lexer dtd in
  let buf = ref [] in
  let allfilter = 
    List.fold_right (fun f st -> f st) !filters 
      (fun tkn -> buf := !buf @ [tkn]) 
  in
  function lexbuf ->
    let warnings, correct, tokens, loc = org_lexer lexbuf in
    tokens |> List.iter allfilter; (* inefficient *)
    let tokens = !buf in 
    buf := [];
    warnings, correct, tokens, loc
@



\subsection{[[htparse]]}

%(* Testing the HTML Lexer/evaluator *)

<<type Htparse.mode>>=
type mode =
 | Check 
 | Indent of int 
 | Nesting
@
% Check =~ token dump
% Ident =~ use stack so more balancing parsing
% Nesting =~ ?
<<constant Htparse.mode>>=
let mode = ref Check
@
% indent? nesting? what for?

<<function Htparse.main>>=
let main () =
  Html.init (Lang.lang());

  Arg.parse [
     "-struct", Arg.Int   (function n -> mode := Indent n), "Parse Tree";
     "-nesting", Arg.Unit (function () -> mode := Nesting), "Check nesting";

     "-debug", Arg.Unit (function () -> Html_eval.debug := true), "Debug mode";
     "-strict", Arg.Set Lexhtml.strict, "Strict mode";
     "-v", Arg.Unit (function () -> verbose := true), "Verbose mode";

     "-dtd", Arg.Unit (function () -> Dtd.dump Dtd.dtd32f), "Dump DTD";
     "-depth", Arg.Int (function n -> Format.set_max_boxes n), "Max print depth"
     ]
     (fun s -> 
       match !mode with
       | Check -> html_lex s
       | Indent n -> html_indent s n
       | Nesting -> html_nest s
       )
     "Usage: htparse <opts> file1.html ... filen.html"
@

<<toplevel Htparse._2>>=
let _ = Printexc.catch main ()
@


<<function Htparse.html_lex>>=
let html_lex name =
  let ic = open_in name in
  let lexbuf, find_line = line_reporting ic in
  Html_eval.automat Dtd.dtd32f lexbuf
     (fun loc token ->
        match token with
        | EOF -> close_in ic
        | t -> 
          <<[[Htparse.html_lex()]] print token t if verbose>>
     )
     (error name find_line)
@
% token dumper

<<toplevel Htparse._1>>=
let _ = 
  Html.verbose := false (* we do our own error report *)
@
<<constant Htparse.verbose>>=
let verbose = ref false
@



<<function Htparse.error>>=
let error name find_line (Loc(n,n')) msg =
  let linenum, linestart = find_line n in
  printf "File \"%s\", line %d, characters %d-%d:\n%s\n"
         name linenum (n - linestart) (n' - linestart) msg
@

<<function Htparse.line_reporting>>=
(* lines: start at 1 *)
(* pos: start at 0 as in caml *)
let line_reporting ic =
  let lines = ref [] in
  let current_line = ref 1 in
  let current_pos = ref 0 in
  let read = input ic in
  Lexing.from_function (fun buf len ->
     let n = read buf 0 len in
       for i = 0 to n - 1 do
     match buf.[i] with
       '\n' -> incr current_pos; incr current_line;
               lines := (!current_pos, !current_line) :: !lines
         | _ -> incr current_pos
         done; 
         n),
  (fun pos ->
    let rec find_line = function
      [] -> 1, 0
    | (linestart, linenum)::l when pos < linestart -> find_line l
    | (linestart, linenum)::l -> linenum, linestart
    in
     find_line !lines)
@
%  let read = 
%    if !Lang.japan 
%    then 
%      (Japan.create_read_japanese (input ic) (Japan.default_config ()))#read
%    else input ic 




<<function Htparse.html_nest>>=
let html_nest name =
  let ic = open_in name in
  let lexbuf = Lexing.from_channel ic in
  let stack = ref [] in
  Html_eval.automat Dtd.dtd32f lexbuf
    (fun (Loc(n,n')) tok ->
       match tok with
       | EOF -> close_in ic
       | OpenTag t ->
           stack := t.tag_name :: !stack
       | CloseTag t ->
           (match !stack with
            | hd::tl when hd = t -> stack := tl
            | hd::tl -> eprintf "Unmatched closing tag %s (expected %s) at 
                            pos %d - %d" t hd n n'
            | [] -> eprintf "Unmatched closing tag %s (Empty stack) at
                            pos %d - %d" t n n'
            )
       | _ -> ()
     )
     (fun _ _ -> ())
@

<<function Htparse.html_indent>>=
let html_indent name level =
  let box = 
    match level with
    | 0 -> Format.open_box
    | 1 -> Format.open_hvbox
    | n -> Format.open_vbox 
  in
  let ic = open_in name in
  let lexbuf  = Lexing.from_channel ic in
  box 0;
  Html_eval.automat Dtd.dtd32f lexbuf
    (fun loc token ->
      match token with
      | EOF -> 
          Format.print_newline();
          close_in ic
       | OpenTag t ->
          Format.print_cut();
          box 0;
          box 2;
          Format.print_string (sprintf "<%s>" t.tag_name)
       | CloseTag t ->
          Format.close_box();
          Format.print_cut();
          Format.print_string (sprintf "</%s>" t);
          Format.close_box()
      | PCData _ -> 
          Format.print_string "*"
      | _ -> ()
      )
      (fun _ msg -> Format.print_string (sprintf "ERROR(%s)" msg))
@



\section{HTTP}

\subsection{Request}

% ??? -> <>
<<signature Http_headers.parse_request>>=
val parse_request : string -> Messages.request
  (* Parses a Request-Line
     Request-Line = Method SP Request-URI SP HTTP-Version CRLF
     Raises [Invalid_HTTP_header "Request-Line"] *)
@
%less: why need to parse a request in a client?
% we need to parse response, not request 

<<function Http_headers.parse_request>>=
(* CHECK: Normally the URI should be encoded (no spaces ?) *)
let parse_request s =
 try
  match Str.bounded_split (regexp "[ ]") s 3 with
    [m;r;v] ->
         { request_version = v;
           request_method = m;
           request_uri = r }
  | ["GET"; uri] ->
         { request_version = "HTTP/0.9";
           request_method = "GET";
           request_uri = uri }
  | [m;s] -> (* uri omitted ? *)
         { request_version = s;
           request_method = m;
           request_uri = "/" }
  | _ -> raise (Invalid_HTTP_header "Request-Line")
 with
   Failure "int_of_string" -> raise (Invalid_HTTP_header "Request-Line")
@
%less: could call parse_method here no? and have typed request_method
%less: aspectize http 0.9?

\subsection{Status}

% Http.process_response -> <>
<<signature Http_headers.parse_status>>=
val parse_status : string -> Messages.status
  (* Parses a Status-Line
     Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase CRLF
     Raises [Invalid_HTTP_header "Status-Line"] 
     or [Not_found] if the string is not a Status-Line at all *)
@
<<function Http_headers.parse_status>>=
(* Status-Line = HTTP-Version SP Status-Code SP Reason-Phrase CRLF *)
let parse_status s =
 if String.length s > 5 & String.sub s 0 5 = "HTTP/" 
 then
   try
    match Str.bounded_split (regexp "[ ]") s 3 with
      [v;c;m] ->
           { status_version = v;
             status_code = int_of_string c;
             status_message = m }
    (* it happened once with Server: Netscape-Commerce/1.1 *)
    (* where the Status Line was: HTTP/1.0 302 *)
    | [v;c] ->
           { status_version = v;
             status_code = int_of_string c;
             status_message = "empty" }
    | _ -> raise (Invalid_HTTP_header "Status-Line")
   with Failure "int_of_string" -> raise (Invalid_HTTP_header "Status-Line")
 else (* 0.9, dammit *)
   raise Not_found
@

%less: aspectize old stuff once we know it works on most of our websites







<<signature Http_headers.http_status>>=
(* Common headers *)
val http_status : int -> status
  (* [http_status n] returns Status-Line for code [n] *)
@
<<function Http_headers.http_status>>=
(* A typical status line *)
let http_status code =
  {
   status_version = "HTTP/1.0";
   status_code = code;
   status_message = status_message code
  }
@

<<function Http_headers.status_message>>=
let status_message code =  
  try Hashtbl.find status_messages code
  with Not_found -> " "
@

<<constant Http_headers.status_messages>>=
(* Messages in Status-Line *)
let status_messages = Hashtbl.create 101
@


<<toplevel Http_headers._2>>=
let _ = 
  [ 200, "OK";

    201, "Created";
    202, "Accepted";
    204, "No Content";

    301, "Moved Permanently";
    302, "Moved Temporarily";
    304, "Not Modified";

    400, "Bad Request";
    401, "Unauthorized";
    403, "Forbidden";
    404, "Not Found";

    500, "Internal Server Error";
    501, "Not Implemented";
    502, "Bad Gateway";
    503, "Service Unavailable";

    (* These are proposed for HTTP1.1 *)
    407, "Proxy Authentication Required"
  ] |> List.iter (function (code, msg) -> Hashtbl.add status_messages code msg)
@
%404!! :)





\subsection{Headers}

% generic function
<<signature Http_headers.get_header>>=
val get_header : string -> header list -> string
  (* [get_header field_name hs] returns the field_value, if any, of
     the headers, or raises [Not_found].
     [field_name] is the token is lowercase (e.g. "content-type") *)
@
<<function Http_headers.get_header>>=
(* [get_header field-name headers]
 *   returns, if it exists the field value of the header field-name
 * This is a bit costly though, but we keep headers as plain strings.
 * CHECK: speed up with some regexp matching.
 * HYP: field-name in lower-case
 *)
let get_header field_name = 
  let size = String.length field_name in
  let rec search = function
   | [] -> raise Not_found
   | s::l ->
      if String.length s >= size + 2 (* : SP *) && 
         String.lowercase (String.sub s 0 size) = field_name
      then String.sub s (size + 2) (String.length s - size - 2)
      else search l 
  in
  search
@


<<signature Http_headers.get_multi_header>>=
val get_multi_header : string -> header list -> string list
  (* [get_multi_header field_name hs] returns the list of field_value
     of the headers.
     [field_name] is the token is lowercase (e.g. "content-type") *)
@

<<function Http_headers.get_multi_header>>=
(* [get_multi_header field_name headers]
 *   get all values of the header
 *)
let get_multi_header field_name =
  let size = String.length field_name in (* :SP *)
  let rec search = function
     [] -> []
   | s::l ->
    if   String.length s >= size + 2 (* : SP *)
       & String.lowercase (String.sub s 0 size) = field_name
    then (String.sub s (size + 2) (String.length s - size - 2)) :: search l
    else search l in
  search
@




%\subsubsection{Content type}

<<signature Http_headers.contenttype>>=
(* Predefined access functions *)
val contenttype : header list -> string
  (* Content-Type *)
@
<<functions Http_headers.xxx get_header applications>>=
let contenttype = 
  get_header "content-type"
@

%\subsubsection{Content length}

<<signature Http_headers.contentlength>>=
val contentlength : header list -> int
  (* Content-Length *)
@
<<functions Http_headers.xxx get_header applications>>=
let contentlength l = 
  let h = get_header "content-length" l in
  try int_of_string h 
  with _ -> raise Not_found
@

%\subsubsection{Content encoding}

<<signature Http_headers.contentencoding>>=
val contentencoding : header list -> string
  (* Content-Encoding *)
@
<<functions Http_headers.xxx get_header applications>>=
let contentencoding = 
  get_header "content-encoding"
@


\subsection{Media}
% ???

<<type Http_headers.media_type>>=
type media_type = string * string
@

<<type Http_headers.media_parameter>>=
(* Media types *)
type media_parameter = string * string
@

<<signature Lexheaders.media_type>>=
val media_type : 
  string -> Http_headers.media_type * Http_headers.media_parameter list
@



\chapter{Retrieving}
%Retrieving Documents
% retrieve/
% put before http

% Nav.request.retrieve_and_handle -> <>
<<signature Retrieve.f>>=
(* f is supposed to raise only Invalid_url *)
val f : Www.request ->  (* the request *)
        (Hyper.link -> unit) -> (* the retry function *)
        Document.document_continuation -> (* the handlers *)
        retrievalStatus
@

<<type Retrieve.retrievalStatus>>=
type retrievalStatus =
 | Started of (unit -> unit)  
 | InUse
@
% abort hook
% less: typedef?

\section{[[Retrieve.f()]]}

<<function Retrieve.f>>=
(*
 * Emitting a request:
 *   we must catch here all errors due to protocols and remove the
 *   cnx from the set of active cnx.
 *)
and f request retry cont = 
  Log.debug "Retrieve.f";
  if Www.is_active_cnx request.www_url
  then InUse
  else begin
    Www.add_active_cnx request.www_url;
    try 
      let (req, cache) = Protos.get request.www_url.protocol in
      Started (req request
               { cont with
                 document_process = http_check cache retry cont request})

   with 
   | Not_found ->
       Www.rem_active_cnx request.www_url;
       raise (Invalid_request (request, I18n.sprintf "unknown protocol"))
   | Http.HTTP_error s ->
       Www.rem_active_cnx request.www_url;
       raise (Invalid_request (request, I18n.sprintf "HTTP Error \"%s\"" s))
   | File.File_error s ->
       Www.rem_active_cnx request.www_url;
       raise (Invalid_request (request, s))
   end
@

\section{Active connections}

<<module Www.UrlSet>>=
(* Table of unresolved active connexions *)
(* We need to keep a trace of pending connections, since there is a race
   condition when the user clicks twice rapidly on an anchor. If the second
   click occurs before the document is added to the cache, (e.g. because we
   are waiting for the headers), then the document will be retrieved twice.
   And naturally, for documents that don't enter the cache we always will
   duplicate connexions.
   Retrieve.f is a safe place to add the request to the list of pending
   connexions, because it is synchronous.
   Removing an active connexion must take place when we close the 
   dh.document_fd.
*)
module UrlSet =
  Set.Make(struct type t = Url.t let compare = compare end)
@

<<constant Www.active_connexions>>=
let active_connexions = ref UrlSet.empty
@

<<signature Www.is_active_cnx>>=
val is_active_cnx : Url.t -> bool
@
<<signature Www.add_active_cnx>>=
val add_active_cnx : Url.t -> unit
@
<<signature Www.rem_active_cnx>>=
val rem_active_cnx : Url.t -> unit
@

% Retrieve.f -> <>
<<functions Www.xxx_active_cnx>>=
let is_active_cnx url = 
  UrlSet.mem url !active_connexions
let add_active_cnx url = 
  active_connexions := UrlSet.add url !active_connexions
@

% Retrieve.f (when error) | (??-> Document.dclose) | Http.failed_request -> <>
<<functions Www.xxx_active_cnx>>=
let rem_active_cnx url =
  active_connexions := UrlSet.remove url !active_connexions
@

\section{Connections}

<<type Feed.internal>>=
(* An abstract notion of connection *)

type internal = Unix.file_descr
@

<<type Feed.t>>=
type t = {
  feed_read : string -> int -> int -> int;
  feed_schedule : (unit -> unit) -> unit;
  feed_unschedule : unit -> unit;
  feed_close : unit -> unit;
  feed_internal : internal  
  }
@

<<signature Feed.of_fd>>=
val of_fd : Unix.file_descr -> t
@

<<signature Feed.internal>>=
val internal : t -> internal
@


<<function Feed.of_fd>>=
(* We should distinguish internal/external connections *)
let of_fd fd =
  let is_open = ref true in
  let action = ref None in
  let condition = Condition.create() in
  let first_read = ref false in

  (* ASSUMES: this is the first read on the fileevent *)
  let safe_read buf offs len =
    first_read := false;
    if !is_open then Low.read fd buf offs len else 0
  in

  (* In other cases : this is non blocking but not fully threaded. *)
  let special_read buf ofs len =
     (* remove the normal handler *)
     Fileevent_.remove_fileinput fd; 
     (* add a handler to trigger the condition *)
     Fileevent_.add_fileinput fd (fun () ->
     Fileevent_.remove_fileinput fd; (* remove myself *)
     Condition.set condition);
     (* wait for the condition to happen *)
     Condition.wait condition;
     (* Meanwhile, someone may have unscheduled/closed the 
    feed (e.g. abort). We call safe_read, but if the feed has been
    closed, read will fail.
    To know if we have to put back on schedule, check the *current*
    state of action
      *)
     let n = try safe_read buf ofs len with _ -> 0 in
     (* reschedule; it is essential that Low.add_fileinput does not
        call the event loop, otherwise we loose sequentiality of reads *)
     (match !action with
        Some f ->
      Fileevent_.add_fileinput fd (fun () -> first_read := true; f())
      | None -> ());
     (* and return *)
     n
  in {

   feed_read = (fun buf ofs len -> 
       if !first_read then safe_read buf ofs len
       else special_read buf ofs len
   );

   feed_schedule = (function f ->
       if not !is_open then
     Log.f "ERROR: feed is closed, can't schedule"
       else match !action with
     Some f -> (* we are already scheduled ! *)
       Log.f "Warning: feed already scheduled"
       | None -> begin
        action := Some f;
        Low.add_fileinput fd (fun () -> first_read := true; f())
      end
   );

   feed_unschedule = (function () -> 
       match !action with
     Some f -> Low.remove_fileinput fd; action := None
       | None -> (* this happens quite often (for all action codes which
            do not process the body of the document, the feed got
            unscheduled as the end of headers) *)
       ()
   );

   (* feed_close must be called only if the feed it *not* scheduled *)

   feed_close = (function () -> 
       (* if we abort during a state when we are waiting on the condition,
          the feed is unscheduled but we never get out. So always change
      the state *)
       Condition.set condition;
       if !is_open then begin
     match !action with 
        Some f -> Log.f "ERROR: feed is scheduled, can't close"
      | None -> Unix.close fd;
                is_open := false;
            (* Condition.free condition RACE CONDITION HERE *)
       end 
    );

    feed_internal = fd
   }
@

<<function Feed.internal>>=
let internal {feed_internal = fd} = fd
@


\section{XXX}

<<type Retrieve.behaviour>>=
(* We should implement the proper behaviours for all return codes
 * defined in the HTTP/1.0 protocol draft. 
 * Return codes are HTTP specific, but since all protocols are more or
 * less mapped to http, we deal with them at the retrieval level.
 *)
type behaviour =
   Ok 			              (* process the document *)
 | Stop of string             (* stop (no document) and display message *)
 | Retry of Hyper.link        (* restart with a new link *)
 | Error of string            (* same as stop, but it's an error *)
 | Restart of (handle -> handle) (* restart the same request, but apply
                     transformation on the continuation *)
@

<<signature Retrieve.add_http_processor>>=
val add_http_processor : 
  int -> (Www.request -> Document.handle -> behaviour) -> unit
@


<<constant Retrieve.http_process>>=
(*
 * Provision for user (re)definition of behaviours.
 *)
let http_process = Hashtbl.create 37
@

<<constant Retrieve.add_http_processor>>=
let add_http_processor = Hashtbl.add http_process
@

<<toplevel Retrieve._1>>=
(* 400 : proxies do return this code when they can satisfy the request,
 *       so we keep it as default (displayed)
 *)
let _ =
 List.iter (function (code, behave) -> Hashtbl.add http_process code behave)
  [200, code200;
   201, code200;
   202, code200;
   204, code204;

   301, forward_permanent;
   302, forward;
   (* 304, update; *)
   401, unauthorized;
   407, proxy_unauthorized]
@

% no 404? :)


<<function Retrieve.code200>>=
(* 200 OK *)
let code200 wwwr dh = Ok
(* 201 Created (same as 200) *)
(* 202 Accepted (same as 200) *)
@


<<function Retrieve.code400>>=
(* 400 Bad request *)
let code400 wwwr dh = Error (I18n.sprintf "Bad Request")
@

\section{Logging}




<<signature Document.dclose>>=
val dclose : bool -> handle -> unit
  (* [dclose remactive dh] closes a living dh *)
@

<<signature Document.add_log>>=
val add_log: handle -> string -> (unit -> unit) -> unit
@

<<signature Document.put_log>>=
val put_log : handle -> string -> unit
@

<<signature Document.progress_log>>=
val progress_log : handle -> int -> unit
@

<<signature Document.end_log>>=
val end_log : handle -> string -> unit
@

<<signature Document.destroy_log>>=
val destroy_log : handle -> bool -> unit
  (* logging functions *)
@



<<function Document.dclose>>=
(* Close a connexion. Should be called only by a fileinput callback
      or by somebody attempting to abort the connexion 
   We remove the fd of the select before closing it since we don't want
   a spurious read to happen. This way we are somewhat independant of the
   Tk implementation 
 *)

let dclose remactive dh =
  dh.document_feed.feed_unschedule();
  dh.document_feed.feed_close();
  if remactive then Www.rem_active_cnx dh.document_id.document_url
@


<<function Document.add_log>>=
let add_log dh initmsg abort =
  !add_log_backend dh initmsg abort
@

<<function Document.end_log>>=
let end_log dh msg =
    dh.document_logger.logger_end msg;
    destroy_log dh true
@

<<functions Document.xxx_log>>=
let put_log dh = dh.document_logger.logger_msg
let destroy_log dh = dh.document_logger.logger_destroy
let progress_log dh = dh.document_logger.logger_progress
@

<<type Document.display_info>>=
type display_info = {
    di_abort : unit -> unit;
    di_destroy : unit -> unit;
    di_fragment : string option -> unit;
    di_redisplay: unit -> unit;
    di_title : unit -> string;	      (* some title for bookmarks *)
    di_source : unit -> unit;
    di_load_images : unit -> unit
}
@

\section{Images}

<<signature Img.get>>=
val get : document_id -> Hyper.link -> (Url.t -> ImageData.t -> unit) -> 
            Scheduler.progress_func -> unit
@

<<signature Img.update>>=
val update : Url.t -> unit
@


<<function Img.get>>=
let get did link cont prog =
  let wr = Www.make link in
  wr.www_headers <- "Accept: image/*" :: wr.www_headers;
  ImageScheduler.add_request wr did cont prog
@


<<function Img.update>>=
let update url =
  try
    let (oldi,refs,headers) = ImageData.direct_cache_access url in
    let link = { h_uri = Url.string_of url;
         h_context = None;
         h_method = GET;
             h_params = []} in
    let wr = Www.make link in
    let date_received = get_header "date" headers in
    wr.www_headers <- 
       ("If-Modified-Since: "^date_received)
       :: "Pragma: no-cache"
       :: wr.www_headers;

    ImageScheduler.add_request wr (DocumentIDSet.choose !refs)
      (fun url i -> 
    match oldi, i with
      Still (ImagePhoto oldn) , Still (ImagePhoto newn) ->
        Imagephoto.copy oldn newn []
  | _, _ -> ())
      Progress.no_meter

  with
    Not_found ->  (* either not in cache (bogus) or no date *)
      ()
@


\section{Scheduling}



\section{Progressing}
% important in a slow word to have some feedback


<<type Scheduler.progress_func>>=
type progress_func = int option -> int -> unit
@



<<signature Progress.no_meter>>=
val no_meter : Scheduler.progress_func
@
<<constant Progress.no_meter>>=
let no_meter = (fun _ _ -> () : Scheduler.progress_func)
@

<<signature Progress.meter>>=
@

<<function Progress.meter>>=
@


\chapter{HTTP}
%Communication Protocol
% http/

% will see http://, main protocol, see also file://, mailto://
% in extra protocol chapter, later

%rappel:
%<<signature Protos.get>>=
%val get: Url.protocol ->
%  (Www.request -> Document.document_continuation -> (unit -> unit)) *
%  (Document.handle -> Document.document_data * Cache.cache_fill)
%@

%less: why use continuation instead of returning things?
% this makes the code harder to follow.
% for instance tcp_connect takes a continuation, but return a connection
% that later will call the continuation. argh.
% use lwt instead? or async? or monads? or use threads??
% might be far simpler with threads no? or is it because
% it would not play well with tk?

% Build each time a serie of intermediate computations.
% for instance I guess mmm want to be called once the document
% arrived, e.g. doc_arrived()
% then we initiate a connection and want
% first start_request to be called and then doc_arrived, so
% we pass another continuation like (fun ... -> start_request   cont)
% where cont will be doc_arrived called by start_request once it's
% done. 



\section{The request}

\subsection{[[Http.req()]]}

<<toplevel Protos._2>>=
let _ = Hashtbl.add protos HTTP (Http.req, Cache.tobuffer)
@

% Nav.request -> Retrieve.f (wr where wr protocol = HTTP) -> <> 
%  (as Retrieve.f.req <- Protos.get HTTP wr <- Hashtbl.add protos (<>) <- _top
<<signature Http.req>>=
val req:
  Www.request -> Document.document_continuation -> (unit -> unit)
@
%todo: do a Aborted and type aborter = abort -> unit?
% so here we return an aborter

% ??? (via Protos.get HTTP) -> <>
%(* Wrappers returning the abort callback *)
% wr = web request, cont = continuation
<<function Http.req>>=
let req wr cont =
  let cnx = request wr cont in
  (fun () -> cnx#abort)
@
% run the request asynchronously,
% and return the function to abort to the caller want to call it!

%urlp = url parsed?
<<function Http.request>>=
(* Issueing request, with the "retry" logic (unless is "always proxy" mode, 
   we attempt first to connect directly to the host, and if it fails,
   we retry through the proxy
 *)
and request wr cont =
  <<[[Http.request()]] if always proxy>>
  else 
    let urlp = wr.www_url in
    if urlp.protocol = HTTP 
    then
      let host = 
        match urlp.host with
        | Some h -> h 
        | _ -> raise (HTTP_error (I18n.sprintf "Missing host in url"))
      in
      let port =  
        match urlp.port with
        | Some p -> p
        | None -> 80  (* default http port *)
      in 
      try 
        tcp_connect host port wr.www_logging
            (fun cnx -> start_request false wr cont  cnx)
            (fun s aborted -> failed_request wr cont.document_finish s aborted)

      with HTTP_error _ -> (* direct failed, go through proxy *)
        <<[[Http.request()]] if http error on tcp_connect, try proxy>>
    else 
      raise (HTTP_error (I18n.sprintf 
             "INTERNAL ERROR\nHttp.request (not a distant http url): %s" 
               (Url.string_of wr.www_url)))
@
%old: used to use partial app of start_request and failed_request
% but clearer to eta expand I think


\subsection{[[Http.tcp_connect()]]}

% Http.req -> <>
<<function Http.tcp_connect>>=
(* Open a TCP connection, asynchronously (except for DNS).
   We pass the continuation *)
let tcp_connect server_name port  log  cont error =

  (*  Find the inet address *)
  let server_addr =
    try Unix.inet_addr_of_string server_name
    with Failure _ ->
      <<[[Http.tcp_connect()]] if inet_add_of_string fails>>
  in

  (* Attempt to connect *)
  let sock = Unix.socket PF_INET SOCK_STREAM 0 in
  Unix.clear_nonblock sock;
  Unix.set_nonblock sock; (* set to non-blocking *)
  let cnx = new cnx (sock, error "User abort") in
  log (I18n.sprintf "Contacting host...");
  try
    begin try
      Unix.connect sock (ADDR_INET(server_addr, port));
      (* just in case. Normally an error should be raised *)
      Unix.clear_nonblock sock; (* set to non-blocking *)
      log (I18n.sprintf "connection established");
      Log.debug "Connect returned without error !";

      (* because we need to return cnx *)
      Timer_.set 10 (fun () -> 
        (* ! calling the continuation, e.g. start_request *)
        cont cnx
      );
      cnx
    with Unix_error((EINPROGRESS | EWOULDBLOCK | EAGAIN), "connect", _) -> 
      <<[[Http.tcp_connect()]] if unix error when connect>>
    end
  with Unix_error(e,fn,_) ->  (* other errors in connect *)
    cnx#close;
    raise (HTTP_error (I18n.sprintf "Cannot establish connection\n%s:%s"
                             (error_message e) fn))
@

\subsubsection{[[cnx]]}

<<type Http.status>>=
(* Support for aborting requests while in connect/write/headers mode.
   When we start applying the document continuation, it is not our job
   anymore to abort the connection.
 *)
type status = 
  | Writing 
  <<[[Http.status]] cases>>
@


<<class Http.cnx>>=
class cnx (sock, finish) =
 object (self)
  val mutable status = Writing
  val mutable fd = sock

  (* val finish = finish *)
  val mutable fdclosed = false		(* protect against double close *)
  val mutable aborted = false

  method fd = 
    fd
  method aborted = 
    aborted
  method set_fd newfd = 
    fd <- newfd
  method set_status s = 
    status <- s

  method close =
    if not fdclosed then begin
      close fd;
      fdclosed <- true
    end

  (* can be called from the aborter by the user or some exn handler *)  
  method abort =
     if not aborted then begin
       aborted <- true;
       match status with
       | Writing -> 
           Fileevent_.remove_fileoutput fd; 
           self#close; 
           finish true
       <<[[Http.cnx.abort()]] cases>>
    end
end
@
% ugly, could simplify?


\subsubsection{Error managment}

<<[[Http.tcp_connect()]] if inet_add_of_string fails>>=
try
  log (I18n.sprintf "Looking for %s ..." server_name);
  let adr = (Low.busy Munix.gethostbyname server_name).h_addr_list.(0) in
  log (I18n.sprintf "%s found" server_name);
  adr
with Not_found -> 
 raise (HTTP_error (I18n.sprintf "Unknown host: %s" server_name)) 
@

<<[[Http.tcp_connect()]] if unix error when connect>>=
 (* that is ok, we are starting something *)
 let stuck = ref true in
 Fileevent_.add_fileoutput sock
   (* we are called when the cnx is established *)
   (fun () -> 
     stuck := false;
     Fileevent_.remove_fileoutput sock;
     Unix.clear_nonblock sock; (* return to blocking mode *)
     begin try (* But has there been a cnx actually *)
       let _ = getpeername sock in
       log (I18n.sprintf "connection established");
       cont cnx
     with Unix_error(ENOTCONN, "getpeername", _) ->
       cnx#close;
       error (I18n.sprintf "Connection refused to %s" server_name) false
      end
   );
  <<[[Http.tcp_connect()]] setup timeout>>
  cnx
@



\subsubsection{Timout managment}

<<constant Http.timeout>>=
let timeout = ref 60		(* in seconds *)
@

<<[[Http.tcp_connect()]] setup timeout>>=
(* but also start the timer if nothing happens now
* the kernel has a timeout, but it might be too long (linux) 
*)
Timer_.set (1000 * !timeout)
  (fun () -> 
     if not cnx#aborted && !stuck 
     then begin
       Fileevent_.remove_fileoutput sock;
       cnx#close;
       error (I18n.sprintf "Timeout during connect to %s" server_name)
             false
      end
  );
@

\subsection{[[Http.start_request()]]}

% tcp_connect -> <>
<<function Http.start_request>>=
and start_request proxy_mode wwwr cont =
 fun cnx ->
  async_request proxy_mode wwwr 
     (fun cnx -> process_response wwwr cont cnx) cnx
@
% the continuation once we get the date is indeed to process
% the response!

<<function Http.async_request>>=
(* Writing the request to the server
 *   TODO:  We might get some error here in write
 *   NOTE: tk doesn't allow two handles on the same fd, thus use CPS
 *         so that reading response is our continuation
 *)
and async_request proxy_mode wwwr cont cnx =
  let b = Ebuffer.create 1024 in
  full_request (fun x -> Ebuffer.output_string b x) proxy_mode wwwr;
  let req = Ebuffer.get b in
  let len = Ebuffer.used b in
  let curpos = ref 0 in
  wwwr.www_logging (I18n.sprintf "Writing request...");
  Fileevent_.add_fileoutput cnx#fd (fun _ ->
    let n = Unix.write cnx#fd req !curpos (len - !curpos) in (* blocking ? *)
    curpos := !curpos  + n;
    if !curpos = len then begin
      Fileevent_.remove_fileoutput cnx#fd;
      <<[[Http.async_request()]] log request string req if verbose>>
      (* ! calling the continuation, e.g. process_response *)
      cont cnx
    end)
@

% the continuation here should be process_response!

\subsection{[[Http.full_request()]]}

% this will build the content of the request in a buffer
% represented by the writer 'w'
% less: pass the buffer instead? need to abstract?
% less: rename build_request_string?

% Http.req -> tcp_connect -> start_request -> async_request -> <>
<<function Http.full_request>>=
let full_request w proxy_mode wwwr = 
  let url = 
    <<[[Http.full_request()]] if proxy mode>>
    else distant_path wwwr.www_url 
  in
  <<[[Http.full_request()]] helper functions>>
  match wwwr.www_link.h_method with
  <<[[Http.full_request()]] method cases>>
@


<<signature Url.distant_path>>=
(* For http. The thing we have to send in the request *)
val distant_path : t -> string
@
<<function Url.distant_path>>=
(* For http only *)
let distant_path urlp =
  match urlp.path, urlp.search with
     None, None -> "/"
   | Some p, None -> "/"^p
   | Some p, Some s -> "/" ^ p ^ "?" ^ s
   | None, Some s -> "/?" ^ s (* ??? *)
@
% so we just send the path and search component!
% the host know who it is already
%less: why distant??

\subsubsection{[[GET]]}

<<[[Http.full_request()]] method cases>>=
| GET ->
    w ("GET " ^ url ^ " HTTP/1.0\r\n");
    (* No General-Header *)
    w (std_request_headers());
    write_referer ();
    <<[[Http.full_request()]] write auth stuff>>
    write_other_headers();
    write_host();
    w "\r\n"
@
% finally! the GET request
% will see referer in section below

<<function Http.std_request_headers>>=
let std_request_headers() =
  Printf.sprintf "User-Agent: %s\r\n" !user_agent
@

<<constant Http.user_agent>>=
let user_agent = 
  ref Version.http
@




<<[[Http.full_request()]] helper functions>>=
let write_other_headers () =
  wwwr.www_headers |> List.iter (fun s -> w s; w "\r\n");
  (* If no Accept given in request, write default one *)
  begin
    try
      get_header "accept" wwwr.www_headers |> ignore
    with Not_found -> w "Accept: */*\r\n"
  end
in
@
% is it where the parameter of the GET are stored?

<<[[Http.full_request()]] helper functions>>=
(* Host: header for virtual domains *)
let write_host () =
  match wwwr.www_url.host with
  | None -> (* never happens *) ()
  | Some h -> 
      (match wwwr.www_url.port with
      | None -> w ("Host: "^h^"\r\n")
      | Some p ->  w ("Host: "^h^":"^string_of_int p^"\r\n")
      )
in
@


\subsubsection{[[POST]]}

<<[[Http.full_request()]] method cases>>=
| POST data ->
    w ("POST "^url^" HTTP/1.0\r\n");
    (* No General-Header *)
    w (std_request_headers());
    write_referer ();
    <<[[Http.full_request()]] write auth stuff>>
    write_other_headers();
    write_host();
    (* 8.2.1 *)
    w ("Content-Type: application/x-www-form-urlencoded\r\n");
    (* 7.2 note *)
    w ("Content-Length: " ^ string_of_int (String.length data)^ "\r\n");
    w "\r\n";
    w data
@


\subsubsection{[[HEAD]]}

<<[[Http.full_request()]] method cases>>=
| HEAD ->
    w ("HEAD "^url^" HTTP/1.0\r\n");
    (* No General-Header *)
    w (std_request_headers());
    write_referer ();
    <<[[Http.full_request()]] write auth stuff>>
    write_other_headers();
    write_host();
    w "\r\n"
@
% ???

\subsubsection{referers}
% ?

<<[[Http.full_request()]] helper functions>>=
let write_referer = 
  match wwwr.www_link.h_context with
  | None -> 
    (fun () -> ())
  | Some r -> 
     (fun () -> 
       if !send_referer 
       then w ("Referer: " ^ r ^ "\r\n"))
in
@

<<constant Http.send_referer>>=
(*
 * HTTP/1.0
 * Headers should be configurable
 *)

let send_referer = ref false
@

\subsection{[[Http.failed_request()]]}

% call with aborted = true when ??
<<function Http.failed_request>>=
(* shared error *)
let failed_request wr finish =
 fun s aborted ->
  finish aborted;
  Www.rem_active_cnx wr.www_url;
  wr.www_logging (I18n.sprintf "Failed");
  wr.www_error#f (I18n.sprintf "Request for %s failed\n%s" 
                   (Url.string_of wr.www_url) s)
@
% aborted is a bool

\section{The response}

\subsection{[[Http.process_response()]]}

% async_request (via its continuation passed in start_request) -> <>
<<function Http.process_response>>=
(* Read headers and run continuation *)
let rec process_response wwwr cont =
 fun cnx ->
  let url = Url.string_of wwwr.www_url in
  wwwr.www_logging (I18n.sprintf "Reading headers...");

  let dh = 
    { document_id = document_id wwwr;
      document_referer = wwwr.www_link.h_context;
      document_fragment = wwwr.www_fragment;

      document_status = 0;
      document_headers = [];
      document_feed = Feed.of_fd cnx#fd;

      document_logger = Document.tty_logger;
    }
  in
  cnx#set_status (Reading dh);

  let stuck = ref true in
  (* set up a timer to abort if server is too far/slow *)
  <<[[Http.process_response()]] setup a timer>>

  (* reading the headers *)
  dh.document_feed.feed_schedule
    (fun () ->
       stuck := false;
       <<[[Http.process_response()]] reading headers>>
@
% seems to call the continuation only for error cases

<<[[Http.status]] cases>>=
| Reading of handle 
@

\subsection{Reading headers}

<<[[Http.process_response()]] reading headers>>=
try
  if dh.document_headers = [] then begin
    (* it should be the HTTP Status-Line *)
    let l = Munix.read_line cnx#fd in
    dh.document_status <- (Http_headers.parse_status l).status_code;
    dh.document_headers <- [l] (* keep it there *)
  end else 
     dh.document_headers <- read_headers cnx#fd dh.document_headers
with
(* each branch must unschedule *)
<<[[Http.process_response()]] feed schedule callback failure cases>>
@

<<exception Http.End_of_headers>>=
(* [read_headers fd]
 *  reads HTTP headers from a fd
 *    raises End_of_file
 *    raises Invalid_HTTP_header
 *)
exception End_of_headers
@

<<signature Http.read_headers>>=
val read_headers: 
  Unix.file_descr -> string list -> string list
@
% process_response | fake_cgi -> <>
<<function Http.read_headers>>=
let read_headers fd previous =
  let l = Munix.read_line fd in
   if String.length l = 0 
   then raise End_of_headers (* end of headers *)
   else 
     if l.[0] = ' ' || l.[0] = '\t' 
     then  (* continuation *)
       match previous with
       | [] -> raise (Invalid_HTTP_header ("invalid continuation " ^ l))
       | s :: rest -> (s^l) :: rest
      else l :: previous
@
% empty line means end of response!
% tabs or space are compacted?


% this is the normal case! 
% we finally call the continuation! to let the caller
% process the document! woohoo!
<<[[Http.process_response()]] feed schedule callback failure cases>>=
| End_of_headers ->
    dh.document_feed.feed_unschedule();
    cnx#set_status Discharged;

    (* ! call the continuation, e.g. MMM stuff? *)
    cont.document_process dh
@
%less: not a big fan of using exn again for non exception cases
% but instead regular flow.

<<[[Http.status]] cases>>=
| Discharged
@
<<[[Http.cnx.abort()]] cases>>=
| Discharged -> ()
@


\subsection{Error managment}


<<[[Http.process_response()]] feed schedule callback failure cases>>=
| Not_found -> (* that's what parse_status raises. HTTP/0.9 dammit *)
    dclose false dh; (* keep it an active cnx since we are retrying *)
    let newcnx = request09 wwwr cont in
    (* the guy up there has the old one !*)
    cnx#set_fd newcnx#fd
@

<<[[Http.process_response()]] feed schedule callback failure cases>>=
| Unix_error(e,_,_) ->
    cnx#abort;
    wwwr.www_error#f (I18n.sprintf 
               "Error while reading headers of %s\n%s" url 
               (error_message e))
@

<<[[Http.process_response()]] feed schedule callback failure cases>>=
| Invalid_HTTP_header s ->
    cnx#abort;
    wwwr.www_error#f (I18n.sprintf 
               "Error while reading headers of %s\n%s" url s)
@
<<[[Http.process_response()]] feed schedule callback failure cases>>=
| End_of_file ->
    cnx#abort;
    wwwr.www_error#f (I18n.sprintf 
               "Error while reading headers of %s\n%s" url "eof"))
@

<<[[Http.cnx.abort()]] cases>>=
| Reading dh -> 
    Document.dclose true dh; 
    finish true
@

\subsection{Timeout managment}


<<[[Http.process_response()]] setup a timer>>=
let rec timout () =
   Timer_.set (1000 * !timeout) 
    (fun () -> 
       if not cnx#aborted && !stuck 
       then
         match wwwr.www_error#ari
           (I18n.sprintf "Timeout while waiting for headers of %s" url) 
         with
         | 0 -> (* abort *) if !stuck then cnx#abort
         | 1 -> (* retry *) timout ()
         | 2 -> (* ignore *) ()
         | _ -> ()
  ) 
in

timout();
@



\section{Headers merging}
%todo: merge in parsing/

% Retype.f | ... -> <>
<<signature Http_headers.merge_headers>>=
val merge_headers : header list -> header list -> header list
  (* [merge_headers oldhs newhs] merges headers, overriding headers in
     [oldhs] by headers in [newhs] *)
@
<<function Http_headers.merge_headers>>=
(* Keep only unmodified headers *)
let merge_headers oldh newh =
  let rec filter acc = function
     [] -> acc
   | s::l ->
      if String.length s > 5 & String.sub s 0 5 = "HTTP/" then
       filter acc l
      else
       try
        let t = header_type s in
        let d = get_header t newh in
      filter acc l
       with
          Invalid_HTTP_header _ -> 
          Log.debug (sprintf "Dumping invalid header (%s)" s);
              filter acc l
        | Not_found -> filter (s::acc) l in
  (filter [] oldh) @ newh
@

% merge_headers -> <>
<<signature Http_headers.header_type>>=
val header_type : string -> string
  (* [header_type h] returns the field_name token of [h], in lowercase *)
@
<<function Http_headers.header_type>>=
let header_type s =
  match Str.bounded_split (regexp "[:]") s 2 with
  | [t;_] -> String.lowercase t
  | _ -> raise (Invalid_HTTP_header s)
@


<<signature Http_headers.remove_headers>>=
val remove_headers : header list -> string list -> header list
  (* [remove_headers hs field_names] returns [hs] without the headers
     with field_name present in [field_names] *)
@
<<function Http_headers.remove_headers>>=
let remove_headers hs names =
  Log.debug "remove headers";
  let rec rem acc = function
     [] -> acc
   | h::l ->
      try
       let t = header_type h in
         if List.mem t names then rem acc l
     else rem (h::acc) l
      with
        Invalid_HTTP_header s ->
      Log.debug (sprintf "Dumping invalid header (%s)" s);
          rem acc l

   in rem [] hs
@
% dead?




\section{Suffixes}

<<type Http_headers.hint>>=
(* Associating MIME type or Content-Encoding with file/URI suffix *)
type hint =
  | ContentType     of header
  | ContentEncoding of header
@


<<constant Http_headers.suffixes>>=
let suffixes =
   (Hashtbl.create 101 : (string, hint) Hashtbl.t)
@

<<toplevel Http_headers._1>>=
(* If the suffix file says otherwise, it will have priority *)
let _ = List.iter (fun (s,t) -> Hashtbl.add suffixes s t)
[ 
  "html",	ContentType  "Content-Type: text/html";
  "htm",	ContentType  "Content-Type: text/html";

  "txt",  	ContentType  "Content-Type: text/plain";

  "ps",  	ContentType  "Content-Type: application/postscript";
  "dvi",  	ContentType  "Content-Type: application/x-dvi";

  "gif",	ContentType  "Content-Type: image/gif";
  "jpeg",	ContentType  "Content-Type: image/jpeg";
  "jpg",	ContentType  "Content-Type: image/jpeg";
  "tiff",	ContentType  "Content-Type: image/tiff";
  "tif",	ContentType  "Content-Type: image/tiff";

  "au",		ContentType  "Content-Type: audio/basic";
  "snd",	ContentType  "Content-Type: audio/basic";
  "wav",	ContentType  "Content-Type: audio/x-wav";
  "mid",	ContentType  "Content-Type: audio/midi";

  "mpeg",	ContentType  "Content-Type: video/mpeg";
  "mpg",	ContentType  "Content-Type: video/mpeg";
  "avi",	ContentType  "Content-Type: video/avi";
  "fli",	ContentType  "Content-Type: video/fli";
  "flc",	ContentType  "Content-Type: video/fli";

  "gz",		ContentEncoding  "Content-Encoding: gzip";
  "Z",		ContentEncoding  "Content-Encoding: compress";

  "asc",	ContentEncoding  "Content-Encoding: pgp";
  "pgp",	ContentEncoding  "Content-Encoding: pgp";

   <<[[Http_headers.suffixes]] elements>>
]
@
% cmo, hehe :)

<<[[Main.main()]] locals>>=
let sufxfile = ref (Mmm.user_file "mime.types") in
@
<<[[Main.main()]] command line options>>=
"-suffixes", Arg.String (fun s -> sufxfile := s),
"<file>\tSuffix file";
@

<<[[Main.main()]] suffix initialisation>>=
(* Suffix mapping to Content-Type and Content-Encoding *)
if Sys.file_exists !sufxfile 
then Http_headers.read_suffix_file !sufxfile;
@

<<signature Http_headers.read_suffix_file>>=
val read_suffix_file : string -> unit
@
<<function Http_headers.read_suffix_file>>=
(* In the file, we select ContentType if there is a slash,
   ContentEncoding otherwise *)
let read_suffix_file f =
 try
  let ic = open_in f in
  try while true do
    let l = input_line ic in
    if l <> "" && l.[0] <> '#' then
      let tokens = 
    split_str (function ' '|'\t' -> true | _ -> false) l in
    match tokens with
      [] -> ()
    | x::l ->
       try 
        let _ = String.index x '/' in
        List.iter 
          (function sufx -> 
               Hashtbl.add suffixes sufx 
                  (ContentType ("Content-Type: "^x)))

        l
       with
         Not_found ->
        List.iter 
          (function sufx ->
               Hashtbl.add suffixes sufx 
                   (ContentEncoding ("Content-Encoding: "^x)))
          l

    done
  with End_of_file -> close_in ic
 with Sys_error _ ->  ()
@





\section{Time}
% could be in Stdlib? with Date?

% why need an extra time library? why not use Unix.tm indeed?
<<type Http_date.http_time>>=
(* Based on Unix.tm *)
type http_time =
  { ht_sec : int;                       (* Seconds 0..59 *)
    ht_min : int;                       (* Minutes 0..59 *)
    ht_hour : int;                      (* Hours 0..23 *)
    ht_mday : int;                      (* Day of month 1..31 *)
    ht_mon : int;                       (* Month of year 0..11 *)
    ht_year : int;                      (* Year - 1900 *)
    ht_wday : int }                     (* Day of week (Sunday is 0) *)
@

<<signature Http_date.expired>>=
val expired : http_time -> bool
  (* Determines if an http_time is in the past *)
@

<<signature Http_date.compare>>=
val compare : http_time -> http_time -> int
  (* Compares two http_times *)
@

<<signature Http_date.string_of_ht>>=
val string_of_ht : http_time -> string
  (* Text version (RFC822) of an http time stamp *)
@

<<signature Http_date.tm_of_ht>>=
val tm_of_ht : http_time -> Unix.tm
@

<<signature Http_date.stamp_of_ht>>=
val stamp_of_ht : http_time -> float
@

<<signature Http_date.ht_of_stamp>>=
val ht_of_stamp : float -> http_time
@



<<function Http_date.expired>>=
let expired ht =
  let now = gmtime(time()) in
  let lht = 
    [ht.ht_year; ht.ht_mon; ht.ht_mday; ht.ht_hour; ht.ht_min; ht.ht_sec]
  and lnow =
    [now.tm_year; now.tm_mon; now.tm_mday; now.tm_hour; now.tm_min; now.tm_sec]
  in
    compare_time (lht, lnow) <= 0
@

<<function Http_date.compare>>=
let compare ht1 ht2 =
 compare_time
  ([ht1.ht_year; ht1.ht_mon; ht1.ht_mday; ht1.ht_hour; ht1.ht_min; ht1.ht_sec],
   [ht2.ht_year; ht2.ht_mon; ht2.ht_mday; ht2.ht_hour; ht2.ht_min; ht2.ht_sec])
@

<<function Http_date.string_of_ht>>=
let string_of_ht ht =
  sprintf "%s, %02d %s %d %02d:%02d:%02d GMT"
      (asc_wkday ht.ht_wday)
      ht.ht_mday
      (asc_month ht.ht_mon)
      (ht.ht_year + 1900)
      ht.ht_hour
      ht.ht_min
      ht.ht_sec
@

<<function Http_date.tm_of_ht>>=
(* 
let has_dst = localtime(time()).tm_isdst
*)
let tm_of_ht ht = {
    tm_sec = ht.ht_sec;
    tm_min = ht.ht_min;
    tm_hour = ht.ht_hour;
    tm_mday = ht.ht_mday;
    tm_mon = ht.ht_mon;
    tm_year = ht.ht_year;
    tm_wday = ht.ht_wday;
    tm_yday = 0;
    tm_isdst = false        (* I don't have a clue here *)
   }
@

<<function Http_date.stamp_of_ht>>=
let stamp_of_ht ht =
   fst (mktime (tm_of_ht ht))
@

<<function Http_date.ht_of_stamp>>=
let ht_of_stamp ut =
  let tm = gmtime ut in {
    ht_sec = tm.tm_sec;
    ht_min = tm.tm_min;
    ht_hour = tm.tm_hour;
    ht_mday = tm.tm_mday;
    ht_mon = tm.tm_mon;
    ht_year = tm.tm_year;
    ht_wday = tm.tm_wday
     }
@

\chapter{Viewers}
% viewers/

%reput process_viewer():
% fun nav wr dh ->
%  let ctx = make_ctx nav dh.document_id in
%  match Viewers.view nav.nav_viewer_frame ctx dh with
%  | None -> () (* external viewer *)
%  | Some di ->
%      <<[[Nav.process_viewer()]] add in cache and history the document>>
%      nav.nav_show_current di dh.document_fragment

<<signature Nav.make_ctx>>=
val make_ctx : t -> Document.document_id -> Viewers.context
@
<<signature Viewers.view>>=
val view : Widget.widget -> context -> Document.handle -> display_info option
@




%where nav_show_current is:
%    di#di_touch;
%    pack di, set title of toplevel window to name of document
%    di#di_fragment frag;




\section{[[Viewers.view()]]}

% Nav.request -> ... document_finish continuation -> Nav.process_viewer  -> <>
<<function Viewers.view>>=
(* the meat *)
and view frame ctx dh =
  try 
    let ctype = contenttype dh.document_headers in
    let (typ, sub), pars = Lexheaders.media_type ctype in
    try (* Get the viewer *)
      let viewer =
        try Hashtbl.find viewers (typ,sub)
        with Not_found -> Hashtbl.find viewers (typ,"*")
      in
      match viewer with
      |	Internal viewer ->
          ctx#log (I18n.sprintf "Displaying...");
          viewer pars frame ctx (Decoders.insert dh)
      |	External ->
          ctx#log (I18n.sprintf "Displaying externally");
          extern (Decoders.insert dh) (sprintf "%s/%s" typ sub);
          None
      |	Interactive ->
          interactive frame ctx dh ctype
      |	Save ->
          Save.interactive (fun _ -> ()) dh;
          None
    with
    | Failure "too late" -> (* custom for our internal viewers *)
        dclose true dh;
        Document.destroy_log dh false;
        None
    | Not_found -> 
       (* we don't know how to handle this *)
       ctx#log (I18n.sprintf "Displaying externally");
       interactive frame ctx dh ctype
  with 
  | Invalid_HTTP_header e ->
      ctx#log (I18n.sprintf "Malformed type: %s" e);
      unknown frame ctx dh
  | Not_found -> 
      (* Content-type was not defined in the headers *)
      (* and could not be computed from url *)
      unknown frame ctx dh
@

\section{[[Nav.stdctx]]}

<<function Nav.make_ctx>>=
let make_ctx nav did = 
  let o = new stdctx(did, nav) in
  ignore (o#init);
  (o :> Viewers.context)
@

<<class Nav.stdctx>>=
(* WARNING: we take copies of these objects, so "self" must *not* be
 * captured in a closure (it would always point to the old object).
 * A new object is created for each new top viewer (follow_link).
 * AND for each frame_goto operation.
 *)
class stdctx (did, nav) =
 object (self)
  inherit Viewers.context (did, []) as super
  (* val nav = nav *)  
  (* val did = did *)

  method log = nav.nav_log
  method init =

    (* a new context for a toplevel window *)
    let make_ctx nav did = 
      ((new stdctx(did, nav))#init :> Viewers.context) in

    (* a new context for an embedded window *)
    let make_embed_ctx w targets = 
      let targets = 
    ("_self", w) :: ("_parent", Winfo.parent w) :: (frame_fugue targets) in
      let newctx = (new stdctx(did,nav))#init in
      begin
    try 
      let f = List.assoc "pointsto" self#hyper_funs in
      let g = List.assoc "clearpointsto" self#hyper_funs in
      newctx#add_nav ("pointsto", f);
      newctx#add_nav ("clearpointsto", g);
    with
      Not_found -> ()
      end;
      (newctx#for_embed [] targets :> Viewers.context) in
    (* by default, use the cache, don't touch the request *)
    let default_request = request nav true id_wr in
    let follow_link _ = 
      default_request (process_viewer true make_ctx) (specific_viewer true)
    and save_link _ =
      default_request (process_save None) nothing_specific
    and copy_link _ = copy_link nav
    and head_link = 
      let f = default_request process_head nothing_specific in
      (fun _ hlink -> f (make_head hlink))
    and new_link _ = nav.nav_new
    in 
    let frame_goto targets hlink =
      try
      (* target semantics PR-HTML 4.0 16.3.2 *)
       match List.assoc "target" hlink.h_params with
       | "_blank" ->
        let w = Toplevel.create Widget.default_toplevel [] in
        Embed.add { 
        embed_hlink = hlink;
        embed_frame = w;
        embed_context = make_embed_ctx w targets;
        embed_map = Maps.NoMap;
        embed_alt = "" }
       | "_self" ->
        let w = List.assoc "_self" targets in
        Embed.add {
        embed_hlink = hlink;
        embed_frame = w;
        embed_context = make_embed_ctx w targets;
        embed_map = Maps.NoMap;
        embed_alt = "" }
       | "_top" -> follow_link targets hlink
       | "_parent" ->
        let w = List.assoc "_parent" targets in
        Embed.add { 
        embed_hlink = hlink;
        embed_frame = w;
        embed_context = make_embed_ctx w targets;
        embed_map = Maps.NoMap;
        embed_alt = "" }
       | s ->
        let w = List.assoc s targets in
        Embed.add {
        embed_hlink = hlink;
        embed_frame = w;
        embed_context = make_embed_ctx w targets;
        embed_map = Maps.NoMap;
        embed_alt = "" }
      with
       Not_found -> (* if we are in a frame, it is available as _self *)
      try
        let w = List.assoc "_self" targets in
        Embed.add {
        embed_hlink = hlink;
        embed_frame = w;
        embed_context = make_embed_ctx w targets;
        embed_map = Maps.NoMap;
        embed_alt = "" }
      with
        Not_found -> follow_link targets hlink
    in
    List.iter super#add_nav !user_navigation;
    List.iter (fun (name, f, txt) ->
      self#add_nav
    (name, {hyper_visible = true; hyper_func = f; hyper_title = txt}))
       ["copy", copy_link, I18n.sprintf "Copy this Link to clipboard";
    "head", head_link, I18n.sprintf "Headers of document";
    "save", save_link, I18n.sprintf "Save this Link";
    "gotonew", new_link, I18n.sprintf "New window with this Link";
        "goto", frame_goto, I18n.sprintf "Open this Link";
       ];
    self

end
@


\section{XXX}

<<type Viewers.t>>=
(* Definition of an internal viewer *)
type t = 
    Http_headers.media_parameter list -> Widget.widget -> 
     context -> Document.handle -> 
     display_info option
@

<<constant Viewers.viewers>>=
let viewers = Hashtbl.create 17
@

<<signature Viewers.add_viewer>>=
val add_viewer : media_type -> t -> unit
    (* [add_viewer type viewer] *)
@
<<signature Viewers.rem_viewer>>=
val rem_viewer : media_type -> unit
@

<<signature Viewers.add_builtin>>=
val add_builtin : media_type -> t -> unit
    (* [add_builtin type viewer] makes viewer a builtin for type *)
@



<<signature Viewers.reset>>=
val reset : unit -> unit
@



<<type Viewers.spec>>=
type spec =
    Internal of t
  | External         (* pass to metamail *)
  | Save	     (* always save *)
  | Interactive	     (* ask what to do about it *)
@

<<constant Viewers.builtin_viewers>>=
let builtin_viewers = ref []
@
<<function Viewers.add_builtin>>=
let add_builtin t v =
  builtin_viewers := (t,v) :: !builtin_viewers
@


% ??? -> <>
<<function Viewers.reset>>=
let reset () =
  (* Reset the viewer table *)
  Hashtbl.clear viewers;

  (* Restore the builtin viewers *)
  List.iter (fun (x,y) -> add_viewer x y) !builtin_viewers;

  (* Preference settings *)
  let l = Tkresource.stringlist "externalViewers" [] in
  List.iter (fun ctype -> 
    try
      let (typ,sub),pars = Lexheaders.media_type ctype in
      Hashtbl.add viewers (typ,sub) External
    with
      Invalid_HTTP_header e ->
    !Error.default#f (I18n.sprintf "Invalid MIME type %s\n%s" ctype e))
    l;
  let l = Tkresource.stringlist "savedTypes" [] in
  List.iter (fun ctype -> 
    try
      let (typ,sub),pars = Lexheaders.media_type ctype in
      Hashtbl.add viewers (typ,sub) Save
    with
      Invalid_HTTP_header e ->
    !Error.default#f (I18n.sprintf "Invalid MIME type %s\n%s" ctype e))
    l
@



\section{XXX}


<<type Viewers.frame_targets>>=
type frame_targets = (string * Widget.widget) list
@

<<signature Viewers.frame_adopt>>=
val frame_adopt : Widget.widget -> frame_targets -> frame_targets
    (* remap _self and _parent *)
@
<<signature Viewers.frame_fugue>>=
val frame_fugue : frame_targets -> frame_targets
    (* forget about _self and _parents *)
@

<<type Viewers.hyper_func>>=
type hyper_func = {
  hyper_visible : bool;
  hyper_title : string;
  hyper_func : frame_targets -> Hyper.link -> unit
  }
@

<<signature Viewers.di_compare>>=
val di_compare : display_info -> display_info -> bool
@


\section{Mime}


\section{Embedded objects}

<<type Embed.embobject>>=
(* Embedded objects *)
type embobject = {
  embed_hlink : Hyper.link;               (* hyperlink to the object *)
  embed_frame : Widget.widget;  
     (* the frame where the viewers can do their stuff *)
  embed_context : Viewers.context;
  embed_map : Maps.t;                  (* associated map *)
  embed_alt : string
 }
@


<<signature Embed.add>>=
val add : embobject -> unit
@

<<signature Embed.update>>=
val update : 
    Widget.widget -> Viewers.context -> Document.document -> (unit -> unit)
    -> unit
@



<<signature Embed.add_viewer>>=
val add_viewer : 
  Http_headers.media_type -> 
  (Http_headers.media_parameter list -> Widget.widget -> Viewers.context ->
    Document.document -> unit) -> unit
@

<<signature Embed.rem_viewer>>=
val rem_viewer :  Http_headers.media_type -> unit
@


<<constant Embed.embedded_viewers>>=
(* Embedded viewers *)

let embedded_viewers = Hashtbl.create 11
@

<<function Embed.embedded_viewer>>=
let embedded_viewer frame ctx doc =
  (* Destroy the alt window *)
  List.iter Tk.destroy (Winfo.children frame);
  try
    let ctype = contenttype doc.document_info in
    let (typ,subtyp),l = Lexheaders.media_type ctype in
    try
      let viewer = 
    try Hashtbl.find embedded_viewers (typ,subtyp)
        with Not_found -> Hashtbl.find embedded_viewers (typ,"*") in
      viewer l frame ctx doc
    with
    Not_found ->
      let t = 
        I18n.sprintf "Embed Error: no viewer for type %s/%s" typ subtyp in
      let l = Label.create frame [Text t] in pack [l][]
  with
    Not_found ->
      let t = I18n.sprintf "Embed Error: no type for document %s" 
                          (Url.string_of doc.document_address) in 
      let l = Label.create frame [Text t] in pack [l][]
  | Invalid_HTTP_header e ->
      let t = 
       I18n.sprintf "Embed Error: malformed type %s (%s)"
         (contenttype doc.document_info) e in
      let l = Label.create frame [Text t] in pack [l][]
@

\section{[[text/html]]}

\section{[[text/plain]]}

<<function Plain.display_plain>>=
(* Viewing text/plain *)

let display_plain mediapars top vcontext dh =
  let viewer = new plain (top,vcontext,dh) in
  viewer#init;
  Some (viewer :> Viewers.display_info)
@

<<toplevel Plain._1>>=
let _ =
  Viewers.add_builtin ("text","plain") display_plain
@

\chapter{HTML}
% html/

\section{Attributes}


% specified where? RFC?
<<constant Html.default_attributes>>=
(* Attribute values *)
let default_attributes = [ 
  ("isindex"  , "prompt" ),  "Document is indexed/searchable: ";
                             
  ("a"        , "methods"),  "GET";     (* <A METHODS=GET> *)
  ("embed"    , "methods"),  "GET";		(* <EMBED METHODS=GET> *)
  ("embed"    , "alt"    ),  "[EMBEDDED OBJECT]";(* <EMBED ALT="EMBEDDED OBJECT"> *)
  ("form"     , "method" ),  "GET";		(* <FORM METHOD=GET> *)
  ("form"     , "enctype"),  "application/x-www-form-urlencoded";

  ("ol"       , "type"   ),  "1";       (* <OL TYPE=1 *)
  ("input"    , "type"   ),  "TEXT";	(* <INPUT TYPE=TEXT> *)
  ("select"   , "size"   ),  "5";
  ("textarea" , "align"  ),  "bottom";
  ("input"    , "align"  ),  "bottom";
  ("select"   , "align"  ),  "bottom";
  ("img"      , "align"  ),  "bottom";
  (* ("img"   , "alt"    ),  "[IMAGE]"; *) (* Just "IMAGE" ? Boring... *)
  ("area"     , "shape"  ),  "rect";
  ("div"      , "align"  ),  "left";
  ("basefont" , "size"   ),  "3";

  (* frames *)
  ("frame"    , "frameborder" ), "0";
  ("frame"    , "scrolling"   ), "auto";
  ("frameset" , "rows"        ), "100%";
  ("frameset" , "cols"        ), "100%";
  ]
@


<<signature Html.get_attribute>>=
val get_attribute : tag -> string -> string
  (* [get_attribute tag attrib_name] *)
@
<<function Html.get_attribute>>=
let get_attribute tag attr =
  try
    List.assoc attr tag.attributes 
  with
    Not_found ->
     List.assoc (tag.tag_name, attr) default_attributes
@


<<signature Html.has_attribute>>=
val has_attribute : tag -> string -> bool
  (* [has_attribute tag attrib_name] *)
@
<<function Html.has_attribute>>=
let has_attribute tag attr =
     List.mem_assoc attr tag.attributes
  || List.mem_assoc (tag.tag_name, attr) default_attributes
@



\section{Tables}

\section{Forms}

\section{Maps}

% important for imgs?

%(* Client-side image maps:
%     the "only" difficulty in implementing client-side image maps is that
%     the map may well come *after* the image in the document. In general,
%     anyway, the map may be an arbitrary URL.
%
%   We thus have to implement a general delay mechanism for maps : the idea
%   here is to use a table of maps, each map being accessed by an URI (that is,
%   an URL plus a fragment).
%
%   PROBLEM: we have no idea in general when to flush this table.
%
% *)


<<type Maps.area_kind>>=
(* The active areas *)
type area_kind = 
 | Rect 
 | Circle 
 | Poly 
 | Default
@

<<type Maps.area>>=
(* The area *)
type area = {
  area_kind : area_kind;
  area_coords : int list;
  area_link : Hyper.link;
  area_alt  : string
 }
@

<<type Maps.map>>=
type map = area list
@

<<type Maps.t>>=
(* We merge any kind of map, for we actually are going to support
   maps for arbitrary embedded objects
 *)
type t = 
    ClientSide of Hyper.link		(* usemap link *)
  | ServerSide of Hyper.link		(* ismap *)
  | Direct of Hyper.link			(* inside an anchor *)
  | NoMap				(* no additionnal navigation *)
  | FormMap of (int * int -> Hyper.link)
@

<<type Maps.map_status>>=
(* The table of client-side image maps *)
type map_status =
   KnownMap of map
 | RequestedMap of string
@

<<signature Maps.parse_coords>>=
val parse_coords : string -> int list
@

<<signature Maps.get>>=
val get : string -> map_status
@

<<signature Maps.add>>=
val add : string -> map -> unit
@


<<constant Maps.table>>=
let table = (Hashtbl.create 37 : (string, map_status) Hashtbl.t)
@

<<constant Maps.coord_sep>>=
(* Tolerance: official syntax is "," separated.
   We use instead "[ \t\n]+\|\([ \t\n]*,[ \t\n]*\)"
   that is non empty sequence of whitespace
        or comma with possible surrounding whitespace
 *)
(* let coord_sep = Str.regexp "," *)
let coord_sep = Str.regexp "[ \t\n]+\\|\\([ \t\n]*,[ \t\n]*\\)"
@

<<function Maps.parse_coords>>=
let parse_coords s =
  List.map int_of_string (Str.split coord_sep s)
@

<<function Maps.add>>=
let add name map =
  Log.debug (sprintf "Adding map : %s" name);
  try
    match Hashtbl.find table name with
      KnownMap m -> Log.debug "Map already known !"
    | RequestedMap event ->
       Hashtbl.remove table name; (* remove it *)
       Hashtbl.add table name (KnownMap map); (* add its value *)
       !broadcast_backend event (* trigger all waiting people *)
  with
    Not_found -> (* nobody requested it *)
      Hashtbl.add table name (KnownMap map)
@

<<function Maps.get>>=
let get name =
  Log.debug (sprintf "Asking map : %s" name);
  try
    Hashtbl.find table name 
  with
    Not_found ->
       let m = Mstring.gensym "map" in
         Hashtbl.add table name (RequestedMap m);
     RequestedMap m
@







\chapter{Displaying}
% display/
% layout engine? or layout engine is actually in viewers/ ?

\section{Display primitives}

\section{Fonts}

\section{Attributes}

\section{HTML compilation}
% from html lexems to instructions to display engine

\section{HTML elememts}

\subsection{HR}

\subsection{Images}

\subsection{Forms}

\subsection{Tables}

\subsection{Frames}

\chapter{CSS}

%http://www.w3.org/TR/CSS2/
% (better spec than CSS 3 according to rubeck, more self contained)

%http://www.w3.org/TR/selectors/#specificity

% rules
% selectors

\section{Lexing}

\section{Parsing}

\chapter{Javascript}

\section{Lexing}

\section{Parsing}



\chapter{Concurrency}
% important in browser context, servo was actually started just for that
% could also have an isolation chapter?

\section{Tasks}

<<signature Low.add_task>>=
val add_task : (unit -> unit) -> unit
  (* regular tasks *)
@

<<constant Low.tasks>>=
(* There is only a default task *)
let tasks = ref [
  (fun () -> !cur_tachy#report_traffic tick_duration !bytes_read !sample_read)
  ]
@

% main -> init -> <>
<<function Low.refresh>>=
let rec refresh() =
  incr global_time;
  List.iter (fun f -> f ()) !tasks;
  sample_read := 0;
  Timer_.add tick_duration refresh
@

<<signature Low.global_time>>=
val global_time : int ref
@
<<constant Low.global_time>>=
let global_time = ref 0
@


<<signature Low.init>>=
val init : unit -> unit
@
% main -> <>
<<function Low.init>>=
let init () = refresh ()
@

\section{Tachymeter}

\subsection{backend}

<<global Low.bytes_read>>=
let bytes_read = ref 0
@

<<global Low.sample_read>>=
let sample_read = ref 0
@


<<signature Low.cur_tachy>>=
val cur_tachy : tachymeter ref
@

\subsection{frontend}

<<[[Mmm.navigator()]] if not main window, create default toplevel>>=
else Toplevel.create Widget.default_toplevel [Class "MMM"]
@

<<[[Mmm.navigator()]] set tachy>>=
(* put this as a function so we can restart it if needed *)
let rec restart_tachy () =
   (* We must not pass hgroup to tachymeter applets *)
   let fcontainer = Frame.create hgroup [] in
   container_frame := Some fcontainer;
   (* restart it if destroyed *)
   bind fcontainer [[], Destroy]
    (BindSet ([Ev_Widget],
      (fun ei -> 
        if ei.ev_Widget = fcontainer 
                && Winfo.exists hgroup (* but we're not dead *) then
          restart_tachy())));

  let rw = Winfo.reqwidth fcontainer in
  let rh = Winfo.reqheight fcontainer in
  Wm.minsize_set top rw rh;
  pack [fcontainer][Side Side_Right; Anchor N];
  start_tachy();
  (* Bad hack to do bindings for our own internal tachymeter:
   * others, in applets, can just access these functions from the safe
   * library *)
  if !tachy_maker == About.create_tachy then begin 
    match Winfo.children fcontainer with
    | [c] ->
         bind c (Glevents.get "tachy_new")
          (BindSet ([], (fun _ -> new_window_initial ())));
         bind c (Glevents.get "tachy_sel")
          (BindSet ([], (fun _ -> new_window_sel ())));
    | _ -> ()
  end
in
restart_tachy(); (* first initialisation *)
(* good size for keeping only the tachy *)
Wm.minsize_set top 80 80;
@


<<signature Mmm.change_tachy>>=
val change_tachy : (Widget.widget -> Low.tachymeter) -> unit
@

<<function Mmm.change_tachy>>=
let change_tachy (t : Widget.widget -> Low.tachymeter) = 
  !Low.cur_tachy#quit;
  tachy_maker := t;
  begin match !container_frame with
    Some f -> 
      List.iter Tk.destroy (Winfo.children f);
      Low.cur_tachy := t f
  | None -> ()
  end
@

<<constant Mmm.tachy_maker>>=
let tachy_maker = ref About.create_tachy
@


<<function Mmm.start_tachy>>=
let start_tachy () = 
  begin match !container_frame with
    Some f -> 
      Low.cur_tachy := !tachy_maker f
  | None -> ()
  end
@

<<constant Mmm.container_frame>>=
(* Tachymeter support
 * [container_frame] is the parent frame for displaying a tachymeter
 * It's initialized only after the first navigator window is created.
 * [tachy_maker] contains the current tachymeter creation function.
 * [change_tachy] changes the current tachymeter. It has immediate
 * effect if the first navigator window is already available. Otherwise,
 * it will take effect at creation time, using [start_tachy].
 *)
let container_frame = ref None
@

\chapter{Extra features}

\section{Bookmarks}
% aka  hotlist

<<constant Mmm.hotlist>>=
(* Preference settings *)
let hotlist = ref ""
@


\section{User preferences}

% important, like in efuns

\subsection{Preference file, [[-prefs]]}
<<constant Mmm.preferences>>=
(* placeholder for preference panel *)
let preferences = ref (fun () -> ())
@

<<[[Mmm.initial_navigator()]] set preferences>>=
preferences := Mmmprefs.f preffile;
!preferences();
@


<<[[Main.main()]] locals>>=
let preffile = ref (Mmm.user_file "MMM.ad") in
@
<<[[Main.main()]] command line options>>=
"-prefs", Arg.String (fun s -> preffile := s),
"<file>\t\tPreference File";
@
% .ad?
% preferences of navigator
% diff with code using MMM.ad below?



<<signature Mmm.user_file>>=
val user_file : string -> string
    (* [user_file base] returns $HOME/.mmm/[base] *)
@
%$
<<function Mmm.user_file>>=
let user_file name =
  Filename.concat (Filename.concat home ".mmm") name
@

%less: rename homedir!
<<constant Mmm.home>>=
let home =
  try
    Sys.getenv "HOME"
  with
  | Not_found -> 
      prerr_endline "Please set the HOME environment variable.";
      exit (-1)
@


% user (localized) file
<<[[Main.main()]] user preferences file>>=
localize !preffile
@

\subsection{Initial geometry, [[-geometry]]}

<<signature Mmm.initial_geom>>=
val initial_geom : string option ref
@
<<constant Mmm.initial_geom>>=
let initial_geom = ref None
@
<<[[Main.main()]] command line options>>=
"-geometry", Arg.String (fun s -> Mmm.initial_geom := Some s),
"<wxh+x+y>\tInitial geometry for the first navigator";
@

<<[[Mmm.navigator()]] set geometry if specified>>=
(match !initial_geom with 
 | None -> ()
 | Some g -> 
    Wm.geometry_set top g
 );
@

\section{TK customization}

\subsection{Color palette, [[-palette]]}

<<[[Main.main()]] resource initialisation>>=
begin match !palette with
| None -> ()
| Some bg -> try Palette.set_background (Tk.NamedColor bg) with _ -> ()
end;
@
% ??

<<[[Main.main()]] locals>>=
let palette = ref None in
@
<<[[Main.main()]] command line options>>=
"-palette", Arg.String (fun s -> palette := Some s),
"<color>\tTk Palette";
@

\subsection{Click to follow, [[-clicktofocus]]}

<<[[Main.main()]] tk initialisation>>=
if not !clicktofocus 
then Focus.follows_mouse();
@

<<[[Main.main()]] locals>>=
let clicktofocus = ref false in
@
<<[[Main.main()]] command line options>>=
"-clicktofocus", Arg.Unit (fun () -> clicktofocus := true),
"\tClick to Focus mode (default is Focus Follows Mouse)";
@


\section{Help URL, [[-helpurl]]}

<<signature Mmm.helpurl>>=
(* Preferences, options *)
val helpurl : Url.t ref
@
<<constant Mmm.helpurl>>=
let helpurl = ref (Lexurl.make (Version.helpurl (Lang.lang ())))
@
<<[[Main.main()]] command line options>>=
"-helpurl", Arg.String (fun s -> Mmm.helpurl := Lexurl.make s),
"<url>\tHelp URL";
@

<<signature Version.helpurl>>=
val helpurl : string -> string (* help url *)
@
<<function Version.helpurl>>=
let helpurl = function
  | "iso8859" -> 
      Printf.sprintf "http://pauillac.inria.fr/mmm/v%d/docindex.html" number
  | _ -> assert false
@

\section{Multi windows}

% mv later?
<<signature Mmm.main_navigator>>=
val main_navigator : Nav.t option ref
@
<<constant Mmm.main_navigator>>=
let main_navigator = ref None
@
% have this mostly to support multi windows,



<<constant Mmm.navigators>>=
(*
 * A navigator window
 *)
let navigators = ref 0
@

<<[[Mmm.navigator()]] new navigator hook>>=
incr navigators;
@

<<[[Mmm.navigator()]] exn handler, else if multiple navigators>>=
else begin 
  destroy top;
  None
end
@


<<[[Nav.t]] other fields>>=
nav_new : Hyper.link -> unit;
@
<<[[Mmm.navigator()]] set nav fields>>=
nav_new = (fun link ->
     try
       let wwwr = Plink.make link in
       navigator false wwwr.www_url |> ignore; ()
     with Invalid_link msg -> 
      error#f (I18n.sprintf "Invalid link")
);
@

<<signature Mmm.new_window_initial>>=
val new_window_initial : unit -> unit
@
<<signature Mmm.new_window_sel>>=
val new_window_sel : unit -> unit
@

<<function Mmm.new_window_initial>>=
and new_window_initial () =
 navigator false 
   (match !initial_page with | Some u -> u | None -> assert false) |> ignore
@

<<function Mmm.new_window_set>>=
and new_window_sel () =
  try 
    let url = Selection.get [] in
    navigator false (Lexurl.make url) |> ignore
  with _ -> new_window_initial ()
@


<<[[Mmm.navigator()]] nested functions>>=
let new_window () =
     navigator false hist.h_current.h_did.document_url |> ignore
in
let new_window_initial () =
     navigator false initial_url |> ignore
in
let new_window_sel () =
  try 
     let url = Selection.get [] in
     navigator false (Lexurl.make url) |> ignore
  with _ -> navigator false initial_url |> ignore
in
@

\section{Gzip decoders}

% for gzip stuff?

<<signature Decoders.insert>>=
val insert  : Document.handle -> Document.handle
@

<<signature Decoders.add>>=
val add : string -> (Document.handle -> Document.handle) -> unit
@

<<constant Decoders.decoders>>=
(* Insert a decoding if necessary.
 * We don't do it in http, since we don't want do decompress when we
 * save for example.
 *)

let decoders = Hashtbl.create 37
@


<<toplevel Decoders._1>>=
let _ =  
  [ "COMPRESS", gzip;
    "X-COMPRESS", gzip;
    "GZIP", gzip;
    "X-GZIP", gzip
  ] |> List.iter (fun (s,t) -> Hashtbl.add decoders s t)
@



\section{Animated GIFs}

\section{Extra Protocols}


\subsection{[[file://]]}

<<toplevel Protos._7>>=
let _ = Hashtbl.add protos FILE (File.request, Cache.dummy)
@

<<[[Lexurl.f]] protocol cases>>=
(* the spec says file://host/ dammit *)
| "FILE" ->
  (try
     slashslash lexbuf;
     let h = fhost lexbuf in
     let p = slashpath lexbuf in
     result.protocol <- FILE;
     result.host <- h;
     result.path <- p
  with Url_Lexing _ ->
    let p = slashpath lexbuf in
    result.protocol <- FILE;
    result.path <- p
  )
@

<<functions Lexurl.xxx>>=
and fhost = parse
  ['A'-'Z' 'a'-'z' '0'-'9' '.' '-']+
     { Some (normalize_host (Lexing.lexeme lexbuf)) }
| ""
     { Some "localhost" }
@



<<signature File.request>>=
(* file: protocol *)
val request : Www.request -> Document.document_continuation -> 
   (unit -> unit)
    (* [request wr cont] returns [abort] *)
@

<<exception File.File_error>>=
exception File_error of string
@

<<function File.document_id>>=
let document_id wwwr =
  { document_url = wwwr.www_url; document_stamp = no_stamp}
@

%less: LP split and distribute in two sections below
<<function File.request>>=
(*
 * Display a file on the local unix file system (file:)
 *  is path really supposed to be absolute ?
 * Note: completely ignores method (GET, POST,...)
 *)

let request wr cont =
  let path = match wr.www_url.path with
    Some path -> "/" ^ (Lexurl.remove_dots path)
  | None -> "/" 
  in
  <<[[File.request()]] if CGI path>>
  else   (* A bit weird, but we don't want to capture errors from the cont *)
    let st =
      try 
        stat path 
      with _ -> raise (File_error (I18n.sprintf "cannot stat file")) 
    in
    match st.st_kind with
    | S_REG ->
      begin
      (* check if this is an update *)
        try 
          let since = get_header "if-modified-since" wr.www_headers in
          let ht = Lexdate.ht_of_string since in
          let filet = Http_date.ht_of_stamp st.st_mtime in
          if Http_date.compare filet ht > 0
          then raise Not_found (* fall through *)
          else begin
            let dh = { 
              document_id = document_id wr;
              document_referer = wr.www_link.h_context;
              document_status = 304;
              document_headers = [ sprintf "Date: %s" (Date.asc_now())];
              document_feed = 
                Feed.of_fd (openfile "/dev/null" [O_RDONLY] 0);
              document_fragment = wr.www_fragment;
              document_logger = Document.tty_logger
            } in
            Retype.f dh;
            cont.document_process dh;
            (fun () -> ())
          end
       with
       | Not_found  (* default case *)
       | Lexdate.Invalid_date (_,_) ->
          let s = 
            try openfile path [O_RDONLY] 0
            with Unix_error(_,_,_) -> 
              raise (File_error (I18n.sprintf "cannot open file")) 
          in
          let dh =
            { document_id = document_id wr;
              document_referer = wr.www_link.h_context;
              document_status = 200;
              document_headers = 
                [sprintf "Content-Length: %d" st.st_size;
                 sprintf "Date: %s" (Date.asc_now());
                 sprintf "Last-modified: %s" (Date.asc st.st_mtime)
                ];
              document_feed = Feed.of_fd s;
              document_fragment = wr.www_fragment;
              document_logger = Document.tty_logger
            } in
           Retype.f dh;
           cont.document_process dh;
           (fun () -> ())
    end
    | S_DIR -> 
        let s = dir path in
        cont.document_process 
          { document_id = document_id wr;
            document_referer = wr.www_link.h_context;
            document_status = 200;
            document_headers = ["Content-Type: text/html"];
            document_feed = Feed.of_fd s;
            document_fragment = wr.www_fragment;
            document_logger = Document.tty_logger
           };
         (fun () -> ())

    | _ -> raise (File_error (I18n.sprintf "cannot open file"))
@


\subsubsection{Files}

\subsubsection{Directories}

% File.request (DIR case) ->  <>
<<function File.dir>>=
(* It's easiest to do it asynchronously anyway *)
let dir path =
  try
    let d = opendir path in
    let cin, cout = pipe() in
    match Low.fork() with
    | 0 -> 
        close cin; dup2 cout stdout; close cout;
        begin
          try 
            d2html path d 
          with e ->
            print_endline (Printexc.to_string e)
        end;
        flush Pervasives.stdout; (* strange bug with our at_exit stuff *)
        exit 0;
        cin (*duh*)
     | n -> closedir d; close cout; cin
  with Unix_error(_,_,_)  -> 
    raise (File_error (I18n.sprintf "cannot open dir"))
@



% File.dir -> <>
<<function File.d2html>>=
let d2html path d =
  (* make sure that when path is used in url, it is / terminated *)
  let pathurl =
    let l = String.length path in
    if l = 0 
    then path 
    else
      if path.[l-1] = '/' 
      then path
      else sprintf "%s/" path
  in
  Printf.printf 
"<HTML>
<HEAD><TITLE>%s</TITLE>
<BASE HREF=\"file://localhost%s\">
</HEAD>
<BODY>
<H1>Directory list: %s</H1>
<PRE>" path pathurl path;

  let entries = ref [] in
  begin 
   try
     while true do 
       entries := (readdir d) :: !entries
     done      	
   with  End_of_file -> closedir d
  end;
  entries := Sort.list (<=) !entries;
  !entries |> List.iter (function
    |  "." -> ()
    | ".." ->
       printf "Dir   <A HREF=\"file://localhost%s\">..</A>\n"
              (Filename.concat (dirname (dirname pathurl)) "")
    | f ->
       try
         let fullname = Filename.concat path f in
         let st = stat fullname in
         match st.st_kind with
         | S_DIR -> printf "Dir   <A HREF=\"%s\">%s</A>\n" f f
         | S_REG -> printf "File  <A HREF=\"%s\">%-30s</A>%8d bytes\n" 
                       f f (st.st_size)
         | S_LNK -> printf "Link  <A HREF=\"%s\">%s</A>\n" f f
         | _ -> ()
       with Unix_error(_,_,_) -> ()
    );
  printf "</PRE></BODY></HTML>"
@

% ??? -> <>
<<function File.isdir>>=
(* 
 * Simulate directory
 *)
let isdir path f =
  let fullname = Filename.concat path f in
  (stat fullname).st_kind = S_DIR
@
% dead?







\subsection{[[mailto://]]}

<<[[Lexurl.f]] protocol cases>>=
| "MAILTO" ->
    let address = any lexbuf in
    result.protocol <- MAILTO;
    result.path <- address
@

% see extra

<<[[Nav.request.handle_wr()]] match protocol cases>>=
| MAILTO -> Mailto.f wr
 (* mailto: is really a pain. It doesn't fit the retrieval semantics
  of WWW requests. *)
@

\subsection{Proxied protocols}

<<toplevel Protos._1>>=
let _ = Hashtbl.add protos FTP (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._3>>=
let _ = Hashtbl.add protos GOPHER (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._4>>=
let _ = Hashtbl.add protos NEWS (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._5>>=
let _ = Hashtbl.add protos NNTP (Http.proxy_req, Cache.tobuffer)
@

<<toplevel Protos._6>>=
let _ = Hashtbl.add protos WAIS (Http.proxy_req, Cache.tobuffer)
@


<<signature Http.proxy_req>>=
val proxy_req:
  Www.request -> Document.document_continuation -> (unit -> unit)
@

<<function Http.prox_req>>=
and proxy_req wr cont = 
  let cnx = proxy_request wr cont in
  (fun () -> cnx#abort)
@


\subsection{[[ftp://]]}

<<[[Lexurl.f]] protocol cases>>=
| "FTP" -> (* we don't need the detail of path *)
   slashslash lexbuf;
   let u, p = userpass lexbuf in
   let h, po = hostport lexbuf in
   let path = slashpath lexbuf in
   result.protocol <- FTP;
   result.user <- u;
   result.password <- p;
   result.host <- h;
   result.port <- normalize_port (FTP, po);
   result.path <- path
@


<<function Lexurl.userpass>>=
and userpass = parse
  (* foo:bar@, foo:@ *)
  [^ ':' '/' '@']+ ':' [^ ':' '/' '@']* '@'
    { let lexeme = Lexing.lexeme lexbuf in
      let pos = String.index lexeme ':' in
      Some (String.sub lexeme 0 pos),
      Some (String.sub lexeme (succ pos) (String.length lexeme - 2 - pos))
    }
  (* foo@, @ *)
| [^ ':' '/' '@']* '@'
   { let lexeme = Lexing.lexeme lexbuf in
     Some (String.sub lexeme 0 (String.length lexeme - 1)), None
   }
      
| ""
   { None, None }
@

<<functions Lexurl.xxx>>=
and slashpath = parse
  "/" { any lexbuf }
| ""  { None }
@

\subsection{[[telnet://]]}

<<[[Lexurl.f]] protocol cases>>=
| "TELNET" ->
    slashslash lexbuf;
    let u,p = userpass lexbuf in
    let h,po = hostport lexbuf in
    result.protocol <- TELNET;
    result.user <- u;
   result.password <- p;
    result.host <- h;
   result.port <- po
@

\subsection{[[nntp://]]}

<<[[Lexurl.f]] protocol cases>>=
| "NNTP" ->
    let h,po = hostport lexbuf in
    let blah = any lexbuf in
    result.protocol <- NEWS;
    result.host <- h;
    result.port <- po;
    result.path <- blah
@


\subsection{Old protocols}

<<[[Lexurl.f]] protocol cases>>=
| "GOPHER" | "GOPHER+" -> (* we don't need the detail of path *)
    slashslash lexbuf;
    let h,po = hostport lexbuf in
    let path = slashpath lexbuf in
    result.protocol <- GOPHER;
    result.host <- h;
    result.port <- po;
    result.path <- path
| "NEWS" ->
    let blah = any lexbuf in
    result.protocol <- NEWS;
    result.path <- blah
| "WAIS" ->
    slashslash lexbuf;
    let h,po = hostport lexbuf in
    let pa,se = pathsearch lexbuf in
    result.protocol <- WAIS;
    result.host <- h;
   result.port <- po;
    result.path <- pa;
    result.search <- se
| "PROSPERO" ->
    slashslash lexbuf;
    let h,po = hostport lexbuf in
    let p = slashpath lexbuf in
    result.protocol <- PROSPERO;
    result.host <- h;
   result.port <- po;
    result.path <- p
@



\section{Audio}

<<function Audio.fake_embed>>=
(* Defines embedded viewer for audio types as re-running the document *)
let fake_embed media_pars w ctx dh =
  Document.dclose true dh;
  try 
    let hlink = {h_uri = Url.string_of dh.document_id.document_url;
         h_context = None;
         h_method = GET;
         h_params = []} in
    pack [Label.create w [Text "Redispatched externally"]][];
    ctx#goto hlink
  with 
    Not_found (* goto *) -> 
      pack [Label.create w [Text "No navigation given to us"]][]
  | e ->
      pack [Label.create w [Text (Printexc.to_string e)]][]
@

<<toplevel Audio._1>>=
let _ =
  Mmm.add_embedded_viewer ("audio", "*") fake_embed
@



\section{[[mmm_remote]]}

\subsection{Server}

<<[[Main.main()]] locals>>=
let accept_external = ref false in
@
<<[[Main.main()]] command line options>>=
"-external", Arg.Unit (fun () -> accept_external := true),
"\t\tAccept remote command (mmm_remote <url>)";
@

<<[[Main.main()]] mmm server initialisation>>=
(* This must occur after most initialisations *)
if !accept_external 
then Cci.init();
@

\subsection{Client}

<<function Main_remote.request>>=
let request sock cmd url =
  if cmd <> "" 
  then write sock cmd 0 (String.length cmd) |> ignore;
  write sock url 0 (String.length url) |> ignore;
  write sock "\n" 0 1 |> ignore;
  let buf = String.create 1024 in
  try
    while true do
      let n = read sock buf 0 1024 in
      if n = 0 
      then raise End_of_file 
      else ignore (write stdout buf 0 n)
    done
  with End_of_file -> close sock
@

<<function Main_remote.main>>=
let main () =
  let file = 
    Filename.concat (Filename.concat (Sys.getenv "HOME") ".mmm") "remote" in
  let cmd = ref "" in
  
  let s = socket PF_UNIX SOCK_STREAM 0 in
  connect s (ADDR_UNIX file);
  Arg.parse [ 
  "-get", Arg.Unit (fun () -> cmd := "GET "), "Get document";
  "-getbody", Arg.Unit (fun () -> cmd := "GETB "), "Get document body";
  "-head", Arg.Unit (fun () -> cmd := "HEAD "), "Get document headers";
  "-show", Arg.Unit (fun () -> cmd := "DISPLAY "), "Open browser on this URL";
  ]
    (fun url -> request s !cmd url)
    "Usage: mmm_remote [-get | -getbody | -head | -show] <url>\n
     The default is -show."
@

<<toplevel Main_remote._1>>=
let _ = Printexc.catch main ()
@




\chapter{Advanced Topics}

\section{Proxy}

<<signature Http.proxy_xxx>>=
val proxy: string ref
val proxy_port: int ref
@
<<global Http.proxy>>=
(* Default proxy definitions *)
let proxy = ref "no-proxy-defined"
@
<<global Http.proxy_port>>=
let proxy_port = ref 80
@

<<[[Main.main()]] command line options>>=
"-proxy", Arg.String (fun s -> Http.proxy := s), 
"<hostname>\tProxy host";
@
<<[[Main.main()]] command line options>>=
"-port", Arg.Int (fun i -> Http.proxy_port := i),
"<port>\t\tProxy port";
@






<<[[Http.request()]] if http error on tcp_connect, try proxy>>=
proxy_request wr cont
@
%old: but can factorize!
%tcp_connect !proxy !proxy_port wr.www_logging
%     (start_request true wr cont)
%     (failed_request wr cont.document_finish)

<<constant Http.always_proxy>>=
let always_proxy = ref false
@
% it's a preference

<<[[Http.request()]] if always proxy>>=
if !always_proxy 
then proxy_request wr cont
@


<<function Http.proxy_request>>=
(* Process an HTTP request using the proxy.
   We pass on the continuation *)
and proxy_request wr cont =
  tcp_connect !proxy !proxy_port wr.www_logging
       (start_request true wr cont)
       (failed_request wr cont.document_finish)
@


% start_request i passed true = proxy_mode, which is
% then passed to async_request and finally to full_request

<<[[Http.full_request()]] if proxy mode>>=
if proxy_mode 
then Url.string_of wwwr.www_url
@
% when it's not a proxy, we just send the path and search component!
% (the host knows who it is already), but for a proxy
% we need to give the info to the proxy host of the actual
% original host we wanted to reach, so we unparse the full url

\section{Encodings}

% base64, 8859, url encode, etc.

\subsection{Base 64}

\subsubsection{Decoding}

<<signature Base64.decode>>=
val decode : string -> string
@
<<function Base64.decode>>=
let decode s =
  let rpos = ref 0
  and wpos = ref 0
  and len = String.length s in
  let res = String.create (len / 4 * 3) in
    while !rpos < len do
      let v1 = index64.(Char.code s.[!rpos]) in
      let v2 = index64.(Char.code s.[!rpos + 1]) in
      let v3 = index64.(Char.code s.[!rpos + 2]) in
      let v4 = index64.(Char.code s.[!rpos + 3]) in
      (* each char gives 6 bits *)
      let i = (v1 lsl 18) lor (v2 lsl 12) lor (v3 lsl 6) lor v4 in
      res.[!wpos] <- Char.chr (i lsr 16);
      res.[!wpos+1] <- Char.chr ((i lsr 8) land 0xFF);
      res.[!wpos+2] <- Char.chr (i land 0xFF);
      rpos := !rpos + 4;
      wpos := !wpos + 3
      done;
  let cut = 
    if s.[len - 1] = '=' then
      if s.[len - 2] = '=' then 2
      else 1
    else 0 
  in
  String.sub res 0 (String.length res - cut)
@

<<constant Base64.index64>>=
(* For basic credentials only *)
(* Encoding is [A-Z][a-z][0-9]+/= *)
(* 3 chars = 24 bits = 4 * 6-bit groups -> 4 chars *)

let index64 = Array.create 128 0
@

<<toplevel Base64._1>>=
(* Init the index *)
let _ =
  for i = 0 to 25 do index64.(i + Char.code 'A') <- i done;
  for i = 0 to 25 do index64.(i + Char.code 'a') <- i + 26 done;
  for i = 0 to 9 do  index64.(i + Char.code '0') <- i + 52 done;
  index64.(Char.code '+') <- 62;
  index64.(Char.code '/') <- 63
@

\subsubsection{Encoding}

<<signature Base64.encode>>=
(* Base64 encoding (ONLY for Basic authentication) *)
val encode : string -> string
@
<<function Base64.encode>>=
(* Encoding *)
let encode s =
  let rpos = ref 0 
  and wpos = ref 0 in
  let origlen = String.length s in
  let s,len = match origlen mod 3 with
      0 -> s, origlen
    | 1 -> s ^ "\000\000", origlen + 2
    | 2 -> s ^ "\000", origlen + 1 
    | _ -> assert false
  in
  let res = String.create (len / 3 * 4) in
    while !rpos < len do
      let i1 = Char.code s.[!rpos] in
      let i2 = Char.code s.[!rpos+1] in
      let i3 = Char.code s.[!rpos+2] in
      let i = (i1 lsl 16) lor (i2 lsl 8) lor i3 in
      res.[!wpos] <- char64.((i lsr 18) land 0x3f);
      res.[!wpos+1] <- char64.((i lsr 12) land 0x3f);
      res.[!wpos+2] <- char64.((i lsr 6) land 0x3f);
      res.[!wpos+3] <- char64.(i land 0x3f);
      rpos := !rpos + 3;
      wpos := !wpos + 4
      done;
  (* Correct padding *)
  for i = 1 to len - origlen do res.[String.length res - i] <- '=' done;
  res
@


<<constant Base64.char64>>=
let char64 = Array.create 64 'a'
@
<<toplevel Base64._2>>=
let _ =
  for i = 0 to 25 do char64.(i) <- Char.chr (Char.code 'A' + i) done;
  for i = 0 to 25 do char64.(i+26) <- Char.chr (Char.code 'a' + i) done;
  for i = 0 to 9 do char64.(i+52) <- Char.chr (Char.code '0' + i) done;
  char64.(62) <- '+';
  char64.(63) <- '/'
@



\section{i18n}

<<signature I18n.language>>=
val language : string ref
@
<<constant I18n.language>>=
let language = ref ""
@
<<[[Main.main()]] command line options>>=
"-lang", Arg.String (fun s -> I18n.language := s),
"<lang>\t\tI18n language";
@


<<signature I18n.message_file>>=
val message_file : string ref
@
<<constant I18n.message_file>>=
let message_file = ref ""
@
<<[[Main.main()]] command line options>>=
"-msgfile", Arg.String (fun s -> I18n.message_file := s),
"<file>\tI18n message file";
@








%less: diff with I18n.language?
<<signature Lang.lang>>=
val lang : unit -> string
@
<<function Lang.lang>>=
let lang () =
  "iso8859"
@
%  (* if !japan then "ja" else *)




<<signature I18n.sprintf>>=
val sprintf: ('a, unit, string) format -> 'a
@

<<signature I18n.menu_option>>=
@
<<signature I18n.menu_pattern>>=
@
% dead anyway?




<<function I18n.fprintf>>=
(* Internationalization (translation of error messages) *)

let fprintf x = 
  Printf.fprintf x
@
%  (* if !Lang.japan then I18nprintf.fprintf x else *)

<<function I18n.sprintf>>=
let sprintf x = 
  Printf.sprintf x
@
%  (* if !Lang.japan then I18nprintf.sprintf x else *)



<<function I18n.read_transl_file>>=
let read_transl_file msgfile =
  let ic = open_in msgfile in
  let tag_buffer = String.create 16
  and msg_buffer = String.create 1024 in
  let rec store_tag c i =
    if i >= 16 then i else (tag_buffer.[i] <- c; succ i)
  and store_msg c i =
    if i >= 1024 then i else (msg_buffer.[i] <- c; succ i)
  and read_line i =
    match input_char ic with
      '\n' -> i
    | '\\' -> begin match input_char ic with
                '\\' -> read_line(store_msg '\\' i)
              | 'n'  -> read_line(store_msg '\n' i)
              | '\n' -> skip_blanks i
              | c    -> read_line(store_msg c (store_msg '\\' i))
              end
    | c    -> read_line(store_msg c i)
  and skip_blanks i =
    match input_char ic with
      ' '|'\t' -> skip_blanks i
    | c        -> read_line(store_msg c i)
  and read_tag i =
    match input_char ic with
      ':'           -> (i, skip_blanks 0)
    | ' '|'\n'|'\t' -> read_tag i
    | c             -> read_tag(store_tag c i) in
  let transl_tbl = Hashtbl.create 37 in
  let currsrc = ref "" in
  begin try
    while true do
      let (tag_len, msg_len) = read_tag 0 in
      if String.sub tag_buffer 0 tag_len = "src" then
        currsrc := String.sub msg_buffer 0 msg_len
      else if String.sub tag_buffer 0 tag_len = !language then
        Hashtbl.add transl_tbl !currsrc (String.sub msg_buffer 0 msg_len)
      else ()
    done
  with End_of_file ->
    close_in ic
  end;
  transl_tbl
@

<<type I18n.translation_table>>=
type translation_table =
    Unknown
  | NoTranslation
  | Transl of (string, string) Hashtbl.t
@

<<constant I18n.transl_table>>=
let transl_table = ref Unknown
@

<<function I18n.translate>>=
let rec translate msg =
  match !transl_table with
    NoTranslation ->
      msg
  | Transl tbl ->
      begin try Hashtbl.find tbl msg with Not_found -> msg end
  | Unknown ->
      transl_table :=
        if String.length !language == 0 then
          NoTranslation
        else begin
          try
            if Sys.file_exists !message_file then	   
              Transl(read_transl_file !message_file)
            else NoTranslation
          with Sys_error _ | Sys.Break ->
            NoTranslation
        end;
      translate msg
@

<<function I18n.fprintf (./commons/i18n.ml)>>=
let fprintf oc (fmt : ('a, out_channel, unit) format) =
  fprintf oc
    (Obj.magic(translate(Obj.magic fmt : string)) :
                                ('a, out_channel, unit) format)
@

<<function I18n.sprintf (./commons/i18n.ml)>>=
let sprintf (fmt : ('a, unit, string) format) =
  sprintf
    (Obj.magic(translate(Obj.magic fmt : string)) :
                                ('a, unit, string) format)

@

<<function I18n.menu_option>>=
@

<<exception I18n.Found>>=
@

<<function I18n.menu_pattern>>=
@

\subsection{Special characters}

<<[[latin1_normal]] elements>>=
"nbsp", 	"\160"; (* non-breaking space *)
"iexcl",	"\161"; (*  inverted exclamation mark *)
"cent", 	"\162"; (*  cent sign*)
"pound",	"\163"; (*  pound sterling sign*)
"curren",	"\164"; (*  general currency sign*)
"yen",	"\165"; (*  yen sign*)
"brvbar",	"\166"; (*  broken (vertical) bar *)
"sect",	"\167"; (*  section sign *)
"uml",	"\168"; (*  umlaut (dieresis) *)
"copy",	"\169"; (*  copyright sign *)
"ordf",	"\170"; (*  ordinal indicator, feminine *)
"laquo",	"\171"; (*  angle quotation mark, left *)
"not",	"\172"; (*  not sign *)
"shy",	"\173"; (*  soft hyphen *)
"reg",	"\174"; (*  registered sign *)
"macr",	"\175"; (*  macron *)
"deg",	"\176"; (*  degree sign *)
"plusmn",	"\177"; (*  plus-or-minus sign *)
"sup2",	"\178"; (*  superscript two *)
"sup3",	"\179"; (*  superscript three *)
"acute",	"\180"; (*  acute accent *)
"micro",	"\181"; (*  micro sign *)
"para",	"\182"; (*  pilcrow (paragraph sign) *)
"middot",	"\183"; (*  middle dot *)
"cedil",	"\184"; (*  cedilla *)
"sup1",	"\185"; (*  superscript one *)
"ordm",	"\186"; (*  ordinal indicator, masculine *)
"raquo",	"\187"; (*  angle quotation mark, right *)
"frac14",	"\188"; (*  fraction one-quarter *)
"frac12",	"\189"; (*  fraction one-half *)
"frac34",	"\190"; (*  fraction three-quarters *)
"iquest",	"\191"; (*  inverted question mark *)
"Agrave", 	"\192";	(*  capital A, grave accent *)
"Aacute", 	"\193";	(*  capital A, acute accent *)
"Acirc", 	"\194";	(*  capital A, circumflex accent *)
"Atilde", 	"\195";	(*  capital A, tilde *)
"Auml", 	"\196";	(*  capital A, dieresis or umlaut mark *)
"Aring", 	"\197";	(*  capital A, ring *)
"AElig", 	"\198";	(*  capital AE diphthong (ligature) *)
"Ccedil", 	"\199";	(*  capital C, cedilla *)
"Egrave", 	"\200";	(*  capital E, grave accent *)
"Eacute", 	"\201";	(*  capital E, acute accent *)
"Ecirc", 	"\202";	(*  capital E, circumflex accent *)
"Euml", 	"\203";	(*  capital E, dieresis or umlaut mark *)
"Igrave", 	"\204";	(*  capital I, grave accent *)
"Iacute", 	"\205";	(*  capital I, acute accent *)
"Icirc", 	"\206";	(*  capital I, circumflex accent *)
"Iuml", 	"\207";	(*  capital I, dieresis or umlaut mark *)
"ETH", 	"\208";	(*  capital Eth, Icelandic *)
"Ntilde", 	"\209";	(*  capital N, tilde *)
"Ograve", 	"\210";	(*  capital O, grave accent *)
"Oacute", 	"\211";	(*  capital O, acute accent *)
"Ocirc", 	"\212";	(*  capital O, circumflex accent *)
"Otilde", 	"\213";	(*  capital O, tilde *)
"Ouml", 	"\214";	(*  capital O, dieresis or umlaut mark *)
"times",	"\215"; (*  multiply sign*)
"Oslash", 	"\216";	(*  capital O, slash *)
"Ugrave", 	"\217";	(*  capital U, grave accent *)
"Uacute", 	"\218";	(*  capital U, acute accent *)
"Ucirc", 	"\219";	(*  capital U, circumflex accent *)
"Uuml", 	"\220";	(*  capital U, dieresis or umlaut mark *)
"Yacute",	"\221"; (*  capital Y, acute accent *)
"THORN", 	"\222";	(*  capital THORN, Icelandic *)
"szlig", 	"\223";	(*  small sharp s, German (sz ligature) *)
"agrave", 	"\224";	(*  small a, grave accent *)
"aacute", 	"\225";	(*  small a, acute accent *)
"acirc", 	"\226";	(*  small a, circumflex accent *)
"atilde", 	"\227";	(*  small a, tilde *)
"auml", 	"\228";	(*  small a, dieresis or umlaut mark *)
"aring", 	"\229";	(*  small a, ring *)
"aelig", 	"\230";	(*  small ae diphthong (ligature) *)
"ccedil", 	"\231";	(*  small c, cedilla *)
"egrave", 	"\232";	(*  small e, grave accent *)
"eacute", 	"\233";	(*  small e, acute accent *)
"ecirc", 	"\234";	(*  small e, circumflex accent *)
"euml", 	"\235";	(*  small e, dieresis or umlaut mark *)
"igrave", 	"\236";	(*  small i, grave accent *)
"iacute", 	"\237";	(*  small i, acute accent *)
"icirc", 	"\238";	(*  small i, circumflex accent *)
"iuml", 	"\239";	(*  small i, dieresis or umlaut mark *)
"eth", 	"\240";	(*  small eth, Icelandic *)
"ntilde", 	"\241";	(*  small n, tilde *)
"ograve", 	"\242";	(*  small o, grave accent *)
"oacute", 	"\243";	(*  small o, acute accent *)
"ocirc", 	"\244";	(*  small o, circumflex accent *)
"otilde", 	"\245";	(*  small o, tilde *)
"ouml", 	"\246";	(*  small o, dieresis or umlaut mark *)
"divide",	"\247"; (*  divide sign *)
"oslash", 	"\248";	(*  small o, slash *)
"ugrave", 	"\249";	(*  small u, grave accent *)
"uacute", 	"\250";	(*  small u, acute accent *)
"ucirc", 	"\251";	(*  small u, circumflex accent *)
"uuml", 	"\252";	(*  small u, dieresis or umlaut mark *)
"yacute", 	"\253";	(*  small y, acute accent *)
"thorn", 	"\254";	(*  small thorn, Icelandic *)
"yuml", 	"\255" 	(*  small y, dieresis or umlaut mark *)
@


\section{Security}


<<[[Http.full_request()]] write auth stuff>>=
write_realm_auth ();
if proxy_mode 
then write_proxy_auth();
@

<<[[Http.full_request()]] helper functions>>=
(* If the request has an Authorization, write it *)
let write_realm_auth () =
  try
    let cookie = List.assoc "realm" wwwr.www_auth in
    w ("Authorization: Basic "^cookie^"\r\n")
  with Not_found -> ()
in
@

<<[[Http.full_request()]] helper functions>>=
(* For proxy, we don't wait until we get an authorization error *)
let write_proxy_auth () =
  let authspace = {
    auth_proxy = true;
    auth_host = !proxy;
    auth_port = !proxy_port;
    auth_dir = "";
    auth_realm = ""} 
  in
  try (* do we know the cookie *)
    let cookie = Auth.get authspace in
    w ("Proxy-Authorization: Basic "^cookie^"\r\n")
  with Not_found -> (* is that in the request ? *)
     try
       let cookie = List.assoc "proxy" wwwr.www_auth in
       w ("Proxy-Authorization: Basic "^cookie^"\r\n")
     with Not_found -> ()
in
@

\subsection{Parsing}

<<signature Lexheaders.challenge>>=
val challenge : Lexing.lexbuf -> authChallenge
@

\subsection{Security challenge}
% auth
% mv in later chapter? Security?


<<signature Http_headers.challenge>>=
val challenge : header list -> string
  (* WWW-Authenticate *)
@

<<signature Http_headers.proxy_challenge>>=
val proxy_challenge : header list -> string
  (* Proxy-Authenticate *)
@

<<signature Http_headers.expires>>=
val expires : header list -> Http_date.http_time option
  (* Expires *)
@

<<type Http_headers.authScheme>>=
(* Authorisation headers *)
type authScheme =
    AuthBasic
  | AuthExtend of string
@

<<type Http_headers.authChallenge>>=
type authChallenge =
    { challenge_scheme : authScheme;
      challenge_realm : string;
      challenge_params: (string * string) list
    }
@



<<type Auth.authSpace>>=
(* Authorizations are remembered on the base of the directory url and realm
 * They are kept during the whole MMM session, with expiration
 *)
type authSpace = {
   auth_proxy: bool;
   auth_host : string;
   auth_port : int;
   auth_dir : string;
   auth_realm : string
  }
@




<<signature Auth.lifetime>>=
val lifetime : int ref
@

<<signature Auth.auth_file>>=
val auth_file : string ref
@

<<signature Auth.edit>>=
val edit : unit -> unit
@

<<signature Auth.load>>=
val load : unit -> unit
@

<<signature Auth.save>>=
val save : unit -> unit
@

<<signature Auth.add>>=
val add : authSpace -> string -> unit
@

<<signature Auth.get>>=
val get : authSpace -> string
@


<<signature Auth.check>>=
val check : Www.request -> authChallenge -> authSpace ->
                  (string * bool * authSpace) option
@




<<type Auth.authEntry>>=
type authEntry = {
   auth_cookie : string;
   mutable auth_lastused : float
   }
@

<<constant Auth.authorizations>>=
let authorizations = Hashtbl.create 37
@

<<function Auth.get>>=
let get space = 
  let entry = Hashtbl.find authorizations space in
    entry.auth_lastused <- Unix.time();
    entry.auth_cookie
@

<<constant Auth.lifetime>>=
(* Lifetime, in minutes. Default is one hour *)
let lifetime = ref 60
@

<<function Auth.lookup>>=
let rec lookup space = 
  (* Printf.eprintf "%s\n" space.auth_dir; flush Pervasives.stderr; *)
  try
    Hashtbl.find authorizations space
  with
    Not_found ->
     if space.auth_dir = "/" || space.auth_dir = "." 
     then raise Not_found 
     else
      let newdir = Filename.dirname space.auth_dir in
       lookup {auth_proxy = space.auth_proxy;
               auth_host = space.auth_host;
            auth_port = space.auth_port;
        auth_dir = newdir;
        auth_realm = space.auth_realm}
@

<<function Auth.ask_cookie>>=
let ask_cookie forwhere =
  try
    let u,p = !open_passwd_ref forwhere in
      Base64.encode (u^":"^p)
  with
    Failure "cancelled" -> failwith "cancelled"
  | _ -> (!Error.default)#f (I18n.sprintf "Error in base 64 encoding");
        failwith "cancelled"
@

<<function Auth.replace>>=
let replace kind cookie l =
  let rec repl acc = function
    [] -> (kind,cookie)::acc
  | (k,_)::l when k = kind -> repl (acc) l
  | p::l -> repl (p::acc) l in
  repl [] l
@

<<function Auth.add>>=
let add space cookie =
  Log.debug "adding cookie";
  Hashtbl.add authorizations 
      space 
      {auth_cookie = cookie; auth_lastused = Unix.time()}
@

<<function Auth.check>>=
(* Kind is either: realm or proxy *)
let check wwwr challenge authspace =
  let kind = if authspace.auth_proxy then "proxy" else "realm" in
  match challenge.challenge_scheme with
    AuthExtend _ -> (* we don't know how to do this *) 
       None
  | AuthBasic -> (* params are gleefully ignored *)
     try (* if the passwd request is cancelled *)
      let cookie, isnew =
        if List.mem_assoc kind wwwr.www_auth then begin
           (* we already tried, so the authorization is bad ! *)
           Hashtbl.remove authorizations authspace; (* in case *)
           ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm 
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
           true
           end
       else (* ah, it is our first try,  get the authorization *)
         if authspace.auth_proxy then 
            ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
            true
         else
           try 
             let entry = lookup authspace in
              entry.auth_lastused <- Unix.time();
              entry.auth_cookie, false
           with Not_found ->
            ask_cookie (I18n.sprintf "Authorization for %s \"%s\" on \
                                             %s:%d/%s" 
                            kind challenge.challenge_realm
                            authspace.auth_host authspace.auth_port 
                            authspace.auth_dir),
            true
      in
      wwwr.www_auth <- replace kind cookie wwwr.www_auth;
      Some (cookie, isnew, authspace)
     with
      Failure "cancelled" -> None
@

<<function Auth.edit>>=
(* needs to be refined *)
let edit () =
  !edit_backend ()
@

<<constant Auth.auth_file>>=
(* Saving authorizations to file *)
let auth_file = ref ""
@

<<function Auth.save>>=
let save () =
 if !auth_file <> "" then
  let auth_file = Msys.tilde_subst !auth_file in
  try
    let o = openfile auth_file [O_WRONLY; O_CREAT] 0o600 in
    let oc = out_channel_of_descr o in
      output_value oc authorizations;
      flush oc;
      close o
  with
    Unix_error(e,_,_) ->
      !Error.default#f (I18n.sprintf "Error in authorisation save\n%s" 
                 (Unix.error_message e))
  | Sys_error s ->
      !Error.default#f (I18n.sprintf "Error in authorisation save\n%s" s)

 else 
   !Error.default#f (I18n.sprintf "No authorisation file defined")
@

<<function Auth.load>>=
let load () =
  if !auth_file <> "" then
    let auth_file = Msys.tilde_subst !auth_file in
    try
      let ic = open_in auth_file in
      let table = input_value ic
      and time = Unix.time() in
       Hashtbl.iter
          (fun spacerealm entry ->
           entry.auth_lastused <- time;
           Hashtbl.add authorizations spacerealm entry)
          table;
    close_in ic
    with
      Sys_error s ->
       !Error.default#f (I18n.sprintf "Error in authorisation load\n%s" s)
 else 
   !Error.default#f (I18n.sprintf "No authorisation file defined")
@

<<signature Auth.init>>=
val init : unit -> unit
@
% main -> <>
<<function Auth.init>>=
let init () =
  let check () =
    let remove = ref []
    and lifetime = float (60 * !lifetime)
    and time = Unix.time () in
    Hashtbl.iter 
      (fun space entry ->
       let expiration_time = entry.auth_lastused +. lifetime in
    if time > expiration_time then remove := space :: !remove)
      authorizations;
    List.iter (Hashtbl.remove authorizations) !remove
  in
  let rec tim () =
    Timer_.set (!lifetime * 30000) (fun () -> check(); tim ())
  in
  tim ()
@



\section{Optimisations}
% could also have an parallel chapter?


\subsection{Document cache, [[Cache]]}

%rappel:
%let _ = Hashtbl.add protos HTTP (Http.req, Cache.tobuffer)

<<signature Cache.tobuffer>>=
val tobuffer: Document.handle -> Document.document_data * cache_fill
@

<<function Cache.tobuffer>>=
let tobuffer dh =
  let b = Ebuffer.create 1024 in
  MemoryData b, {cache_write = Ebuffer.output b;
                 cache_close = (fun () -> ())}
@


<<function Cache.add>>=
(* Add a new entry *)
let add did doc =
  if !debug 
  then Log.f (sprintf  "Adding new cache entry %s(%d) %s"
                        (Url.string_of did.document_url)
                        did.document_stamp
                        (match doc.document_data with
                        | MemoryData _ -> "in memory"
                        | FileData (f,true) -> f
                        | FileData (f,false) -> "fake " ^f));

  (* Kill the previous entry, if any [for update] *)
  kill did;
  (* Because of frames (not kept in history), we must make room even
   * in history mode
   *)
  if (*not !history_mode && *)!current >= !max_documents 
  then make_room()
  else 
   if !debug 
   then Log.f (sprintf "Cache size(max): %d(%d)" !current !max_documents);
   incr current;
    memory := (did,
               { cache_document = doc;
                 cache_pending = true;
                 cache_lastused = max_lastused;
                 cache_condition = Condition.create()
               }) :: !memory
@


<<[[Nav.request.handle_wr()]] if use cache>>=
(* If the the document can be cached, then it is with no_stamp *)
let did = 
  { document_url = wr.www_url; 
    document_stamp = no_stamp }
in
try
  specific nav did wr
with Not_found ->
  try
    let doc = Cache.find did in
    try (* display it from source *)
      process nav wr (Cache.make_handle wr doc)
    with 
    | Sys_error s ->
        wr.www_error#f (I18n.sprintf
         "Cache error occurred during save of temporary buffer (%s)"
            s)
    | Unix_error (e,fname,arg) ->
        wr.www_error#f (I18n.sprintf 
          "Cache error occurred when opening temporary file\n%s: %s (%s)"
          fname (Unix.error_message e) arg)
 with Not_found -> (* we don't have the document *)
   retrieve_and_handle wr
@


<<signature Nav.dont_check_cache>>=
(*-*)
val dont_check_cache : Www.request -> bool
@
% Nav.request -> <>
<<function Nav.dont_check_cache>>=
(* Some requests should not be looked for in the cache *)
let dont_check_cache wwwr =
  match wwwr.www_link.h_method with
  | POST _ -> true
  | _ -> false
@


\subsection{Graphic cache, [[Gcache]]}
% Graphic cache

<<[[Nav.process_viewer()]] add in cache and history the document>>=
Gcache.add nav.nav_id dh.document_id di;
@

\section{Fake CGI}

<<[[File.request()]] if CGI path>>=
if is_cgi path 
then (fake_cgi wr cont path; (fun () -> ()))
@

<<constant File.binary_path>>=
(* Pref stuff *)
let binary_path = ref ([] : string list)
@

<<function File.is_cgi>>=
let is_cgi file =
  match !binary_path with
    [] -> false
  | path ->
      let l = String.length file in
      List.exists (fun dir ->
    let ldir = String.length dir in
    l > ldir && String.sub file 0 ldir = dir)
    path
(*
 * Display a file on the local unix file system (file:)
 *  is path really supposed to be absolute ?
 * Note: completely ignores method (GET, POST,...)
 *)
@


<<function File.fake_cgi>>=
(* Not true CGI interface, just a hack *)
(* TODO: headers ? *)
let fake_cgi wwwr cont path =
  try 
    let (cmd_in, cmd_out) = pipe() in
    let cmd, args = 
      try 
       let pos = String.index path '?' in
       let cmd = String.sub path 0 pos in
       if pos + 1 = String.length path 
       then cmd, [| cmd |]
       else cmd, [|cmd; String.sub path (pos+1) (String.length path - pos - 1)|]
      with Not_found -> path, [| path |] 
    in
    match Low.fork() with
    | 0 -> 
        close cmd_in;
        dup2 cmd_out stdout; close cmd_out;
        begin 
          try execvp cmd args 
          with Unix_error(e, _, _) ->
            Munix.write_string stdout "HTTP/1.0 404 Not found\r\n";
            Munix.write_string stdout "Content-Type: text/html\r\n\r\n";
            Munix.write_string stdout "<H1>Cannot execute local file</H1>";
            Munix.write_string stdout "Command \"";
            Munix.write_string stdout cmd;
            Munix.write_string stdout "\" failed:";
            Munix.write_string stdout (Unix.error_message e);
            Munix.write_string stdout "\n";
            exit 1
         end
   | n ->
      close cmd_out;
      let dh = {document_id = document_id wwwr;
                document_referer = wwwr.www_link.h_context;
                document_status = 0;
                document_headers = [];
                document_feed = Feed.of_fd cmd_in;
                document_fragment = wwwr.www_fragment;
                document_logger = Document.tty_logger} 
      in
      dh.document_feed.feed_schedule
        (fun () ->
           try
            if dh.document_headers = [] then begin
            (* it should be the HTTP Status-Line *)
            let l = Munix.read_line cmd_in in
              dh.document_status <- (parse_status l).status_code;
              dh.document_headers <- [l] (* keep it there *)
            end
          else 
            dh.document_headers <- 
              read_headers cmd_in dh.document_headers
          with
           | End_of_headers ->
               dh.document_feed.feed_unschedule();
               cont.document_process dh
           | Not_found -> (* No HTTP/ header *)
               dh.document_feed.feed_unschedule();
               dh.document_status <- 200;
               dh.document_headers <- ["Content-Type: text/plain"];
               cont.document_process dh
           | Unix_error(_,_,_) ->
               dclose true dh;
               raise (File_error (I18n.sprintf 
                  "Error while reading headers of %s\n%s" path "(read)"))
           | Invalid_HTTP_header s ->
               dclose true dh;
               raise (File_error (I18n.sprintf 
                      "Error while reading headers of %s\n%s" path s))
           | End_of_file ->
               dclose true dh;
               raise (File_error (I18n.sprintf 
                  "Error while reading headers of %s\n%s" path "eof"))
          )
  with Unix_error(_,_,_) -> 
    raise (File_error (I18n.sprintf "cannot exec file"))
@


\section{Applets}

<<[[Http_headers.suffixes]] elements>>=
"cmo", ContentType "Content-Type: application/x-caml-applet; encoding=bytecode";
@

<<[[Main.main()]] applet system initialisation>>=
(* The applet system.
 * This loads the local modules also, so any setup that might be
 * overriden by a local module should happen before here.
 * However, preference initialisation must happen *after* initialisation
 * of the applet system
 *)
!Version.applet_init !modules;
@

<<[[Main.main()]] locals>>=
let modules = ref true in
@
<<[[Main.main()]] command line options>>=
"-nomodule", Arg.Unit (fun () -> modules := false),
"\t\tDon't load initial modules";
@



<<signature Version.applet_init>>=
(*-*)
val applet_init : (bool -> unit) ref
@
<<constant Version.applet_init>>=
(* Make it easier to compile both bytecode and native versions *)
let applet_init = ref (fun _ -> ())
@


<<[[Mmm.navigator()]] User menu>>=
(* User menu, extensible by applets *)
let userb = Menubutton.create_named mbar "user" [Text (I18n.sprintf "User")] in
let userm = ref (Menu.create_named userb "menu" []) in
let reset_user_menu _ =
  destroy !userm;
  userm := Menu.create_named userb "menu" [];
  !user_menus |> List.iter (fun (entry, f) ->
      Menu.add_command !userm 
           [Label entry; 
            Command (fun () -> f (Nav.make_ctx nav hist.h_current.h_did))]
  );
  Menubutton.configure userb [Menu !userm] 
in
reset_user_menu();
Frx_synth.bind userb "user_menu" reset_user_menu;
@




<<signature Mmm.add_user_menu>>=
(* Used for applets *)
val add_user_menu : string -> (Viewers.context -> unit) -> unit
@

<<constant Mmm.user_menus>>=
(* User defined menus *)
let user_menus = ref []
@
<<function Mmm.add_user_menu>>=
let add_user_menu entry f = 
  user_menus := (entry,(fun x -> try f x with _ ->())) :: !user_menus;
  Frx_synth.broadcast "user_menu"
@


\section{Signals}

<<[[Main.main()]] signal handling>>=
Sys.catch_break true;
(* Avoid SIGPIPE completely, in favor of write() errors *)
Sys.set_signal Sys.sigpipe Sys.Signal_ignore;
@

\chapter{Conclusion}

\appendix

\chapter{Debugging}

<<signature Log.debug_mode>>=
val debug_mode : bool ref
@
<<constant Log.debug_mode>>=
let debug_mode = ref false
@

\section{Logging}

<<signature Log.f>>=
val f : string -> unit
@
% ??
<<function Log.f>>=
(* flushes ! *)
let f s = 
  try prerr_endline s with _ -> ()
@




<<signature Log.debug>>=
val debug : string -> unit
@
<<function Log.debug>>=
let debug s = 
  if !debug_mode 
  then f s 
@


\section{Postmortem}


<<[[Main.main()]] after event loop, if debug mode>>=
if !Log.debug_mode then begin
  Cache.postmortem();
  Gcache.postmortem()
end;
@
%less: could put that outside main actually,
% and below do main(); and this code. cleaner.


<<toplevel Main._1>>=
let _ = 
  Printexc.catch postmortem ()
@

<<function Main.postmortem>>=
let postmortem () =
  try 
    main ()
  with
  | Dynlink.Error err ->
      failwith (spf "dynlink error = %s" (Dynlink.error_message err))
  | e -> 
      <<[[Main.main()]] after event loop, if debug mode>>
      raise e
@



<<signature Cache.postmortem>>=
val postmortem : unit -> unit
@

<<function Cache.postmortem>>=
(* Debugging *)
let postmortem () =
  Log.f (sprintf "Cache size(max): %d(%d)" !current !max_documents);
  !memory |> List.iter (fun (did, entry) ->
    Log.f (sprintf "%s(%d) %s"
            (Url.string_of did.document_url)
            did.document_stamp
            (match entry.cache_document.document_data with
             | MemoryData _ -> "in memory"
             | FileData (f,true) -> f
             | FileData (f,false) -> "fake " ^f)
             );
    entry.cache_document.document_info
    |> List.rev
    |> List.iter (fun h -> Log.f (sprintf "%s" h));

    if entry.cache_pending 
    then Log.f "pending ";
    Log.f (sprintf "Last used: %f" entry.cache_lastused);
    Log.f ""
  )
@


\section{Subsystems}

\subsection{Documents}

<<signature type Document.logger>>=
(* pad: exported for tk_document, but normally should be abstract *)
type logger = {
  logger_destroy : bool -> unit;
  logger_progress : int -> unit;
  logger_msg : string -> unit;
  logger_end : string -> unit
}
@
\ifallcode
<<type Document.logger>>=
type logger = {
  logger_destroy : bool -> unit;
  logger_progress : int -> unit;
  logger_msg : string -> unit;
  logger_end : string -> unit
}
@
\fi

<<signature Document.tty_logger>>=
val tty_logger : logger
@

<<constant Document.tty_logger>>=
let tty_logger = 
  { logger_destroy = (fun _ -> ());
    logger_progress = (fun _ -> ());
    logger_msg = Log.f;
    logger_end = Log.f
   }
@

% who sets something more complex?

\subsection{HTML}

<<signature Html.verbose>>=
val verbose : bool ref
  (* verbose mode for HTML related stuff *)
@
<<constant Html.verbose>>=
let verbose = ref false
@

<<[[Htparse.html_lex()]] print token t if verbose>>=
if !verbose 
then begin 
   Html.print t; 
   flush stdout
end
@

% ??? -> <>
<<function Html.warning>>=
let warning s (Loc(n,m)) = 
  if !verbose then begin 
    eprintf "HTML Warning: %s at (%d, %d)\n" s n m;
    flush stderr
   end
@


<<signature Html_eval.debug>>=
(* HTML Evaluation *)
val debug : bool ref
@

<<constant Html_eval.debug>>=
let debug = ref false
@

% code using that? can be set via command line?

\subsection{HTTP}

<<constant Http.verbose>>=
let verbose = ref false
@

<<[[Http.async_request()]] log request string req if verbose>>=
if !verbose 
then Log.f req;
@


\subsection{Caches}

<<signature Cache.debug>>=
(* Configurable settings *)
val debug : bool ref
@
<<constant Cache.debug>>=
let debug = ref false
@

% code using that? can be set via command line?

\subsection{Scheduler}

<<signature Scheduler.debug>>=
(*
 * Certain kind of documents need to be shared, such as in-lined images.
 * In this case, instead of working with Retrieve.f and the normal
 * document continuation, we queue the request to a scheduler, with a
 * continuation to be applied to an object representing the shared 
 * information for that document.
 * E.G: for in-lined images, the shared information is the Tk-handle to
 * the image.
 *)

val debug : bool ref
@
<<constant Scheduler.debug>>=
let debug = ref false 
@

\subsection{GUI}

% main -> <>
<<function Debug.init>>=
let init () =
  Frx_rpc.register "cb" active_cb;
  Frx_rpc.register "cache"
     (fun _ -> 
       Cache.postmortem();  
       Gcache.postmortem(); 
       flush stderr);
  Frx_rpc.register "images" (fun _ -> 
    Img.ImageData.dump(); 
    flush stderr);
  Frx_rpc.register "camltkdb" (fun _ -> 
    Protocol.debug := not !Protocol.debug)
@

<<function Debug.active_cb>>=
let active_cb _ =
  let cnter = ref 0 in
  Hashtbl.iter 
    (fun w id ->
      incr cnter;
      Printf.fprintf stdout "%s %s %b\n"
        (Widget.name w) (string_of_cbid id) (Winfo.exists w)  
    )
    callback_memo_table;
  Printf.fprintf stdout "Memo cb: %d\n" !cnter;
  cnter := 0;
  Hashtbl.iter (fun _ _ -> incr cnter) callback_naming_table;
  Printf.fprintf stdout "Active cb: %d\n" !cnter;
  flush stdout
@


\section{Dumpers}

\subsection{URLs}

<<signature Url.string_of_protocol>>=
val string_of_protocol: protocol -> string
  (* maps FTP to "ftp", etc... *)
@

<<function Url.string_of_protocol>>=
let string_of_protocol = function
   FTP -> "ftp"
 | HTTP -> "http"
 | GOPHER -> "gopher"
 | MAILTO -> "mailto"
 | NEWS -> "news"
 | NNTP -> "nntp"
 | TELNET -> "telnet"
 | WAIS -> "wait"
 | FILE -> "file"
 | PROSPERO -> "prospero"
 | OtherProtocol s -> s
@

<<signature Url.string_of>>=
(* These are used to get "normalized urls" *)
val string_of: t -> string
@


<<function Url.string_of>>=
let string_of p =
  let buf = Ebuffer.create 128 in
  let ws x = Ebuffer.output_string buf x in
  let wc x = Ebuffer.output_char buf x in
  let write_userpass () =
      match p.user, p.password with
         None, None -> ()
       | Some u, Some p -> ws u; wc ':'; ws p; wc '@'
       | Some u, None ->   ws u; wc ':'; wc '@'
       | None, Some _ -> failwith "url_of_parsed"
  in
  (* hostname is always put in lowercase *)
  let write_hostport def =
      match p.host, p.port with
         None, None -> ()
       | Some h, None -> ws (String.lowercase h)
       | Some h, Some p when p = def -> ws (String.lowercase h)
       | Some h, Some p -> 
           ws (String.lowercase h); wc ':'; ws (string_of_int p)
       | None, Some _ -> failwith "url_of_parsed"	    
  in
  let write_pathsearch () =
      match p.path, p.search with
        None, None -> wc '/'
      | Some p, Some s -> wc '/'; ws p; wc '?'; ws s
      | Some p, None -> wc '/'; ws p
      | None, Some _ -> failwith "url_of_parsed"	    
  in
  let write_slashpath () =
      match p.path with
       None -> ()
      | Some p -> wc '/'; ws p
  in
  let write_path () =
      match p.path with
       None -> ()
      | Some p -> ws p
  in
  let write_fhost () =
      match p.host with
       None -> ws "localhost"
      | Some h -> ws (String.lowercase h)
  in
  begin match p.protocol with
    FTP ->
      ws "ftp://"; write_userpass (); write_hostport 21; write_slashpath ()
  | HTTP ->
      ws "http://"; write_hostport 80; write_pathsearch ()
  | GOPHER ->
      ws "gopher://"; write_hostport 70; write_slashpath ()
  | MAILTO -> ws "mailto:"; write_path()
  | NEWS -> ws "news:"; write_path()
  | NNTP -> ws "nntp:"; write_hostport 119; write_path()
  | TELNET -> ws "telnet://"; write_userpass(); write_hostport 23
  | WAIS -> ws "wais://"; write_hostport 210; write_pathsearch()
  | FILE ->
    (* for file: we have to transform to ftp: if host is not localhost *)
    begin match p.host with
      None | Some "localhost" ->
        ws "file://"; write_fhost(); write_slashpath()
    | Some h ->
       p.protocol <- FTP;
        ws "ftp://"; write_userpass (); write_hostport 21; write_slashpath ()
    end
  | PROSPERO -> ws "prospero://"; write_hostport 1525; write_slashpath()
  | OtherProtocol s -> ws s; ws ":"; write_path()
  end;
  Ebuffer.get buf
@

\subsection{Links}

<<signature Hyper.string_of>>=
val string_of : link -> string
  (* make an absolute URI (including fragment) from link 
     raises Invalid_link(msg) *)
@

<<function Hyper.string_of>>=
let string_of link =
  let uri = resolve link in
   match uri.uri_frag with 
      None -> uri.uri_url
    | Some f -> Printf.sprintf "%s#%s" uri.uri_url f
@

\subsection{DTDs}

<<signature Dtd.dump>>=
val dump : t -> unit
@

<<function Dtd.dump>>=
let dump dtd =
  dtd.contents |> Hashtbl.iter (fun s contents -> 
      printf "Element %s %s %s\n" s 
             (if Elements.mem s dtd.open_omitted then "O" else "-")
             (if Elements.mem s dtd.close_omitted then "O" else "-");
      printf "Contains:";
      contents |> Elements.iter (fun e -> printf " %s" e);
      printf "\n"
  )
@

\subsection{HTML}

<<signature Html.print>>=
val print : token -> unit
  (* for debugging, prints an HTML token *)
@


<<function Html.print>>=
let print = function
    PCData s -> eprintf "PCData: %s\n" s
  | CData s -> eprintf "CData: %s\n" s
  | OpenTag {tag_name = n; attributes = l} ->
            eprintf "Open: %s\n" n;
         List.iter (function (a,v) ->
                   eprintf "%s=%s\n" a v) l
  | CloseTag n -> eprintf "Close: %s\n" n
  | Comment s -> eprintf "Comment: %s\n" s
  | Doctype s -> eprintf "Doctype: %s\n" s
  | EOF -> eprintf "EOF\n"
@

\chapter{Profiling}

\chapter{Error Managment}

\section{[[Error.t]]}

<<signature Error.f>>=
val f : string -> unit
@
<<signature Error.ok>>=
val ok : string -> unit
@
<<signature Error.choose>>=
val choose : string -> bool
@
<<signature Error.ari>>=
val ari : string -> int
@

%todo: should actually use those functions
% instead of those !Error.default#xxx everywhere. How better to use oo
% for that?


<<signature class Error.t>>=
class virtual t : object
 method virtual f : string -> unit
 method virtual ok : string -> unit
 method virtual choose : string -> bool
 method virtual ari : string -> int
end
@


<<signature Error.default>>=
val default : t ref
@
<<constant Error.default>>=
let default = ref (new x)
@

<<functions Error.xxx>>=
let f msg = !default#f msg
and ok msg = !default#ok msg
and choose msg = !default#choose msg
and ari msg = !default#ari msg
@

<<class Error.t>>=
@

\section{URL}

<<exception Url.Url_Lexing>>=
exception Url_Lexing of string * int
@

<<exception Url.Invalid_url>>=
exception Invalid_url of t * string
@

\section{Links}

<<exception Hyper.Invalid_link>>=
exception Invalid_link of link_error
@

<<type Hyper.link_error>>=
type link_error =
    LinkResolve of string
  | UrlLexing of string * int
@


\section{Web requests}

<<exception Www.Invalid_request>>=
exception Invalid_request of request * string
@

\section{HTML}

<<exception Html.Html_Lexing>>=
exception Html_Lexing of string * int
@

<<exception Html.Invalid_Html>>=
exception Invalid_Html of string
@

<<signature Html.warning>>=
val warning : string -> location -> unit
@

\section{HTTP}

<<exception Http_headers.Invalid_HTTP_header>>=
exception Invalid_HTTP_header of string
@

<<exception Http.HTTP_error>>=
exception HTTP_error of string
@


\chapter{A Preferences Library}

\chapter{Standard Library}

<<constant Common.spf>>=
let spf = Printf.sprintf
@

<<function Common.TODOOPERATOR>>=
let (|>) o f = f o
@

\section{Lists}

<<signature Mlist.hdn>>=
(* List utilities *)
val hdn : 'a list -> int -> 'a list
   (* [hdn [a1;a2;...;an;...; ak] returns [a1;a2;...;an] *)
@

<<signature Mlist.tln>>=
val tln : 'a list -> int -> 'a list
   (* [tln [a1;a2;...;an;...; ak] returns [an+1;...; ak] *)
@

<<signature Mlist.except_assoc>>=
val except_assoc: 'a -> ('a * 'b) list -> ('a * 'b) list
@

<<signature Mlist.exceptq>>=
val exceptq: 'a -> 'a list -> 'a list
@

<<signature Mlist.rev_do_list>>=
val rev_do_list : ('a -> unit) -> 'a list -> unit
@

<<signature Mlist.do_listi>>=
val do_listi : (int -> 'a -> unit) -> int -> 'a list -> unit
@




<<function Mlist.tln>>=
(* tln l n *)
let rec tln l = function
   0 -> l
 | n -> if l = [] then [] else tln (List.tl l) (pred n)
@

<<function Mlist.hdn>>=
let hdn l =
  let rec h l acc = function
    0 -> List.rev acc
  | n -> if l = [] then List.rev acc 
        else h (List.tl l) (List.hd l :: acc) (pred n) in
  h l []
@

<<function Mlist.except_assoc>>=
let except_assoc x =
  let rec ex acc = function 
      [] -> acc
    | (y,v)::l when x = y -> ex acc l
    | z :: l -> ex (z::acc) l
  in
  ex []
@

<<function Mlist.exceptq>>=
let exceptq x =
  let rec ex acc = function
     [] -> acc
   | y::l when y == x -> ex acc l
   | y::l -> ex (y::acc) l
  in
  ex []
@

<<function Mlist.rev_do_list>>=
(* List.iter from right to left *)
let rev_do_list f = 
 let rec do_list_f = function
     [] -> () | x::l -> do_list_f l; f x in
  do_list_f
@

<<function Mlist.do_listi>>=
let rec do_listi f n l =
  match l with
    [] -> ()
  | (x::l) -> f n x; do_listi f (succ n) l
@

\section{Strings}

<<signature Mstring.split_str>>=
(* String utilities *)
val split_str : (char -> bool) -> string -> string list
@

<<signature Mstring.get_suffix>>=
val get_suffix : string -> string
@

<<signature Mstring.hex_to_dec>>=
val hex_to_dec : char -> int
@

<<signature Mstring.dec_to_hex>>=
val dec_to_hex : int -> char
@

<<signature Mstring.hex_to_string>>=
val hex_to_string : string -> string
@

<<signature Mstring.gensym>>=
val gensym : string -> string
@

<<signature Mstring.egensym>>=
val egensym : string -> unit -> string
@

<<signature Mstring.rem_trailing_sp>>=
val rem_trailing_sp : string -> string
@

<<signature Mstring.catenate_sep>>=
val catenate_sep : string -> string list -> string
@

<<signature Mstring.norm_crlf>>=
val norm_crlf : bool -> string -> int -> int -> string * bool
    (* [norm_crlf last_was_cr buf offs len] returns
       buf with CRLF/CR/LF converted to LF, and a flag indicating
       whether last char was CR *)
@




<<function Mstring.split_str>>=
(* split a string according to char_sep predicate *)
let split_str char_sep str =
  let len = String.length str in
  if len = 0 then [] else
    let rec skip_sep cur =
      if cur >= len then cur
      else if char_sep str.[cur] then skip_sep (succ cur)
      else cur  in
    let rec split beg cur =
      if cur >= len then 
    if beg = cur then []
    else [String.sub str beg (len - beg)]
      else if char_sep str.[cur] 
       then 
         let nextw = skip_sep cur in
          (String.sub str beg (cur - beg))
        ::(split nextw nextw)
       else split beg (succ cur) in
    let wstart = skip_sep 0 in
    split wstart wstart
@

<<function Mstring.get_suffix>>=
(* extract the . suffix (dot excluded) of a string *)
let get_suffix s =
  try
    let dotpos = succ (String.rindex s '.') in
      String.sub s dotpos (String.length s - dotpos)
  with
    Not_found -> ""
@

<<function Mstring.hex_to_dec>>=
(* HEX/DEC conversions *)
let hex_to_dec c = match c with
    '0'..'9' -> Char.code c - 48
  | 'a'..'f' -> Char.code c - 87 (* 87 = Char.code 'a' - 10 *)
  | 'A'..'F' -> Char.code c - 55 (* 55 = Char.code 'A' - 10 *)
  | _ -> failwith "hex_to_dec"
@

<<function Mstring.dec_to_hex>>=
let dec_to_hex i =
  if i < 10 then Char.chr (i + 48)  (* 48 = Char.code '0' *)
  else Char.chr (i + 55)            (* 55 = Char.code 'A' - 10 *)
@

<<function Mstring.hex_to_string>>=
(* Converting a hex stored string *)
let hex_to_string s =
  let len = String.length s / 2 in
  let res = String.create len in
    for i = 0 to len - 1 do
      res.[i] <- Char.chr ( 16 * (hex_to_dec s.[i+i]) + hex_to_dec s.[i+i+1])
      done;
    res
@

<<constant Mstring.gensym>>=
let gensym =
  let cnter = ref 0 in
  (fun n ->
    incr cnter;
    n ^ string_of_int !cnter)
@

<<function Mstring.egensym>>=
let egensym s =
  let cnter = ref 0 in
  (fun () ->
    incr cnter;
    s ^ string_of_int !cnter)
@

<<function Mstring.rem_trailing_sp>>=
let rem_trailing_sp s =
  let l = String.length s in
  let pos = ref (l - 1) in
  while !pos >= 0 && List.mem s.[!pos] [' '; '\t'] do decr pos done;
  if !pos = l - 1 then s
  else String.sub s 0 (succ !pos)
@

<<function Mstring.catenate_sep>>=
let catenate_sep sep =
  function 
      [] -> ""
    | x::l -> List.fold_left (fun s s' -> s^sep^s') x l
@

<<function Mstring.norm_crlf>>=
(* Filters CRLF:
 *  CR -> LF
 *  CRLF -> LF
 *  LF -> LF
 * We do this on successive chunks of a stream, so we need to consider
 * the case when the chunk finishes on CR.
 * Assume len > 0
 *)

let norm_crlf lastwascr buf offs len =
  let rpos = ref offs
  and wpos = ref 0
  and dest = String.create (len + 1) (* we need one more char *)
  and limit = offs + len - 1  
  and lastiscr = ref false in
  if lastwascr then
    if buf.[!rpos] = '\n' then begin
      dest.[!wpos] <- '\n';
      incr rpos; incr wpos
    end
    else begin
      dest.[!wpos] <- '\n'; incr wpos
    end;

  while !rpos < limit do
    match buf.[!rpos] with
      '\n' -> dest.[!wpos] <- '\n'; incr rpos; incr wpos
    | '\r' -> 
    if buf.[!rpos + 1] = '\n'
    then begin dest.[!wpos] <- '\n'; rpos := !rpos + 2; incr wpos end
    else begin dest.[!wpos] <- '\n'; incr rpos; incr wpos end
    | c -> dest.[!wpos] <- c; incr rpos; incr wpos 
  done;
  begin match buf.[offs+len-1] with
    '\n' -> dest.[!wpos] <- '\n'; incr wpos
  | '\r' -> lastiscr := true
  | c -> dest.[!wpos] <- c; incr wpos
  end;
  String.sub dest 0 !wpos, !lastiscr
@

\section{Files}

<<signature Msys.tilde_subst>>=
val tilde_subst : string -> string
    (* substitute ~ at beginning of file path *)
@

<<signature Msys.rm>>=
val rm: string -> unit
    (* quiet unlink *)
@

<<signature Msys.fsize>>=
val fsize: string -> int
    (* file size *)
@

<<signature Msys.mktemp>>=
val mktemp : string -> string
@

<<function Msys.next_slash>>=
(* skip to next / *)
let rec next_slash s n =
  if  n >= String.length s or s.[n] = '/' 
  then n
  else next_slash s (succ n)
@

<<function Msys.tilde_subst>>=
let tilde_subst s =
 try
  if s = "" or s.[0] <> '~' then s 
  else
    let len = String.length s in
    if len = 1 then Sys.getenv "HOME"
    else match s.[1] with
      '/' -> 
        Filename.concat (Sys.getenv "HOME") (String.sub s 2 (len - 2))
     | _ ->
       let final = next_slash s 1 in
       let user = String.sub s 1 (pred final) in
       let pwnam = getpwnam user in
         if succ final >= len then pwnam.pw_dir
         else
          Filename.concat pwnam.pw_dir 
               (String.sub s (succ final) (len - (succ final)))
 with
    Unix_error(_,_,_) -> s
  | Sys_error _ -> s
  | Not_found -> s
@

<<function Msys.rm>>=
(* Quiet unlink *)
let rm s = try unlink s with Unix_error _ -> ()
@

<<function Msys.rmdir>>=
let rmdir dir =
  try
    let dh = opendir dir 
    and l = ref [] in
    try while true do
      let f = readdir dh in
      if f <> "." && f <> ".." then l := f :: !l
    done
    with
      End_of_file -> 
    closedir dh;
    List.iter (fun f -> rm (Filename.concat dir f)) !l;
    Unix.rmdir dir
  with
    Unix_error _ -> ()
@

<<function Msys.fsize>>=
let fsize f =
  try (Unix.stat f).st_size
  with Unix_error(_,_,_) -> raise Not_found
@

<<constant Msys.tmp_dir>>=
let tmp_dir = ref "/tmp"
@

<<constant Msys.mktemp>>=
(* We know use our own private directory in /tmp, cleared at exit-time,
   so no one can snoop our temporary files *)
let mktemp =
  let cnter = ref 0 
  and pid = Unix.getpid() 
  and id = ref 0 in
  let thisdir = 
    let testdir = ref "" in
    try while true do
      testdir := Filename.concat !tmp_dir ("mmm" ^ string_of_int pid
                         ^ "_" ^ string_of_int !id);
      if not (Sys.file_exists !testdir) then raise Exit;
      incr id;
      if !id >= 16 then 
    raise (Failure ("Too many MMM temporary directory in " ^ !tmp_dir ^
            ". Clean them first."))
    done; "" (* cannot reach *)
    with
      Exit -> !testdir
  in
  Unix.mkdir thisdir 0o700;
  at_exit (fun () -> rmdir thisdir);
  (function prefx -> 
      incr cnter; 
      (Filename.concat thisdir (prefx ^ string_of_int !cnter)))
@


\section{Dates}


<<signature Date.asc_wkday>>=
val asc_wkday : int -> string
    (* [asc_wkday n] maps 0..6 to Sun..Sat *)
@

<<signature Date.asc_month>>=
val asc_month : int -> string
    (* [asc_month n] maps 0..11 to Jan..Dec *)
@

<<signature Date.asc>>=
val asc : float -> string
    (* [asc uxtime] RFC822 of unix time *)
@

<<signature Date.asc_now>>=
val asc_now : unit -> string
    (* [asc_now ()] RFC822 of now *)
@

<<signature Date.commonlog>>=
val commonlog : float -> string
  (* Text version (Common log format) of an Unix time value *)
@

<<signature Date.compare_time>>=
val compare_time : int list * int list -> int
    (* [compare_time l1 l2] compare lists encodings of timestamps
       Encoding must be:
        [year; month; mday; hour; min; sec]
     *)
@



<<function Date.asc_wkday>>=
let asc_wkday = function
   0 -> "Sun"
 | 1 -> "Mon"
 | 2 -> "Tue"
 | 3 -> "Wed"
 | 4 -> "Thu"
 | 5 -> "Fri"
 | 6 -> "Sat"
 | _ -> assert false
@

<<function Date.asc_month>>=
let asc_month = function
   0 -> "Jan"
 | 1 -> "Feb"
 | 2 -> "Mar"
 | 3 -> "Apr"
 | 4 -> "May"
 | 5 -> "Jun"
 | 6 -> "Jul"
 | 7 -> "Aug"
 | 8 -> "Sep"
 | 9 -> "Oct"
 | 10 -> "Nov"
 | 11 -> "Dec"
 | _ -> assert false
@

<<function Date.asc>>=
(* Produces RFC822 style *)
let asc ut =
  let tm = gmtime ut in
    sprintf "%s, %02d %s %d %02d:%02d:%02d GMT"
        (asc_wkday tm.tm_wday)
    tm.tm_mday
    (asc_month tm.tm_mon)
    (tm.tm_year + 1900)
    tm.tm_hour
    tm.tm_min
    tm.tm_sec
@

<<function Date.asc_now>>=
let asc_now () = asc (time())
@

<<function Date.commonlog>>=
(* Timezone ??? *)
let commonlog int =
  let tm = localtime int in
  sprintf "%02d/%s/%d:%02d:%02d:%02d"
      tm.tm_mday
      (asc_month tm.tm_mon)
      (tm.tm_year + 1900)
      tm.tm_hour
      tm.tm_min
      tm.tm_sec
@

<<function Date.compare_time>>=
let rec compare_time = function
   [], [] -> 0
 | (x::xx), (y::yy) when x = y -> compare_time (xx, yy)
 | (x::_), (y::_) when x < y -> -1
 | (x::_), (y::_) when x > y -> 1
 |  _, _ -> assert false
@



\chapter{Extra Code}

\ifallcode
#include "Browser_extra.nw"
\fi

\chapter{Changelog}
\label{sec:changelog}

\chapter{Glossary}
\label{sec:glossary}

\begin{verbatim}
URL  = Uniform Resource Locator
URI  = Universal Resource Identifier
HTML =
DOM  = Document Object Model
CSS  = Cascading Style Sheets
JS   = Javascript
HTTP =
WWW  = World Wide Web
MIME = ??

DID  = Document IDentifier
\end{verbatim}


\chapter*{Indexes}
\addcontentsline{toc}{section}{Index}

%\chapter{References} 
\addcontentsline{toc}{section}{References}

\begin{thebibliography}{99}

% see mmm-gdr-fr.ps biblio, main RFCs are there.

\bibitem[1]{wp-literate-programming} Donald Knuth,,
{\em Literate Programming}, 
\url{http://en.wikipedia.org/wiki/Literate\_Program}

\bibitem[2]{noweb} Norman Ramsey,
{\em Noweb}, 
\url{http://www.cs.tufts.edu/~nr/noweb/}

\bibitem[3]{syncweb} Yoann Padioleau,
{\em Syncweb, literate programming meets unison}, 
\url{http://padator.org/software/project-syncweb/readme.txt}

\end{thebibliography}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}

